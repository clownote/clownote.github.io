<!DOCTYPE html>
<html lang=zh>
<head><meta name="generator" content="Hexo 3.9.0">
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="Deep Learning with Python è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘å­¦ä¹ ã€ŠDeep Learning with Pythonã€‹(ç¬¬äºŒç‰ˆï¼ŒFranÃ§ois Chollet è‘—) æ—¶å†™çš„ç³»åˆ—ç¬”è®°ä¹‹ä¸€ã€‚æ–‡ç« çš„å†…å®¹æ˜¯ä»  Jupyter notebooks è½¬æˆ Markdown çš„ï¼Œä½ å¯ä»¥å» GitHub æˆ– Gitee æ‰¾åˆ°åŸå§‹çš„ .ipynb ç¬”è®°æœ¬ã€‚ ä½ å¯ä»¥å»è¿™ä¸ªç½‘ç«™åœ¨çº¿é˜…è¯»è¿™æœ¬ä¹¦çš„æ­£ç‰ˆåŸæ–‡(è‹±æ–‡)">
<meta name="keywords" content="Machine Learning,Deep Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ">
<meta property="og:url" content="https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/index.html">
<meta property="og:site_name" content="clownote">
<meta property="og:description" content="Deep Learning with Python è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘å­¦ä¹ ã€ŠDeep Learning with Pythonã€‹(ç¬¬äºŒç‰ˆï¼ŒFranÃ§ois Chollet è‘—) æ—¶å†™çš„ç³»åˆ—ç¬”è®°ä¹‹ä¸€ã€‚æ–‡ç« çš„å†…å®¹æ˜¯ä»  Jupyter notebooks è½¬æˆ Markdown çš„ï¼Œä½ å¯ä»¥å» GitHub æˆ– Gitee æ‰¾åˆ°åŸå§‹çš„ .ipynb ç¬”è®°æœ¬ã€‚ ä½ å¯ä»¥å»è¿™ä¸ªç½‘ç«™åœ¨çº¿é˜…è¯»è¿™æœ¬ä¹¦çš„æ­£ç‰ˆåŸæ–‡(è‹±æ–‡)">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghq58v9qd6j319c0ka41y.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghq692zm1nj316f0u0k9r.jpg">
<meta property="og:updated_time" content="2020-11-24T04:45:20.328Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ">
<meta name="twitter:description" content="Deep Learning with Python è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘å­¦ä¹ ã€ŠDeep Learning with Pythonã€‹(ç¬¬äºŒç‰ˆï¼ŒFranÃ§ois Chollet è‘—) æ—¶å†™çš„ç³»åˆ—ç¬”è®°ä¹‹ä¸€ã€‚æ–‡ç« çš„å†…å®¹æ˜¯ä»  Jupyter notebooks è½¬æˆ Markdown çš„ï¼Œä½ å¯ä»¥å» GitHub æˆ– Gitee æ‰¾åˆ°åŸå§‹çš„ .ipynb ç¬”è®°æœ¬ã€‚ ä½ å¯ä»¥å»è¿™ä¸ªç½‘ç«™åœ¨çº¿é˜…è¯»è¿™æœ¬ä¹¦çš„æ­£ç‰ˆåŸæ–‡(è‹±æ–‡)">
<meta name="twitter:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghq58v9qd6j319c0ka41y.jpg">
    
    
        
          
              <link rel="shortcut icon" href="/images/rabbit.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/rabbit_192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/rabbit_180.png">
          
        
    
    <!-- title -->
    <title>Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss -->
    
    
    <!--Google search varification (PRIVATE)-->
    <meta name="google-site-verification" content="MrqlpFAD8nDanw3Ypv7ZsIWHLnTdhRuLa4QhSVwxIvc">
    <!--Google AdSense å…³è” (PRIVATE)-->
    <script data-ad-client="ca-pub-1510963483941114" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">é¦–é¡µ</a></li>
         
          <li><a href="/about/">å…³äº</a></li>
         
          <li><a href="/archives/">å½’æ¡£</a></li>
         
          <li><a href="https://github.com/cdfmlr">é¡¹ç›®</a></li>
         
          <li><a href="/search/">æœç´¢</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2020/08/21/DeepLearningWithPython/Deep-Learning with-Python-ch8_2/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2020/08/19/DeepLearningWithPython/Deep-Learning with-Python-ch7_3/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">ä¸Šä¸€ç¯‡</span>
      <span id="i-next" class="info" style="display:none;">ä¸‹ä¸€ç¯‡</span>
      <span id="i-top" class="info" style="display:none;">è¿”å›é¡¶éƒ¨</span>
      <span id="i-share" class="info" style="display:none;">åˆ†äº«æ–‡ç« </span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&text=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&is_video=false&description=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ&body=Check out this article: https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&name=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#deep-learning-with-python"><span class="toc-number">1.</span> <span class="toc-text"> Deep Learning with Python</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#81-text-generation-with-lstm"><span class="toc-number">1.1.</span> <span class="toc-text"> 8.1 Text generation with LSTM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#åºåˆ—æ•°æ®çš„ç”Ÿæˆ"><span class="toc-number">1.1.1.</span> <span class="toc-text"> åºåˆ—æ•°æ®çš„ç”Ÿæˆ</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#é‡‡æ ·ç­–ç•¥"><span class="toc-number">1.1.2.</span> <span class="toc-text"> é‡‡æ ·ç­–ç•¥</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#å­—ç¬¦çº§-lstm-æ–‡æœ¬ç”Ÿæˆå®ç°"><span class="toc-number">1.1.3.</span> <span class="toc-text"> å­—ç¬¦çº§ LSTM æ–‡æœ¬ç”Ÿæˆå®ç°</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#æ•°æ®å‡†å¤‡"><span class="toc-number">1.1.3.1.</span> <span class="toc-text"> æ•°æ®å‡†å¤‡</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#æ„å»ºç½‘ç»œ"><span class="toc-number">1.1.3.2.</span> <span class="toc-text"> æ„å»ºç½‘ç»œ</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#è®­ç»ƒè¯­è¨€æ¨¡å‹å¹¶ä»ä¸­é‡‡æ ·"><span class="toc-number">1.1.3.3.</span> <span class="toc-text"> è®­ç»ƒè¯­è¨€æ¨¡å‹å¹¶ä»ä¸­é‡‡æ ·</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#é™„åŸºäºè¯åµŒå…¥çš„æ–‡æœ¬ç”Ÿæˆ"><span class="toc-number">1.1.4.</span> <span class="toc-text"> é™„ï¼šåŸºäºè¯åµŒå…¥çš„æ–‡æœ¬ç”Ÿæˆ</span></a></li></ol></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">clownote</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2020-08-20T11:21:34.000Z" itemprop="datePublished">2020-08-20</time>
        
        (Updated: <time datetime="2020-11-24T04:45:20.328Z" itemprop="dateModified">2020-11-24</time>)
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/Machine-Learning/">Machine Learning</a> â€º <a class="category-link" href="/categories/Machine-Learning/Deep-Learning-with-Python/">Deep Learning with Python</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a>, <a class="tag-link" href="/tags/Machine-Learning/">Machine Learning</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h1 id="deep-learning-with-python"><a class="markdownIt-Anchor" href="#deep-learning-with-python"></a> Deep Learning with Python</h1>
<p>è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘å­¦ä¹ ã€ŠDeep Learning with Pythonã€‹(ç¬¬äºŒç‰ˆï¼ŒFranÃ§ois Chollet è‘—) æ—¶å†™çš„ç³»åˆ—ç¬”è®°ä¹‹ä¸€ã€‚æ–‡ç« çš„å†…å®¹æ˜¯ä»  Jupyter notebooks è½¬æˆ Markdown çš„ï¼Œä½ å¯ä»¥å» <a href="https://github.com/cdfmlr/Deep-Learning-with-Python-Notebooks" target="_blank" rel="noopener">GitHub</a> æˆ– <a href="https://gitee.com/cdfmlr/Deep-Learning-with-Python-Notebooks" target="_blank" rel="noopener">Gitee</a> æ‰¾åˆ°åŸå§‹çš„ <code>.ipynb</code> ç¬”è®°æœ¬ã€‚</p>
<p>ä½ å¯ä»¥å»<a href="https://livebook.manning.com/book/deep-learning-with-python" target="_blank" rel="noopener">è¿™ä¸ªç½‘ç«™åœ¨çº¿é˜…è¯»è¿™æœ¬ä¹¦çš„æ­£ç‰ˆåŸæ–‡</a>(è‹±æ–‡)ã€‚è¿™æœ¬ä¹¦çš„ä½œè€…ä¹Ÿç»™å‡ºäº†é…å¥—çš„ <a href="https://github.com/fchollet/deep-learning-with-python-notebooks" target="_blank" rel="noopener">Jupyter notebooks</a>ã€‚</p>
<p>æœ¬æ–‡ä¸º <strong>ç¬¬8ç«   ç”Ÿæˆå¼æ·±åº¦å­¦ä¹ </strong> (Chapter 8. <em>Generative deep learning</em>) çš„ç¬”è®°ä¹‹ä¸€ã€‚</p>
<p>[TOC]</p>
<h2 id="81-text-generation-with-lstm"><a class="markdownIt-Anchor" href="#81-text-generation-with-lstm"></a> 8.1 Text generation with LSTM</h2>
<blockquote>
<p>ä½¿ç”¨ LSTM ç”Ÿæˆæ–‡æœ¬</p>
</blockquote>
<p>ä»¥å‰æœ‰äººè¯´è¿‡ï¼šâ€œgenerating sequential data is the closest computers get to dreamingâ€ï¼Œè®©è®¡ç®—æœºç”Ÿæˆåºåˆ—æ˜¯å¾ˆæœ‰é­…åŠ›çš„äº‹æƒ…ã€‚æˆ‘ä»¬å°†ä»¥æ–‡æœ¬ç”Ÿæˆä¸ºä¾‹ï¼Œæ¢è®¨å¦‚ä½•å°†å¾ªç¯ç¥ç»ç½‘ç»œç”¨äºç”Ÿæˆåºåˆ—æ•°æ®ã€‚è¿™é¡¹æŠ€æœ¯ä¹Ÿå¯ä»¥ç”¨äºéŸ³ä¹çš„ç”Ÿæˆã€è¯­éŸ³åˆæˆã€èŠå¤©æœºå™¨äººå¯¹è¯ç”Ÿæˆã€ç”šè‡³æ˜¯ç”µå½±å‰§æœ¬çš„ç¼–å†™ç­‰ç­‰ã€‚</p>
<p>å…¶å®ï¼Œæˆ‘ä»¬ç°åœ¨ç†ŸçŸ¥çš„ LSTM ç®—æ³•ï¼Œæœ€æ—©è¢«å¼€å‘å‡ºæ¥çš„æ—¶å€™ï¼Œå°±æ˜¯ç”¨äºé€å­—ç¬¦åœ°ç”Ÿæˆæ–‡æœ¬çš„ã€‚</p>
<h3 id="åºåˆ—æ•°æ®çš„ç”Ÿæˆ"><a class="markdownIt-Anchor" href="#åºåˆ—æ•°æ®çš„ç”Ÿæˆ"></a> åºåˆ—æ•°æ®çš„ç”Ÿæˆ</h3>
<p>ç”¨æ·±åº¦å­¦ä¹ ç”Ÿæˆåºåˆ—çš„é€šç”¨æ–¹æ³•ï¼Œå°±æ˜¯è®­ç»ƒä¸€ä¸ªç½‘ç»œ(ä¸€èˆ¬ç”¨ RNN æˆ– CNN)ï¼Œè¾“å…¥å‰é¢çš„ Tokenï¼Œé¢„æµ‹åºåˆ—ä¸­æ¥ä¸‹æ¥çš„ Tokenã€‚</p>
<p>è¯´çš„æœ¯è¯­åŒ–ä¸€äº›ï¼šç»™å®šå‰é¢çš„ Tokenï¼Œèƒ½å¤Ÿå¯¹ä¸‹ä¸€ä¸ª Token çš„æ¦‚ç‡è¿›è¡Œå»ºæ¨¡çš„ç½‘ç»œå«ä½œã€Œè¯­è¨€æ¨¡å‹(language model)ã€ã€‚è¯­è¨€æ¨¡å‹èƒ½å¤Ÿæ•æ‰åˆ°è¯­è¨€çš„ç»Ÿè®¡ç»“æ„ â€”â€”ã€Œæ½œåœ¨ç©ºé—´(latent space)ã€ã€‚è®­ç»ƒå¥½ä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼Œè¾“å…¥åˆå§‹æ–‡æœ¬å­—ç¬¦ä¸²ï¼ˆç§°ä¸ºã€Œæ¡ä»¶æ•°æ®ã€ï¼Œconditioning dataï¼‰ï¼Œä»è¯­è¨€æ¨¡å‹ä¸­é‡‡æ ·ï¼Œå°±å¯ä»¥ç”Ÿæˆæ–° Tokenï¼ŒæŠŠæ–°çš„ Token åŠ å…¥æ¡ä»¶æ•°æ®ä¸­ï¼Œå†æ¬¡è¾“å…¥ï¼Œé‡å¤è¿™ä¸ªè¿‡ç¨‹å°±å¯ä»¥ç”Ÿæˆå‡ºä»»æ„é•¿åº¦çš„åºåˆ—ã€‚</p>
<p>æˆ‘ä»¬ä»ä¸€ä¸ªç®€å•çš„ä¾‹å­å¼€å§‹ï¼šç”¨ä¸€ä¸ª LSTM å±‚ï¼Œè¾“å…¥æ–‡æœ¬è¯­æ–™çš„ N ä¸ªå­—ç¬¦ç»„æˆçš„å­—ç¬¦ä¸²ï¼Œè®­ç»ƒæ¨¡å‹æ¥ç”Ÿæˆç¬¬ N+1 ä¸ªå­—ç¬¦ã€‚æ¨¡å‹çš„è¾“å‡ºæ˜¯åš softmaxï¼Œåœ¨æ‰€æœ‰å¯èƒ½çš„å­—ç¬¦ä¸Šï¼Œå¾—åˆ°ä¸‹ä¸€ä¸ªå­—ç¬¦çš„æ¦‚ç‡åˆ†å¸ƒã€‚è¿™ä¸ªæ¨¡å‹å«ä½œã€Œå­—ç¬¦çº§çš„ç¥ç»è¯­è¨€æ¨¡å‹ã€(character-level neural language model)ã€‚</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghq58v9qd6j319c0ka41y.jpg" alt="ä½¿ç”¨è¯­è¨€æ¨¡å‹é€ä¸ªå­—ç¬¦ç”Ÿæˆæ–‡æœ¬çš„è¿‡ç¨‹"></p>
<h3 id="é‡‡æ ·ç­–ç•¥"><a class="markdownIt-Anchor" href="#é‡‡æ ·ç­–ç•¥"></a> é‡‡æ ·ç­–ç•¥</h3>
<p>ä½¿ç”¨å­—ç¬¦çº§çš„ç¥ç»è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œæœ€é‡è¦çš„é—®é¢˜æ˜¯å¦‚ä½•é€‰æ‹©ä¸‹ä¸€ä¸ªå­—ç¬¦ã€‚è¿™é‡Œæœ‰å‡ å¼ å¸¸ç”¨æ–¹æ³•ï¼š</p>
<ul>
<li>è´ªå©ªé‡‡æ ·(greedy sampling)ï¼šå§‹ç»ˆé€‰æ‹©å¯èƒ½æ€§æœ€å¤§çš„ä¸‹ä¸€ä¸ªå­—ç¬¦ã€‚è¿™ä¸ªæ–¹æ³•å¾ˆå¯èƒ½å¾—åˆ°é‡å¤çš„ã€å¯é¢„æµ‹çš„å­—ç¬¦ä¸²ï¼Œè€Œä¸”å¯èƒ½æ„æ€ä¸è¿è´¯ã€‚ï¼ˆè¾“å…¥æ³•è”æƒ³ï¼‰</li>
<li>çº¯éšæœºé‡‡æ ·ï¼šä»å‡åŒ€æ¦‚ç‡åˆ†å¸ƒä¸­æŠ½å–ä¸‹ä¸€ä¸ªå­—ç¬¦ï¼Œå…¶ä¸­æ¯ä¸ªå­—ç¬¦çš„æ¦‚ç‡ç›¸åŒã€‚è¿™æ ·éšæœºæ€§å¤ªé«˜ï¼Œå‡ ä¹ä¸ä¼šç”Ÿæˆå‡ºæœ‰è¶£çš„å†…å®¹ã€‚ï¼ˆå°±æ˜¯èƒ¡ä¹±è¾“å‡ºå­—ç¬¦çš„ç»„åˆï¼‰</li>
<li>éšæœºé‡‡æ ·(stochastic sampling)ï¼šæ ¹æ®è¯­è¨€æ¨¡å‹çš„ç»“æœï¼Œå¦‚æœä¸‹ä¸€ä¸ªå­—ç¬¦æ˜¯ e çš„æ¦‚ç‡ä¸º 0.3ï¼Œé‚£ä¹ˆä½ ä¼šæœ‰ 30% çš„æ¦‚ç‡é€‰æ‹©å®ƒã€‚æœ‰ä¸€ç‚¹çš„éšæœºæ€§ï¼Œè®©ç”Ÿæˆçš„å†…å®¹æ›´<s>éšæ„</s>å¯Œæœ‰å˜åŒ–ï¼Œä½†åˆä¸æ˜¯å®Œå…¨éšæœºï¼Œè¾“å‡ºå¯ä»¥æ¯”è¾ƒæœ‰æ„æ€ã€‚</li>
</ul>
<p>éšæœºé‡‡æ ·çœ‹ä¸Šå»å¾ˆå¥½ï¼Œå¾ˆæœ‰åˆ›é€ æ€§ï¼Œä½†æœ‰ä¸ªé—®é¢˜æ˜¯æ— æ³•æ§åˆ¶éšæœºæ€§çš„å¤§å°ï¼šéšæœºæ€§è¶Šå¤§ï¼Œå¯èƒ½å¯Œæœ‰åˆ›é€ æ€§ï¼Œä½†å¯èƒ½èƒ¡ä¹±è¾“å‡ºï¼›éšæœºæ€§è¶Šå°ï¼Œå¯èƒ½æ›´æ¥è¿‘çœŸå®è¯å¥ï¼Œä½†å¤ªæ­»æ¿ã€å¯é¢„æµ‹ã€‚</p>
<p>ä¸ºäº†åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­æ§åˆ¶éšæœºæ€§çš„å¤§å°ï¼Œå¼•å…¥ä¸€ä¸ªå‚æ•°ï¼šã€Œsoftmax æ¸©åº¦ã€(softmax temperature)ï¼Œç”¨äºè¡¨ç¤ºé‡‡æ ·æ¦‚ç‡åˆ†å¸ƒçš„ç†µï¼Œå³è¡¨ç¤ºæ‰€é€‰æ‹©çš„ä¸‹ä¸€ä¸ªå­—ç¬¦ä¼šæœ‰å¤šä¹ˆå‡ºäººæ„æ–™æˆ–å¤šä¹ˆå¯é¢„æµ‹ï¼š</p>
<ul>
<li>æ›´é«˜çš„æ¸©åº¦ï¼šç†µæ›´å¤§çš„é‡‡æ ·åˆ†å¸ƒï¼Œä¼šç”Ÿæˆæ›´åŠ å‡ºäººæ„æ–™ã€æ›´åŠ æ— ç»“æ„çš„æ•°æ®ï¼›</li>
<li>æ›´ä½çš„æ¸©åº¦ï¼šå¯¹åº”æ›´å°çš„éšæœºæ€§ï¼Œä¼šç”Ÿæˆæ›´åŠ å¯é¢„æµ‹çš„æ•°æ®ã€‚</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghq692zm1nj316f0u0k9r.jpg" alt="å¯¹åŒä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒè¿›è¡Œä¸åŒçš„é‡æ–°åŠ æƒï¼šæ›´ä½çš„æ¸©åº¦=æ›´ç¡®å®šï¼Œæ›´é«˜çš„æ¸©åº¦=æ›´éšæœº"></p>
<p>å…·ä½“çš„å®ç°æ˜¯ï¼Œç»™å®š temperature å€¼ï¼Œå¯¹æ¨¡å‹çš„ softmax è¾“å‡ºé‡æ–°åŠ æƒï¼Œå¾—åˆ°æ–°çš„æ¦‚ç‡åˆ†å¸ƒï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rewight_distribution</span><span class="params">(original_distributon, temperature=<span class="number">0.5</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    å¯¹äºä¸åŒçš„ softmax æ¸©åº¦ï¼Œå¯¹æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œé‡æ–°åŠ æƒ</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    distribution = np.log(original_distribution) / temperature</span><br><span class="line">    distribution = np.exp(distribution)</span><br><span class="line">    <span class="keyword">return</span> distribution / np.sum(distribution)</span><br></pre></td></tr></table></figure>
<h3 id="å­—ç¬¦çº§-lstm-æ–‡æœ¬ç”Ÿæˆå®ç°"><a class="markdownIt-Anchor" href="#å­—ç¬¦çº§-lstm-æ–‡æœ¬ç”Ÿæˆå®ç°"></a> å­—ç¬¦çº§ LSTM æ–‡æœ¬ç”Ÿæˆå®ç°</h3>
<p>ç†è®ºå°±ä¸Šé¢é‚£äº›äº†ï¼Œç°åœ¨ï¼Œæˆ‘ä»¬è¦ç”¨ Keras æ¥å®ç°å­—ç¬¦çº§çš„ LSTM æ–‡æœ¬ç”Ÿæˆäº†ã€‚</p>
<h4 id="æ•°æ®å‡†å¤‡"><a class="markdownIt-Anchor" href="#æ•°æ®å‡†å¤‡"></a> æ•°æ®å‡†å¤‡</h4>
<p>é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å¤§é‡çš„æ–‡æœ¬æ•°æ®(è¯­æ–™ï¼Œcorpus)æ¥è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚å¯ä»¥å»æ‰¾è¶³å¤Ÿå¤§çš„ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡æœ¬æ–‡ä»¶ï¼šç»´åŸºç™¾ç§‘ã€å„ç§ä¹¦ç±ç­‰éƒ½å¯ã€‚è¿™é‡Œæˆ‘ä»¬é€‰æ‹©ç”¨ä¸€äº›å°¼é‡‡çš„ä½œå“ï¼ˆè‹±æ–‡è¯‘æœ¬ï¼‰ï¼Œè¿™æ ·æˆ‘ä»¬å­¦ä¹ å‡ºæ¥çš„è¯­è¨€æ¨¡å‹å°†æ˜¯æœ‰å°¼é‡‡çš„å†™ä½œé£æ ¼å’Œä¸»é¢˜çš„ã€‚ï¼ˆæ’ï¼šæˆ‘ï¼Œæˆ‘ä»¥å‰è‡ªå·±å†™é‡ç”Ÿæ¨¡å‹ç©ï¼Œéƒ½æ˜¯ç”¨é²è¿…ğŸ˜‚ï¼‰</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä¸‹è½½è¯­æ–™ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºå…¨å°å†™</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">path = keras.utils.get_file(</span><br><span class="line">    <span class="string">'nietzsche.txt'</span>, </span><br><span class="line">    origin=<span class="string">'https://s3.amazonaws.com/text-datasets/nietzsche.txt'</span>)</span><br><span class="line">text = open(path).read().lower()</span><br><span class="line">print(<span class="string">'Corpus length:'</span>, len(text))</span><br></pre></td></tr></table></figure>
<pre><code>/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
  return f(*args, **kwds)
/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
  return f(*args, **kwds)


Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt
606208/600901 [==============================] - 430s 709us/step
Corpus length: 600893
</code></pre>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¦æŠŠæ–‡æœ¬åšæˆæ•°æ® (å‘é‡åŒ–)ï¼šä» text é‡Œæå–é•¿åº¦ä¸º <code>maxlen</code> çš„åºåˆ—(åºåˆ—ä¹‹é—´å­˜åœ¨éƒ¨åˆ†é‡å )ï¼Œè¿›è¡Œ one-hot ç¼–ç ï¼Œç„¶åæ‰“åŒ…æˆ <code>(sequences, maxlen, unique_characters)</code> å½¢çŠ¶çš„ã€‚åŒæ—¶ï¼Œè¿˜éœ€è¦å‡†å¤‡æ•°ç»„ <code>y</code>ï¼ŒåŒ…å«å¯¹åº”çš„ç›®æ ‡ï¼Œå³åœ¨æ¯ä¸€ä¸ªæ‰€æå–çš„åºåˆ—ä¹‹åå‡ºç°çš„å­—ç¬¦(ä¹Ÿæ˜¯ one-hot ç¼–ç çš„)ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å°†å­—ç¬¦åºåˆ—å‘é‡åŒ–</span></span><br><span class="line"></span><br><span class="line">maxlen = <span class="number">60</span>     <span class="comment"># æ¯ä¸ªåºåˆ—çš„é•¿åº¦</span></span><br><span class="line">step = <span class="number">3</span>        <span class="comment"># æ¯ 3 ä¸ªå­—ç¬¦é‡‡æ ·ä¸€ä¸ªæ–°åºåˆ—</span></span><br><span class="line">sentences = []  <span class="comment"># ä¿å­˜æ‰€æå–çš„åºåˆ—</span></span><br><span class="line">next_chars = [] <span class="comment"># sentences çš„ä¸‹ä¸€ä¸ªå­—ç¬¦</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(text) - maxlen, step):</span><br><span class="line">    sentences.append(text[i: i+maxlen])</span><br><span class="line">    next_chars.append(text[i+maxlen])</span><br><span class="line">print(<span class="string">'Number of sequences:'</span>, len(sentences))</span><br><span class="line"></span><br><span class="line">chars = sorted(list(set(text)))</span><br><span class="line">char_indices = dict((char, chars.index(char)) <span class="keyword">for</span> char <span class="keyword">in</span> chars)</span><br><span class="line"><span class="comment"># æ’ï¼šä¸Šé¢è¿™ä¸¤è¡Œä»£ç  6</span></span><br><span class="line">print(<span class="string">'Unique characters:'</span>, len(chars))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Vectorization...'</span>)</span><br><span class="line"></span><br><span class="line">x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)</span><br><span class="line">y = np.zeros((len(sentences), len(chars)), dtype=np.bool)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, sentence <span class="keyword">in</span> enumerate(sentences):</span><br><span class="line">    <span class="keyword">for</span> t, char <span class="keyword">in</span> enumerate(sentence):</span><br><span class="line">        x[i, t, char_indices[char]] = <span class="number">1</span></span><br><span class="line">    y[i, char_indices[next_chars[i]]] = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<pre><code>Number of sequences: 200278
Unique characters: 57
Vectorization...
</code></pre>
<h4 id="æ„å»ºç½‘ç»œ"><a class="markdownIt-Anchor" href="#æ„å»ºç½‘ç»œ"></a> æ„å»ºç½‘ç»œ</h4>
<p>æˆ‘ä»¬è¦ç”¨åˆ°çš„ç½‘ç»œå…¶å®å¾ˆç®€å•ï¼Œä¸€ä¸ª LSTM å±‚ + ä¸€ä¸ª softmax æ¿€æ´»çš„ Dense å±‚å°±å¯ä»¥äº†ã€‚å…¶å®å¹¶ä¸ä¸€å®šè¦ç”¨ LSTMï¼Œç”¨ä¸€ç»´å·ç§¯å±‚ä¹Ÿæ˜¯å¯ä»¥ç”Ÿæˆåºåˆ—çš„ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç”¨äºé¢„æµ‹ä¸‹ä¸€ä¸ªå­—ç¬¦çš„å•å±‚ LSTM æ¨¡å‹</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> LSTM, Dense</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">128</span>, input_shape=(maxlen, len(chars))))</span><br><span class="line">model.add(Dense(len(chars), activation=<span class="string">'softmax'</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ¨¡å‹ç¼–è¯‘é…ç½®</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line">optimizer = optimizers.RMSprop(lr=<span class="number">0.01</span>)</span><br><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">              optimizer=optimizer)</span><br></pre></td></tr></table></figure>
<h4 id="è®­ç»ƒè¯­è¨€æ¨¡å‹å¹¶ä»ä¸­é‡‡æ ·"><a class="markdownIt-Anchor" href="#è®­ç»ƒè¯­è¨€æ¨¡å‹å¹¶ä»ä¸­é‡‡æ ·"></a> è®­ç»ƒè¯­è¨€æ¨¡å‹å¹¶ä»ä¸­é‡‡æ ·</h4>
<p>ç»™å®šä¸€ä¸ªè¯­è¨€æ¨¡å‹å’Œä¸€ä¸ªç§å­æ–‡æœ¬ç‰‡æ®µï¼Œå°±å¯ä»¥é€šè¿‡é‡å¤ä»¥ä¸‹æ“ä½œæ¥ç”Ÿæˆæ–°çš„æ–‡æœ¬ï¼š</p>
<ol>
<li>ç»™å®šç›®å‰å·²æœ‰æ–‡æœ¬ï¼Œä»æ¨¡å‹ä¸­å¾—åˆ°ä¸‹ä¸€ä¸ªå­—ç¬¦çš„æ¦‚ç‡åˆ†å¸ƒï¼›</li>
<li>æ ¹æ®æŸä¸ªæ¸©åº¦å¯¹åˆ†å¸ƒè¿›è¡Œé‡æ–°åŠ æƒï¼›</li>
<li>æ ¹æ®é‡æ–°åŠ æƒåçš„åˆ†å¸ƒå¯¹ä¸‹ä¸€ä¸ªå­—ç¬¦è¿›è¡Œéšæœºé‡‡æ ·ï¼›</li>
<li>å°†æ–°å­—ç¬¦æ·»åŠ åˆ°æ–‡æœ¬æœ«å°¾ã€‚</li>
</ol>
<p>åœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæŠŠã€Œé‡‡æ ·å‡½æ•°ã€å†™äº†ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(preds, temperature=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    å¯¹æ¨¡å‹å¾—åˆ°çš„åŸå§‹æ¦‚ç‡åˆ†å¸ƒé‡æ–°åŠ æƒï¼Œå¹¶ä»ä¸­æŠ½å–ä¸€ä¸ªå­—ç¬¦ç´¢å¼•</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    preds = np.asarray(preds).astype(<span class="string">'float64'</span>)</span><br><span class="line">    preds = np.log(preds) / temperature</span><br><span class="line">    exp_preds = np.exp(preds)</span><br><span class="line">    preds = exp_preds / np.sum(exp_preds)</span><br><span class="line">    probas = np.random.multinomial(<span class="number">1</span>, preds, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> np.argmax(probas)</span><br></pre></td></tr></table></figure>
<p>æœ€åï¼Œå†æ¥è®­ç»ƒå¹¶ç”Ÿæˆæ–‡æœ¬ã€‚æˆ‘ä»¬åœ¨æ¯è½®å®Œæˆåéƒ½ä½¿ç”¨ä¸€ç³»åˆ—ä¸åŒçš„æ¸©åº¦å€¼æ¥ç”Ÿæˆæ–‡æœ¬ï¼Œè¿™æ ·å°±å¯ä»¥çœ‹åˆ°ï¼Œéšç€æ¨¡å‹æ”¶æ•›ï¼Œç”Ÿæˆçš„æ–‡æœ¬å¦‚ä½•å˜åŒ–ï¼Œä»¥åŠæ¸©åº¦å¯¹é‡‡æ ·ç­–ç•¥çš„å½±å“ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ–‡æœ¬ç”Ÿæˆå¾ªç¯</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">60</span>):    <span class="comment"># è®­ç»ƒ 60 ä¸ªè½®æ¬¡</span></span><br><span class="line">    print(<span class="string">f'ğŸ‘‰\033[1;35m epoch <span class="subst">&#123;epoch&#125;</span> \033[0m'</span>)    <span class="comment"># print('epoch', epoch)</span></span><br><span class="line">    </span><br><span class="line">    model.fit(x, y,</span><br><span class="line">              batch_size=<span class="number">128</span>,</span><br><span class="line">              epochs=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    start_index = random.randint(<span class="number">0</span>, len(text) - maxlen - <span class="number">1</span>)</span><br><span class="line">    generated_text = text[start_index: start_index + maxlen]</span><br><span class="line">    print(<span class="string">f'  ğŸ“– Generating with seed: "\033[1;32;43m<span class="subst">&#123;generated_text&#125;</span>\033[0m"'</span>)    <span class="comment"># print(f' Generating with seed: "&#123;generated_text&#125;"')</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> temperature <span class="keyword">in</span> [<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">1.2</span>]:</span><br><span class="line">        print(<span class="string">f'\n   \033[1;36m ğŸŒ¡ï¸ temperature: <span class="subst">&#123;temperature&#125;</span>\033[0m'</span>)    <span class="comment"># print('\n  temperature:', temperature)</span></span><br><span class="line">        print(generated_text, end=<span class="string">''</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">400</span>):    <span class="comment"># ç”Ÿæˆ 400 ä¸ªå­—ç¬¦</span></span><br><span class="line">            <span class="comment"># one-hot ç¼–ç ç›®å‰æœ‰çš„æ–‡æœ¬</span></span><br><span class="line">            sampled = np.zeros((<span class="number">1</span>, maxlen, len(chars)))</span><br><span class="line">            <span class="keyword">for</span> t, char <span class="keyword">in</span> enumerate(generated_text):</span><br><span class="line">                sampled[<span class="number">0</span>, t, char_indices[char]] = <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># é¢„æµ‹ï¼Œé‡‡æ ·ï¼Œç”Ÿæˆä¸‹ä¸€å­—ç¬¦</span></span><br><span class="line">            preds = model.predict(sampled, verbose=<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">            next_index = sample(preds, temperature)</span><br><span class="line">            next_char = chars[next_index]</span><br><span class="line">            print(next_char, end=<span class="string">''</span>)</span><br><span class="line">            </span><br><span class="line">            generated_text = generated_text[<span class="number">1</span>:] + next_char</span><br><span class="line">            </span><br><span class="line">    print(<span class="string">'\n'</span> + <span class="string">'-'</span> * <span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<pre><code>ğŸ‘‰ epoch 1 
1565/1565 [==============================] - 170s 108ms/step - loss: 1.4089
  ğŸ“– Generating with seed: &quot;ary!--will at least be entitled to demand in return that
psy&quot;

    ğŸŒ¡ï¸ temperature: 0.2
ary!--will at least be entitled to demand in return that
psychological senses of the the most comprehensed that is a sense of a perhaps the experience of the heart the present that the profound that the experience of the exploition and present that is a self and the present that is a more of the senses of a more and the sense of a more art and the the exploition and self-contempt of a perhaps the superiom and perhaps the contempt of the superiom and all th
    ğŸŒ¡ï¸ temperature: 0.5
superiom and perhaps the contempt of the superiom and all the instance and plays place of comprehensed and so in morals and all the auther to present mettoral of the senses and fellines to have the conceive that the
possibility of the expendeness, the hasters as how to really expendened and
all that the forenies; and all the most consequently comes that the most constanter to constantering only all the expearated the expendeness is in the delight and one w
    ğŸŒ¡ï¸ temperature: 1.0
l the expearated the expendeness is in the delight and one would be persists more and world, others which in the utility of the fellows
among and deceeth, virtuery, mode. one
soul the most conterrites and ly under that conservate to mapt of the own toweration here old taste inilt, the &quot;frew-well
to openhanss&quot;--and the way could easily hamint; becoming being, thrien himself, very deteruence who usked slaver and own scientification, of the eever,&quot; wand
undou
    ğŸŒ¡ï¸ temperature: 1.2
ed slaver and own scientification, of the eever,&quot; wand
undoupible &quot;befost suldeces.&quot; it weim even astreated drwadged,
owing parits, word of hister&quot;
enocest.-
sychea, that that words in the savery: 
y allverowed&quot;, when and liqksis felling, them soperation of clentous
and blendiers.
the pleasrvation humiturring, likeford of feit-rum. i must &quot;nrightenmy,&quot; beneveral man.&quot; the goods-
the cerses is christrantss and lightence--not man goemin love,
frro-akem.y tix
--------------------
...
ğŸ‘‰ epoch 30 
1565/1565 [==============================] - 452s 289ms/step - loss: 1.2692
  ğŸ“– Generating with seed: &quot;y system of morals, is that it is a
long constraint. in orde&quot;

    ğŸŒ¡ï¸ temperature: 0.2
y system of morals, is that it is a
long constraint. in order to be stronger and according to the same the standand, as a men and sanctity, and all the sense of the strength to the sense of the strong the striving of the strong the striving of the sense of the same this consequently and something and in a man with the sense of the sense of the same the strong of the same the sense of the strength to the sense of the same the artist the strong more and the 
    ğŸŒ¡ï¸ temperature: 0.5
to the sense of the same the artist the strong more and the intellectually in the called bet of the more of such as something of standand, the experience and profound, and in the delusions of the morality of the propeted and the more of a good and one has a sorts of the constitute in the same the religion
in the same the human condition, the old proper all this taste which seeming and the standand, and are to the person of the strength and the latten more 
    ğŸŒ¡ï¸ temperature: 1.0
, and are to the person of the strength and the latten more matter, fith, niquet of nature of rove seemsion and proxible is itself, it has
 final &quot;genion&quot; in coptent,
and un so larmor, romant.

bicident, with which fur one remain echo of
called in this acqueis forceek of consciate convoled,
asceticilies
invaluable demardinatid.

          he in respons himons, which, a engliches bad hope feels these see,
fermines &quot;only he will&quot;n--as stapty pullens of bad a
    ğŸŒ¡ï¸ temperature: 1.2
se see,
fermines &quot;only he will&quot;n--as stapty pullens of bad adaval inexcepning at the unvery in all, whose in--that is a power be many trainitg prtunce--by the crueled him is every
noble,
as he society of this
sneke viged, has to telless all juscallers. we megnant cominghik, as gray illow and of holy este, &quot;the knowing&quot; how videly upon the adventive. there is discived and it attine to jesubuc'--the .=--what
lived
a! iapower, profoundc: of himself, it is lie
--------------------
...
ğŸ‘‰ epoch 59 
1565/1565 [==============================] - 173s 110ms/step - loss: 1.2279
  ğŸ“– Generating with seed: &quot;inward self-contempt, seek to get out of
the business, no ma&quot;

    ğŸŒ¡ï¸ temperature: 0.2
inward self-contempt, seek to get out of
the business, no may be only and the ascetiably sense of the real and the sense of the more sense of the community of the moral and profound the way there is the sense of the most contempt of the spirit in a perceive, and the interpreting the sense of the world as it is the soul is the artist of the sense and the world as in the entire
complication of the world as it is the strong of the most profound to the world a
    ğŸŒ¡ï¸ temperature: 0.5
orld as it is the strong of the most profound to the world as the self nowadays to me that all the artifure in the mother of significance of the roman and we are this from the strength of existing and faith enthurable to the discover of the contrain to
religious were and self-grades the world with the way to the present think there are also all the plato-pit firels made a weart for the person of the rank on a way of the ethical prombates, to reason of the 
    ğŸŒ¡ï¸ temperature: 1.0
he rank on a way of the ethical prombates, to reason of the mortand: that pureon good lack as has refree, in a herore proposition is
pronounce
the last the reasonably book of will calued and vexeme, and no means mentary honour pertimate our new, conversations. it is that
the sense ciertably with our distins of the remare of counter that german &quot;miswome centurially instinct&quot; in course,.
 hsyaulity he in their minds and matter of mystimalsing of itplupetin
    ğŸŒ¡ï¸ temperature: 1.2
y he in their minds and matter of mystimalsing of itplupeting.t his asserated approysely to special,
are devial.; the finerevings
in orieicalous also mistakeng time, a :     this
benurion and
european voightry
ands centuries: it problem as place into the errords for triubtly etsibints, vetter after distrinitionn, where it lacking sole .=-vow accorded.

12u borany utmansishe and diffire being savest his
cardij(l qualition. neeked upon this
essentially, his 
--------------------
</code></pre>
<p>åˆ©ç”¨æ›´å¤šçš„æ•°æ®è®­ç»ƒæ›´å¤§çš„æ¨¡å‹ï¼Œè®­ç»ƒæ—¶é—´æ›´é•¿ï¼Œç”Ÿæˆçš„æ ·æœ¬ä¼šæ›´è¿è´¯ã€æ›´çœŸå®ã€‚ä½†æ˜¯ï¼Œè¿™æ ·ç”Ÿæˆçš„æ–‡æœ¬å¹¶æ²¡æœ‰ä»»ä½•æ„ä¹‰ã€‚æœºå™¨æ‰€åšçš„ä»…ä»…æ˜¯ä»ç»Ÿè®¡æ¨¡å‹ä¸­å¯¹æ•°æ®è¿›è¡Œé‡‡æ ·ï¼Œå®ƒå¹¶æ²¡æœ‰ç†è§£äººç±»çš„è¯­è¨€ï¼Œä¹Ÿä¸çŸ¥é“è‡ªå·±åœ¨è¯´ä»€ä¹ˆã€‚</p>
<h3 id="é™„åŸºäºè¯åµŒå…¥çš„æ–‡æœ¬ç”Ÿæˆ"><a class="markdownIt-Anchor" href="#é™„åŸºäºè¯åµŒå…¥çš„æ–‡æœ¬ç”Ÿæˆ"></a> é™„ï¼šåŸºäºè¯åµŒå…¥çš„æ–‡æœ¬ç”Ÿæˆ</h3>
<p>å¦‚æœè¦ç”Ÿæˆä¸­æ–‡æ–‡æœ¬ï¼Œæˆ‘ä»¬çš„æ±‰å­—å¤ªå¤šäº†ï¼Œé€å­—ç¬¦å»åšæˆ‘è®¤ä¸ºä¸æ˜¯å¾ˆå¥½çš„é€‰æ‹©ã€‚æ‰€ä»¥å¯ä»¥è€ƒè™‘åŸºäºè¯åµŒå…¥æ¥ç”Ÿæˆæ–‡æœ¬ã€‚åœ¨ä¹‹å‰çš„å­—ç¬¦çº§ LSTM æ–‡æœ¬ç”Ÿæˆçš„åŸºç¡€ä¸Šï¼Œå°†ç¼–ç /è§£ç æ–¹å¼ç¨ä½œä¿®æ”¹ã€æ·»åŠ  Embedding å±‚å³å¯å®ç°ä¸€ä¸ªåˆçº§çš„åŸºäºè¯åµŒå…¥çš„æ–‡æœ¬ç”Ÿæˆï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> optimizers</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> jieba    <span class="comment"># ä½¿ç”¨ jieba åšä¸­æ–‡åˆ†è¯</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">"TF_CPP_MIN_LOG_LEVEL"</span>] = <span class="string">"3"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯¼å…¥æ–‡æœ¬</span></span><br><span class="line"></span><br><span class="line">path = <span class="string">'~/Desktop/txt_zh_cn.txt'</span></span><br><span class="line">text = open(path).read().lower()</span><br><span class="line">print(<span class="string">'Corpus length:'</span>, len(text))</span><br><span class="line"></span><br><span class="line"><span class="comment"># å°†æ–‡æœ¬åºåˆ—å‘é‡åŒ–</span></span><br><span class="line"></span><br><span class="line">maxlen = <span class="number">60</span>     <span class="comment"># æ¯ä¸ªåºåˆ—çš„é•¿åº¦</span></span><br><span class="line">step = <span class="number">3</span>        <span class="comment"># æ¯ 3 ä¸ª token é‡‡æ ·ä¸€ä¸ªæ–°åºåˆ—</span></span><br><span class="line">sentences = []  <span class="comment"># ä¿å­˜æ‰€æå–çš„åºåˆ—</span></span><br><span class="line">next_tokens = []  <span class="comment"># sentences çš„ä¸‹ä¸€ä¸ª token</span></span><br><span class="line"></span><br><span class="line">token_text = list(jieba.cut(text))</span><br><span class="line"></span><br><span class="line">tokens = list(set(token_text))</span><br><span class="line">tokens_indices = &#123;token: tokens.index(token) <span class="keyword">for</span> token <span class="keyword">in</span> tokens&#125;</span><br><span class="line">print(<span class="string">'Number of tokens:'</span>, len(tokens))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(token_text) - maxlen, step):</span><br><span class="line">    sentences.append(</span><br><span class="line">        list(map(<span class="keyword">lambda</span> t: tokens_indices[t], token_text[i: i+maxlen])))</span><br><span class="line">    next_tokens.append(tokens_indices[token_text[i+maxlen]])</span><br><span class="line">print(<span class="string">'Number of sequences:'</span>, len(sentences))</span><br><span class="line"></span><br><span class="line"><span class="comment"># å°†ç›®æ ‡ one-hot ç¼–ç </span></span><br><span class="line">next_tokens_one_hot = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> next_tokens:</span><br><span class="line">    y = np.zeros((len(tokens),), dtype=np.bool)</span><br><span class="line">    y[i] = <span class="number">1</span></span><br><span class="line">    next_tokens_one_hot.append(y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åšæˆæ•°æ®é›†</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((sentences, next_tokens_one_hot))</span><br><span class="line">dataset = dataset.shuffle(buffer_size=<span class="number">4096</span>)</span><br><span class="line">dataset = dataset.batch(<span class="number">128</span>)</span><br><span class="line">dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># æ„å»ºã€ç¼–è¯‘æ¨¡å‹</span></span><br><span class="line"></span><br><span class="line">model = models.Sequential([</span><br><span class="line">    layers.Embedding(len(tokens), <span class="number">256</span>),</span><br><span class="line">    layers.LSTM(<span class="number">256</span>),</span><br><span class="line">    layers.Dense(len(tokens), activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">optimizer = optimizers.RMSprop(lr=<span class="number">0.1</span>)</span><br><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">              optimizer=optimizer)</span><br><span class="line"></span><br><span class="line"><span class="comment"># é‡‡æ ·å‡½æ•°</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(preds, temperature=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    å¯¹æ¨¡å‹å¾—åˆ°çš„åŸå§‹æ¦‚ç‡åˆ†å¸ƒé‡æ–°åŠ æƒï¼Œå¹¶ä»ä¸­æŠ½å–ä¸€ä¸ª token ç´¢å¼•</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    preds = np.asarray(preds).astype(<span class="string">'float64'</span>)</span><br><span class="line">    preds = np.log(preds) / temperature</span><br><span class="line">    exp_preds = np.exp(preds)</span><br><span class="line">    preds = exp_preds / np.sum(exp_preds)</span><br><span class="line">    probas = np.random.multinomial(<span class="number">1</span>, preds, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> np.argmax(probas)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒæ¨¡å‹</span></span><br><span class="line"></span><br><span class="line">callbacks_list = [</span><br><span class="line">    keras.callbacks.ModelCheckpoint(  <span class="comment"># åœ¨æ¯è½®å®Œæˆåä¿å­˜æƒé‡</span></span><br><span class="line">        filepath=<span class="string">'text_gen.h5'</span>,</span><br><span class="line">        monitor=<span class="string">'loss'</span>,</span><br><span class="line">        save_best_only=<span class="literal">True</span>,</span><br><span class="line">    ),</span><br><span class="line">    keras.callbacks.ReduceLROnPlateau(  <span class="comment"># ä¸å†æ”¹å–„æ—¶é™ä½å­¦ä¹ ç‡</span></span><br><span class="line">        monitor=<span class="string">'loss'</span>,</span><br><span class="line">        factor=<span class="number">0.5</span>,</span><br><span class="line">        patience=<span class="number">1</span>,</span><br><span class="line">    ),</span><br><span class="line">    keras.callbacks.EarlyStopping(  <span class="comment"># ä¸å†æ”¹å–„æ—¶ä¸­æ–­è®­ç»ƒ</span></span><br><span class="line">        monitor=<span class="string">'loss'</span>,</span><br><span class="line">        patience=<span class="number">3</span>,</span><br><span class="line">    ),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">model.fit(dataset, epochs=<span class="number">30</span>, callbacks=callbacks_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ–‡æœ¬ç”Ÿæˆ</span></span><br><span class="line"></span><br><span class="line">start_index = random.randint(<span class="number">0</span>, len(text) - maxlen - <span class="number">1</span>)</span><br><span class="line">generated_text = text[start_index: start_index + maxlen]</span><br><span class="line">print(<span class="string">f' ğŸ“– Generating with seed: "<span class="subst">&#123;generated_text&#125;</span>"'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> temperature <span class="keyword">in</span> [<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">1.2</span>]:</span><br><span class="line">    print(<span class="string">'\n  ğŸŒ¡ï¸ temperature:'</span>, temperature)</span><br><span class="line">    print(generated_text, end=<span class="string">''</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):    <span class="comment"># ç”Ÿæˆ 100 ä¸ª token</span></span><br><span class="line">        <span class="comment"># ç¼–ç å½“å‰æ–‡æœ¬</span></span><br><span class="line">        text_cut = jieba.cut(generated_text)</span><br><span class="line">        sampled = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> text_cut:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> tokens_indices:</span><br><span class="line">                sampled.append(tokens_indices[i])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                sampled.append(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># é¢„æµ‹ï¼Œé‡‡æ ·ï¼Œç”Ÿæˆä¸‹ä¸€ä¸ª token</span></span><br><span class="line">        preds = model.predict(sampled, verbose=<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">        next_index = sample(preds, temperature)</span><br><span class="line">        next_token = tokens[next_index]</span><br><span class="line">        print(next_token, end=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">        generated_text = generated_text[<span class="number">1</span>:] + next_token</span><br></pre></td></tr></table></figure>
<p>æˆ‘ç”¨ä¸€äº›é²è¿…çš„æ–‡ç« å»è®­ç»ƒï¼Œå¾—åˆ°çš„ç»“æœå¤§æ¦‚æ˜¯è¿™æ ·çš„ï¼š</p>
<blockquote>
<p>å¿˜å´ä¸€æ ·ï¼Œä½³ä½œæœ‰äº›è¿™å°±â€¦â€¦åœ¨æœªåº„ä¸€é˜µï¼Œä½†æ¸¸è¡—æ­£æ˜¯å€’ä¸å¦‚æ˜¯å‡ å¹´æ”»å‡»ç½¢ä¸€å †å»å†çš„æ˜¯æœ‰æ€•å°±å‡†çš„è¯æ˜¯æœªåº„æŒ‡ä¹Ÿæ·»æœªåº„ä¸æœ½å¤§å®¶ï¼™è½¬ï¼•ï¼Œå…¬å…±æœªåº„ä»–çš„ä»–äº†è™½ç„¶è¿˜æˆäº†ï¼Œä½†è±†ç§ä»–å¥³äººæ˜¯æœªåº„å¾ˆçš„çªœçš„å¯»ä¹Ÿçš„å¹¶æˆ‘â€”æ°´ç”Ÿæ˜¯ä½†æ”¶æ­£æ˜¯æœ¬ä½†å¤ªçˆ·ä¸¤ä¸ªè¦äº”æ˜¯å‡ ä¹å¤ªçˆ·ç»ˆäºç¡¬è¾«å­</p>
</blockquote>
<p>å¯ä»¥çœ‹åˆ°ï¼Œè¿™äº›å¥å­éƒ½è¯´ä¸é€šï¼Œçœ‹ç€å¾ˆéš¾å—ã€‚æ‰€ä»¥æˆ‘ä»¬è¿˜å¯ä»¥æŠŠåˆ† token çš„æ–¹æ³•æ”¹ä¸€æ”¹ï¼Œä¸æ˜¯åˆ†è¯ï¼Œè€Œæ˜¯å»åˆ†å¥å­ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">text = text.replace(<span class="string">'ï¼Œ'</span>, <span class="string">' ï¼Œ'</span>).replace(<span class="string">'ã€‚'</span>, <span class="string">' ã€‚'</span>).replace(<span class="string">'ï¼Ÿ'</span>, <span class="string">' ï¼Ÿ'</span>).replace(<span class="string">'ï¼š'</span>, <span class="string">' ï¼š'</span>)</span><br><span class="line">token_text = tf.keras.preprocessing.text.text_to_word_sequence(text, split=<span class="string">' '</span>)</span><br></pre></td></tr></table></figure>
<p>å…¶ä»–çš„åœ°æ–¹åŸºæœ¬ä¸å˜ï¼Œè¿™æ ·ä¹Ÿå¯ä»¥å¾—åˆ°æ¯”è¾ƒæœ‰æ„æ€çš„æ–‡æœ¬ã€‚æ¯”å¦‚è¿™æ˜¯æˆ‘ç”¨ä¸€äº›ä½™ç§‹é›¨çš„æ–‡ç« å»è®­ç»ƒçš„ç»“æœï¼š</p>
<blockquote>
<p>å‡ ä¸ªçŸ­è¡£äººç‰©ä¹Ÿå’Œä»–åŒååœ¨ä¸€å¤„è¿™è½¦ç«‹åˆ»èµ°åŠ¨äº†ï¼Œè´å£³å¤©æ°”è¿˜æ—©ï¼ŒèµŠäº†ä¸¤ç¢—é…’æ²¡æœ‰åƒè¿‡äººçš„å­©å­ï¼Œç±³è¦é’±ä¹°è¿™ä¸€ç‚¹ç²—æµ…äº‹æƒ…éƒ½ä¸çŸ¥é“â€¦â€¦å¤©æ°”è¿˜æ—©ä¸å¦¨äº‹ä¹ˆä»–â€¦â€¦å…¨å±‹å­éƒ½å¾ˆé™è¿™æ—¶çº¢é¼»å­è€æ‹±çš„å°æ›²ï¼Œè€Œä¸”åˆç ´è´¹äº†äºŒååƒçš„èµé’±ï¼Œä»–ä¸€å®šé¡»åœ¨å¤œé‡Œçš„åäºŒç‚¹é’Ÿæ‰å›å®¶ã€‚</p>
</blockquote>
<hr>
<p>By(â€œCDFMLRâ€, â€œ2020-08-20â€);</p>

  </div>
</article>
<!--Disqus-->


<!--Livere-->

    <div class="blog-post-comments">
        <div id="lv-container" data-id="city" data-uid="MTAyMC80NjEzMi8yMjY0Mw==">
            <noscript>ä¸å¯ç”¨ JavaScript æ”¯æŒçš„äººæ˜¯çœ‹ä¸åˆ°å¯çˆ±çš„è¯„è®ºåŒºçš„ã€‚ğŸ˜¥</noscript>
        </div>
    </div>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">é¦–é¡µ</a></li>
         
          <li><a href="/about/">å…³äº</a></li>
         
          <li><a href="/archives/">å½’æ¡£</a></li>
         
          <li><a href="https://github.com/cdfmlr">é¡¹ç›®</a></li>
         
          <li><a href="/search/">æœç´¢</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#deep-learning-with-python"><span class="toc-number">1.</span> <span class="toc-text"> Deep Learning with Python</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#81-text-generation-with-lstm"><span class="toc-number">1.1.</span> <span class="toc-text"> 8.1 Text generation with LSTM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#åºåˆ—æ•°æ®çš„ç”Ÿæˆ"><span class="toc-number">1.1.1.</span> <span class="toc-text"> åºåˆ—æ•°æ®çš„ç”Ÿæˆ</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#é‡‡æ ·ç­–ç•¥"><span class="toc-number">1.1.2.</span> <span class="toc-text"> é‡‡æ ·ç­–ç•¥</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#å­—ç¬¦çº§-lstm-æ–‡æœ¬ç”Ÿæˆå®ç°"><span class="toc-number">1.1.3.</span> <span class="toc-text"> å­—ç¬¦çº§ LSTM æ–‡æœ¬ç”Ÿæˆå®ç°</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#æ•°æ®å‡†å¤‡"><span class="toc-number">1.1.3.1.</span> <span class="toc-text"> æ•°æ®å‡†å¤‡</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#æ„å»ºç½‘ç»œ"><span class="toc-number">1.1.3.2.</span> <span class="toc-text"> æ„å»ºç½‘ç»œ</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#è®­ç»ƒè¯­è¨€æ¨¡å‹å¹¶ä»ä¸­é‡‡æ ·"><span class="toc-number">1.1.3.3.</span> <span class="toc-text"> è®­ç»ƒè¯­è¨€æ¨¡å‹å¹¶ä»ä¸­é‡‡æ ·</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#é™„åŸºäºè¯åµŒå…¥çš„æ–‡æœ¬ç”Ÿæˆ"><span class="toc-number">1.1.4.</span> <span class="toc-text"> é™„ï¼šåŸºäºè¯åµŒå…¥çš„æ–‡æœ¬ç”Ÿæˆ</span></a></li></ol></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&text=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&is_video=false&description=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ&body=Check out this article: https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&name=Pythonæ·±åº¦å­¦ä¹ ä¹‹LSTMæ–‡æœ¬ç”Ÿæˆ&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> èœå•</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> ç›®å½•</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> åˆ†äº«</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> è¿”å›é¡¶éƒ¨</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2020 CDFMLR
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">é¦–é¡µ</a></li>
         
          <li><a href="/about/">å…³äº</a></li>
         
          <li><a href="/archives/">å½’æ¡£</a></li>
         
          <li><a href="https://github.com/cdfmlr">é¡¹ç›®</a></li>
         
          <li><a href="/search/">æœç´¢</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css">

    <!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<!-- clipboard -->

  <script src="/lib/clipboard/clipboard.min.js"></script>
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"å¤åˆ¶åˆ°ç²˜è´´æ¿!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight .code pre").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      target: function(trigger) {
        return trigger.nextElementSibling;
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "å¤åˆ¶æˆåŠŸ!");
      e.clearSelection();
    })
  })
  </script>

<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-146911386-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Baidu Analytics -->

    <script type="text/javascript">
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?9a0d2e6fde93dad496ac79f04f3aba97";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

<!-- Disqus Comments -->


<!--Livere Comments-->

    <script type="text/javascript">
      (function (d, s) {
        var j, e = d.getElementsByTagName(s)[0];

        if (typeof LivereTower === 'function') { return; }

        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;

        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>

</body>
</html>
