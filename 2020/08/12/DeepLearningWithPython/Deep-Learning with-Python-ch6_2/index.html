<!DOCTYPE html>
<html lang=zh>
<head><meta name="generator" content="Hexo 3.9.0">
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="Deep Learning with Python è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘å­¦ä¹ ã€ŠDeep Learning with Pythonã€‹(ç¬¬äºŒç‰ˆï¼ŒFranÃ§ois Chollet è‘—) æ—¶å†™çš„ç³»åˆ—ç¬”è®°ä¹‹ä¸€ã€‚æ–‡ç« çš„å†…å®¹æ˜¯ä»  Jupyter notebooks è½¬æˆ Markdown çš„ï¼Œä½ å¯ä»¥å» GitHub æˆ– Gitee æ‰¾åˆ°åŸå§‹çš„ .ipynb ç¬”è®°æœ¬ã€‚ ä½ å¯ä»¥å»è¿™ä¸ªç½‘ç«™åœ¨çº¿é˜…è¯»è¿™æœ¬ä¹¦çš„æ­£ç‰ˆåŸæ–‡(è‹±æ–‡)">
<meta name="keywords" content="Machine Learning,Deep Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ">
<meta property="og:url" content="https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/index.html">
<meta property="og:site_name" content="clownote">
<meta property="og:description" content="Deep Learning with Python è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘å­¦ä¹ ã€ŠDeep Learning with Pythonã€‹(ç¬¬äºŒç‰ˆï¼ŒFranÃ§ois Chollet è‘—) æ—¶å†™çš„ç³»åˆ—ç¬”è®°ä¹‹ä¸€ã€‚æ–‡ç« çš„å†…å®¹æ˜¯ä»  Jupyter notebooks è½¬æˆ Markdown çš„ï¼Œä½ å¯ä»¥å» GitHub æˆ– Gitee æ‰¾åˆ°åŸå§‹çš„ .ipynb ç¬”è®°æœ¬ã€‚ ä½ å¯ä»¥å»è¿™ä¸ªç½‘ç«™åœ¨çº¿é˜…è¯»è¿™æœ¬ä¹¦çš„æ­£ç‰ˆåŸæ–‡(è‹±æ–‡)">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghgvghuih9j30iy0ict9s.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghh2b81pn9j31520j276a.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnskm7t47j30al07caac.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnskna7p7j30af07c74j.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghhebke5inj31p80rq78o.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnsko5b0pj30al07cdg3.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnskmosogj30al07cdg5.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnskl04gej30al07cjrn.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnsklsn9gj30af07cglv.jpg">
<meta property="og:updated_time" content="2020-09-11T13:53:58.185Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ">
<meta name="twitter:description" content="Deep Learning with Python è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘å­¦ä¹ ã€ŠDeep Learning with Pythonã€‹(ç¬¬äºŒç‰ˆï¼ŒFranÃ§ois Chollet è‘—) æ—¶å†™çš„ç³»åˆ—ç¬”è®°ä¹‹ä¸€ã€‚æ–‡ç« çš„å†…å®¹æ˜¯ä»  Jupyter notebooks è½¬æˆ Markdown çš„ï¼Œä½ å¯ä»¥å» GitHub æˆ– Gitee æ‰¾åˆ°åŸå§‹çš„ .ipynb ç¬”è®°æœ¬ã€‚ ä½ å¯ä»¥å»è¿™ä¸ªç½‘ç«™åœ¨çº¿é˜…è¯»è¿™æœ¬ä¹¦çš„æ­£ç‰ˆåŸæ–‡(è‹±æ–‡)">
<meta name="twitter:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghgvghuih9j30iy0ict9s.jpg">
    
    
        
          
              <link rel="shortcut icon" href="/images/rabbit.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/rabbit_192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/rabbit_180.png">
          
        
    
    <!-- title -->
    <title>Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss -->
    
    
    <!--Google search varification (PRIVATE)-->
    <meta name="google-site-verification" content="MrqlpFAD8nDanw3Ypv7ZsIWHLnTdhRuLa4QhSVwxIvc">
    <!--Google AdSense å…³è” (PRIVATE)-->
    <script data-ad-client="ca-pub-1510963483941114" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">é¦–é¡µ</a></li>
         
          <li><a href="/about/">å…³äº</a></li>
         
          <li><a href="/archives/">å½’æ¡£</a></li>
         
          <li><a href="https://github.com/cdfmlr">é¡¹ç›®</a></li>
         
          <li><a href="/search/">æœç´¢</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2020/08/13/DeepLearningWithPython/Deep-Learning with-Python-ch6_3/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2020/08/11/DeepLearningWithPython/Deep-Learning with-Python-ch6_1/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">ä¸Šä¸€ç¯‡</span>
      <span id="i-next" class="info" style="display:none;">ä¸‹ä¸€ç¯‡</span>
      <span id="i-top" class="info" style="display:none;">è¿”å›é¡¶éƒ¨</span>
      <span id="i-share" class="info" style="display:none;">åˆ†äº«æ–‡ç« </span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&text=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&is_video=false&description=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ&body=Check out this article: https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&name=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#deep-learning-with-python"><span class="toc-number">1.</span> <span class="toc-text"> Deep Learning with Python</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#62-understanding-recurrent-neural-networks"><span class="toc-number">1.1.</span> <span class="toc-text"> 6.2 Understanding recurrent neural networks</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#keras-ä¸­çš„å¾ªç¯å±‚"><span class="toc-number">1.1.1.</span> <span class="toc-text"> Keras ä¸­çš„å¾ªç¯å±‚</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#lstm-å±‚å’Œ-gru-å±‚"><span class="toc-number">1.1.1.1.</span> <span class="toc-text"> LSTM å±‚å’Œ GRU å±‚</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#keras-ä¸­ä½¿ç”¨-lstm"><span class="toc-number">1.1.1.2.</span> <span class="toc-text"> Keras ä¸­ä½¿ç”¨ LSTM</span></a></li></ol></li></ol></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">clownote</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2020-08-12T09:50:52.000Z" itemprop="datePublished">2020-08-12</time>
        
        (Updated: <time datetime="2020-09-11T13:53:58.185Z" itemprop="dateModified">2020-09-11</time>)
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/Machine-Learning/">Machine Learning</a> â€º <a class="category-link" href="/categories/Machine-Learning/Deep-Learning-with-Python/">Deep Learning with Python</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a>, <a class="tag-link" href="/tags/Machine-Learning/">Machine Learning</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h1 id="deep-learning-with-python"><a class="markdownIt-Anchor" href="#deep-learning-with-python"></a> Deep Learning with Python</h1>
<p>è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘å­¦ä¹ ã€ŠDeep Learning with Pythonã€‹(ç¬¬äºŒç‰ˆï¼ŒFranÃ§ois Chollet è‘—) æ—¶å†™çš„ç³»åˆ—ç¬”è®°ä¹‹ä¸€ã€‚æ–‡ç« çš„å†…å®¹æ˜¯ä»  Jupyter notebooks è½¬æˆ Markdown çš„ï¼Œä½ å¯ä»¥å» <a href="https://github.com/cdfmlr/Deep-Learning-with-Python-Notebooks" target="_blank" rel="noopener">GitHub</a> æˆ– <a href="https://gitee.com/cdfmlr/Deep-Learning-with-Python-Notebooks" target="_blank" rel="noopener">Gitee</a> æ‰¾åˆ°åŸå§‹çš„ <code>.ipynb</code> ç¬”è®°æœ¬ã€‚</p>
<p>ä½ å¯ä»¥å»<a href="https://livebook.manning.com/book/deep-learning-with-python" target="_blank" rel="noopener">è¿™ä¸ªç½‘ç«™åœ¨çº¿é˜…è¯»è¿™æœ¬ä¹¦çš„æ­£ç‰ˆåŸæ–‡</a>(è‹±æ–‡)ã€‚è¿™æœ¬ä¹¦çš„ä½œè€…ä¹Ÿç»™å‡ºäº†é…å¥—çš„ <a href="https://github.com/fchollet/deep-learning-with-python-notebooks" target="_blank" rel="noopener">Jupyter notebooks</a>ã€‚</p>
<p>æœ¬æ–‡ä¸º <strong>ç¬¬6ç«   æ·±åº¦å­¦ä¹ ç”¨äºæ–‡æœ¬å’Œåºåˆ—</strong> (Chapter 6. <em>Deep learning for text and sequences</em>) çš„ç¬”è®°ã€‚</p>
<p>[TOC]</p>
<h2 id="62-understanding-recurrent-neural-networks"><a class="markdownIt-Anchor" href="#62-understanding-recurrent-neural-networks"></a> 6.2 Understanding recurrent neural networks</h2>
<blockquote>
<p>ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ</p>
</blockquote>
<p>ä¹‹å‰æˆ‘ä»¬ç”¨çš„å…¨è¿æ¥ç½‘ç»œå’Œå·ç§¯ç¥ç»ç½‘ç»œéƒ½æœ‰æ˜¯è¢«å«åš feedforward networks (å‰é¦ˆç½‘ç»œ) çš„ã€‚è¿™ç§ç½‘ç»œæ˜¯æ— è®°å¿†çš„ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒä»¬å•ç‹¬å¤„ç†æ¯ä¸ªè¾“å…¥ï¼Œåœ¨è¾“å…¥ä¸è¾“å…¥ä¹‹é—´æ²¡æœ‰ä¿å­˜ä»»ä½•çŠ¶æ€ã€‚åœ¨è¿™ç§ç½‘ç»œä¸­ï¼Œæˆ‘ä»¬è¦å¤„ç†æ—¶é—´/æ–‡æœ¬ç­‰åºåˆ—ï¼Œå°±å¿…é¡»æŠŠä¸€ä¸ªå®Œæ•´çš„åºåˆ—å¤„ç†æˆä¸€ä¸ªå¤§å¼ é‡ï¼Œæ•´ä¸ªçš„ä¼ åˆ°ç½‘ç»œä¸­ï¼Œè®©æ¨¡å‹ä¸€æ¬¡çœ‹å®Œæ•´ä¸ªåºåˆ—ã€‚</p>
<p>è¿™ä¸ªæ˜¾ç„¶å’Œæˆ‘ä»¬äººç±»é˜…è¯»ã€å­¦ä¹ æ–‡æœ¬ç­‰ä¿¡æ¯çš„æ–¹å¼æœ‰æ‰€åŒºåˆ«ã€‚æˆ‘ä»¬ä¸æ˜¯ä¸€çœ¼çœ‹å®Œæ•´æœ¬ä¹¦çš„ï¼Œæˆ‘ä»¬è¦ä¸€ä¸ªè¯ä¸€ä¸ªè¯åœ°çœ‹ï¼Œçœ¼ç›ä¸åœç§»åŠ¨è·å–æ–°çš„æ•°æ®çš„åŒæ—¶ï¼Œè®°ä½ä¹‹å‰çš„å†…å®¹ï¼Œå°†æ–°çš„ã€æ—§çš„å†…å®¹è”ç³»åœ¨ä¸€èµ·æ¥ç†è§£æ•´å¥è¯çš„æ„æ€ã€‚è¯´æŠ½è±¡ä¸€äº›ï¼Œæˆ‘ä»¬ä¼šä¿å­˜ä¸€ä¸ªå…³äºæ‰€å¤„ç†å†…å®¹çš„å†…éƒ¨æ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹æ ¹æ®è¿‡å»çš„ä¿¡æ¯æ„å»ºï¼Œå¹¶éšç€æ–°ä¿¡æ¯çš„è¿›å…¥è€Œä¸æ–­æ›´æ–°ã€‚æˆ‘ä»¬éƒ½æ˜¯ä»¥è¿™ç§æ¸è¿›çš„æ–¹å¼å¤„ç†ä¿¡æ¯çš„ã€‚</p>
<p>æŒ‰ç…§è¿™ç§æ€æƒ³ï¼Œæˆ‘ä»¬åˆå¾—åˆ°ä¸€ç§æ–°çš„æ¨¡å‹ï¼Œå«åš<strong>å¾ªç¯ç¥ç»ç½‘ç»œ</strong>(recurrent neural network, RNN)ï¼Œè¿™ç½‘ç»œä¼šéå†å¤„ç†æ‰€æœ‰åºåˆ—å…ƒç´ ï¼Œå¹¶ä¿å­˜ä¸€ä¸ªè®°å½•å·²æŸ¥çœ‹å†…å®¹ç›¸å…³ä¿¡æ¯çš„çŠ¶æ€(state)ã€‚è€Œåœ¨å¤„ç†ä¸‹ä¸€æ¡åºåˆ—ä¹‹æ—¶ï¼ŒRNN çŠ¶æ€ä¼šè¢«é‡ç½®ã€‚ä½¿ç”¨ RNN æ—¶ï¼Œæˆ‘ä»¬ä»å¯ä»¥å°†ä¸€ä¸ªåºåˆ—æ•´ä¸ªçš„è¾“å‡ºç½‘ç»œï¼Œä¸è¿‡åœ¨ç½‘ç»œå†…éƒ¨ï¼Œæ•°æ®ä¸å†æ˜¯ç›´æ¥è¢«æ•´ä¸ªå¤„ç†ï¼Œè€Œæ˜¯è‡ªåŠ¨å¯¹åºåˆ—å…ƒç´ è¿›è¡Œéå†ã€‚</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghgvghuih9j30iy0ict9s.jpg" alt="å¾ªç¯ç½‘ç»œ:å¸¦æœ‰ç¯çš„ç½‘ç»œ"></p>
<p>ä¸ºäº†ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬ç”¨ Numpy æ‰‹å†™ä¸€ä¸ªç©å…·ç‰ˆçš„ RNN å‰å‘ä¼ é€’ã€‚è€ƒè™‘å¤„ç†å½¢çŠ¶ä¸º <code>(timesteps, input_features)</code> çš„ä¸€æ¡åºåˆ—ï¼ŒRNN åœ¨ timesteps ä¸Šåšè¿­ä»£ï¼Œå°†å½“å‰ timestep çš„ input_features ä¸å‰ä¸€æ­¥å¾—åˆ°çš„çŠ¶æ€ç»“åˆç®—å‡ºè¿™ä¸€æ­¥çš„è¾“å‡ºï¼Œç„¶åå°†è¿™ä¸ªè¾“å‡ºä¿å­˜ä¸ºæ–°çš„çŠ¶æ€ä¾›ä¸‹ä¸€æ­¥ä½¿ç”¨ã€‚ç¬¬ä¸€æ­¥æ—¶ï¼Œæ²¡æœ‰çŠ¶æ€ï¼Œå› æ­¤å°†çŠ¶æ€åˆå§‹åŒ–ä¸ºä¸€ä¸ªå…¨é›¶å‘é‡ï¼Œç§°ä¸ºç½‘ç»œçš„åˆå§‹çŠ¶æ€ã€‚</p>
<p>ä¼ªä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">state_t = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> input_t <span class="keyword">in</span> input_sequence:</span><br><span class="line">    output_t = f(input_t, state_t)</span><br><span class="line">    state_t = output_t</span><br></pre></td></tr></table></figure>
<p>è¿™é‡Œçš„ <code>f(...)</code> å…¶å®å’Œæˆ‘ä»¬çš„ Dense å±‚æ¯”è¾ƒç±»ä¼¼ï¼Œä½†è¿™é‡Œä¸ä»…å¤„ç†è¾“å‡ºï¼Œè¿˜è¦åŒæ—¶åŠ å…¥çŠ¶æ€çš„å½±å“ã€‚æ‰€ä»¥å®ƒå°±éœ€è¦åŒ…å« 3 ä¸ªå‚æ•°ï¼šåˆ†åˆ«ä½œç”¨ä¸è¾“å‡ºå’ŒçŠ¶æ€çš„çŸ©é˜µ Wã€Uï¼Œä»¥åŠåç§»å‘é‡ b:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(input_t, state_t)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> activation(</span><br><span class="line">        dot(W, input_t) + dot(U, state_t) + b</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>ç”»ä¸ªå›¾æ¥è¡¨ç¤ºè¿™ä¸ªç¨‹åºï¼š</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghh2b81pn9j31520j276a.jpg" alt="ä¸€ä¸ªç®€å•çš„ RNNï¼Œæ²¿æ—¶é—´å±•å¼€"></p>
<p>ä¸‹é¢æŠŠå®ƒå†™æˆçœŸå®çš„ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰å„ç§ç»´åº¦å¤§å°</span></span><br><span class="line">timesteps = <span class="number">100</span></span><br><span class="line">input_features = <span class="number">32</span></span><br><span class="line">output_features = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">inputs = np.random.random((timesteps, input_features))</span><br><span class="line"></span><br><span class="line">state_t = np.zeros((output_features))</span><br><span class="line"></span><br><span class="line">W = np.random.random((output_features, input_features))</span><br><span class="line">U = np.random.random((output_features, output_features))</span><br><span class="line">b = np.random.random((output_features))</span><br><span class="line"></span><br><span class="line">successive_outputs = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> input_t <span class="keyword">in</span> inputs:    <span class="comment"># input_t: (input_features, )</span></span><br><span class="line">    output_t = np.tanh(   <span class="comment"># output_t: (output_features, )</span></span><br><span class="line">        np.dot(W, input_t) + np.dot(U, state_t) + b</span><br><span class="line">    )</span><br><span class="line">    successive_outputs.append(output_t)</span><br><span class="line">    </span><br><span class="line">    state_t = output_t</span><br><span class="line">    </span><br><span class="line">final_output_sequence = np.stack(successive_outputs, axis=<span class="number">0</span>)  <span class="comment"># (timesteps, output_features)</span></span><br><span class="line"></span><br><span class="line">print(successive_outputs[<span class="number">-1</span>].shape)</span><br><span class="line">print(final_output_sequence.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(64,)
(100, 64)
</code></pre>
<p>åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æœ€ç»ˆè¾“å‡ºæ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º (timesteps, output_features) ï¼Œæ˜¯æ‰€æœ‰ timesteps çš„ç»“æœæ‹¼èµ·æ¥çš„ã€‚ä½†å®é™…ä¸Šï¼Œæˆ‘ä»¬ä¸€èˆ¬åªç”¨æœ€åä¸€ä¸ªç»“æœ <code>successive_outputs[-1]</code> å°±è¡Œäº†ï¼Œè¿™ä¸ªé‡Œé¢å·²ç»åŒ…å«äº†ä¹‹å‰æ‰€æœ‰æ­¥éª¤çš„ç»“æœï¼Œå³åŒ…å«äº†æ•´ä¸ªåºåˆ—çš„ä¿¡æ¯ã€‚</p>
<h3 id="keras-ä¸­çš„å¾ªç¯å±‚"><a class="markdownIt-Anchor" href="#keras-ä¸­çš„å¾ªç¯å±‚"></a> Keras ä¸­çš„å¾ªç¯å±‚</h3>
<p>æŠŠåˆšæ‰è¿™ä¸ªç©å…·ç‰ˆæœ¬å†åŠ å·¥ä¸€ä¸‹ï¼Œè®©å®ƒèƒ½æ¥æ”¶å½¢çŠ¶ä¸º <code>(batch_size, timesteps, input_features)</code> çš„è¾“å…¥ï¼Œæ‰¹é‡å»å¤„ç†ï¼Œå°±å¾—åˆ°äº† keras ä¸­çš„ <code>SimpleRNN</code> å±‚ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> SimpleRNN</span><br></pre></td></tr></table></figure>
<p>è¿™ä¸ª SimpleRNN å±‚å’Œ keras ä¸­çš„å…¶ä»–å¾ªç¯å±‚éƒ½æœ‰ä¸¤ç§å¯é€‰çš„è¾“å‡ºæ¨¡å¼ï¼š</p>
<table>
<thead>
<tr>
<th>è¾“å‡ºå½¢çŠ¶</th>
<th>è¯´æ˜</th>
<th>ä½¿ç”¨</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>(batch_size, timesteps, output_features)</code></td>
<td>è¾“å‡ºæ¯ä¸ª timestep è¾“å‡ºçš„å®Œæ•´åºåˆ—</td>
<td>return_sequences=True</td>
</tr>
<tr>
<td><code>(batch_size, output_features)</code></td>
<td>åªè¿”å›æ¯ä¸ªåºåˆ—çš„æœ€ç»ˆè¾“å‡º</td>
<td>return_sequences=False (é»˜è®¤)</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åªè¿”å›æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Embedding, SimpleRNN</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(<span class="number">10000</span>, <span class="number">32</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">32</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 32)          320000    
_________________________________________________________________
simple_rnn (SimpleRNN)       (None, 32)                2080      
=================================================================
Total params: 322,080
Trainable params: 322,080
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è¿”å›å®Œæ•´çš„çŠ¶æ€åºåˆ—</span></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(<span class="number">10000</span>, <span class="number">32</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">32</span>, return_sequences=<span class="literal">True</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_2&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_2 (Embedding)      (None, None, 32)          320000    
_________________________________________________________________
simple_rnn_2 (SimpleRNN)     (None, None, 32)          2080      
=================================================================
Total params: 322,080
Trainable params: 322,080
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<p>å¦‚æœæˆ‘ä»¬è¦å †å ä½¿ç”¨å¤šä¸ª RNN å±‚çš„æ—¶å€™ï¼Œä¸­é—´çš„å±‚å¿…é¡»è¿”å›å®Œæ•´çš„çŠ¶æ€åºåˆ—ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å †å å¤šä¸ª RNN å±‚ï¼Œä¸­é—´å±‚è¿”å›å®Œæ•´çš„çŠ¶æ€åºåˆ—</span></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(<span class="number">10000</span>, <span class="number">32</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">32</span>, return_sequences=<span class="literal">True</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">32</span>, return_sequences=<span class="literal">True</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">32</span>, return_sequences=<span class="literal">True</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">32</span>))    <span class="comment"># æœ€åä¸€å±‚è¦æœ€åä¸€ä¸ªè¾“å‡ºå°±è¡Œäº†</span></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_3&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_3 (Embedding)      (None, None, 32)          320000    
_________________________________________________________________
simple_rnn_3 (SimpleRNN)     (None, None, 32)          2080      
_________________________________________________________________
simple_rnn_4 (SimpleRNN)     (None, None, 32)          2080      
_________________________________________________________________
simple_rnn_5 (SimpleRNN)     (None, None, 32)          2080      
_________________________________________________________________
simple_rnn_6 (SimpleRNN)     (None, 32)                2080      
=================================================================
Total params: 328,320
Trainable params: 328,320
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°è¯•ç”¨ RNN å†æ¬¡å¤„ç† IMDB é—®é¢˜ã€‚é¦–å…ˆï¼Œå‡†å¤‡æ•°æ®ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å‡†å¤‡ IMDB æ•°æ®</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing <span class="keyword">import</span> sequence</span><br><span class="line"></span><br><span class="line">max_features = <span class="number">10000</span></span><br><span class="line">maxlen = <span class="number">500</span></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Loading data...'</span>)</span><br><span class="line">(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)</span><br><span class="line">print(len(input_train), <span class="string">'train sequences'</span>)</span><br><span class="line">print(len(input_test), <span class="string">'test sequences'</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Pad sequences (samples x time)'</span>)</span><br><span class="line">input_train = sequence.pad_sequences(input_train, maxlen=maxlen)</span><br><span class="line">input_test = sequence.pad_sequences(input_test, maxlen=maxlen)</span><br><span class="line">print(<span class="string">'input_train shape:'</span>, input_train.shape)</span><br><span class="line">print(<span class="string">'input_train shape:'</span>, input_test.shape)</span><br></pre></td></tr></table></figure>
<pre><code>Loading data...
25000 train sequences
25000 test sequences
Pad sequences (samples x time)
input_train shape: (25000, 500)
input_train shape: (25000, 500)
</code></pre>
<p>æ„å»ºå¹¶è®­ç»ƒç½‘ç»œï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç”¨ Embedding å±‚å’Œ SimpleRNN å±‚æ¥è®­ç»ƒæ¨¡å‹</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Embedding, SimpleRNN, Dense</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(max_features, <span class="number">32</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">32</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>, </span><br><span class="line">              loss=<span class="string">'binary_crossentropy'</span>, </span><br><span class="line">              metrics=[<span class="string">'acc'</span>])</span><br><span class="line">history = model.fit(input_train, y_train, </span><br><span class="line">                    epochs=<span class="number">10</span>, </span><br><span class="line">                    batch_size=<span class="number">128</span>, </span><br><span class="line">                    validation_split=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_4&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_4 (Embedding)      (None, None, 32)          320000    
_________________________________________________________________
simple_rnn_7 (SimpleRNN)     (None, 32)                2080      
_________________________________________________________________
dense (Dense)                (None, 1)                 33        
=================================================================
Total params: 322,113
Trainable params: 322,113
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
157/157 [==============================] - 17s 107ms/step - loss: 0.6445 - acc: 0.6106 - val_loss: 0.6140 - val_acc: 0.6676
Epoch 2/10
157/157 [==============================] - 20s 129ms/step - loss: 0.4139 - acc: 0.8219 - val_loss: 0.4147 - val_acc: 0.8194
Epoch 3/10
157/157 [==============================] - 20s 124ms/step - loss: 0.3041 - acc: 0.8779 - val_loss: 0.4529 - val_acc: 0.8012
Epoch 4/10
157/157 [==============================] - 18s 115ms/step - loss: 0.2225 - acc: 0.9151 - val_loss: 0.3957 - val_acc: 0.8572
Epoch 5/10
157/157 [==============================] - 18s 115ms/step - loss: 0.1655 - acc: 0.9391 - val_loss: 0.4416 - val_acc: 0.8246
Epoch 6/10
157/157 [==============================] - 17s 111ms/step - loss: 0.1167 - acc: 0.9601 - val_loss: 0.4614 - val_acc: 0.8606
Epoch 7/10
157/157 [==============================] - 17s 109ms/step - loss: 0.0680 - acc: 0.9790 - val_loss: 0.4754 - val_acc: 0.8408
Epoch 8/10
157/157 [==============================] - 15s 95ms/step - loss: 0.0419 - acc: 0.9875 - val_loss: 0.5337 - val_acc: 0.8352
Epoch 9/10
157/157 [==============================] - 16s 99ms/step - loss: 0.0246 - acc: 0.9935 - val_loss: 0.5796 - val_acc: 0.8468
Epoch 10/10
157/157 [==============================] - 15s 96ms/step - loss: 0.0174 - acc: 0.9952 - val_loss: 0.7274 - val_acc: 0.7968
</code></pre>
<p>ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹çœ‹çœ‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç»˜åˆ¶ç»“æœ</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">acc = history.history[<span class="string">'acc'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_acc'</span>]</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line"></span><br><span class="line">epochs = range(len(acc))</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo-'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'rs-'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo-'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'rs-'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnskm7t47j30al07caac.jpg" alt="png"></p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnskna7p7j30af07c74j.jpg" alt="png"></p>
<p>Emmmmï¼Œå…¶å®å§ï¼Œè¿™ä¸ªæ¨¡å‹çš„ç»“æœè¿˜æ²¡æœ‰ç¬¬ä¸‰ç« é‡Œé¢çš„ç”¨å‡ ä¸ªå…¨è¿æ¥å±‚å †å èµ·æ¥çš„æ¨¡å‹å¥½ã€‚åŸå› æœ‰å¥½å‡ ä¸ªï¼Œä¸€ä¸ªæ˜¯æˆ‘ä»¬è¿™é‡Œåªè€ƒè™‘äº†æ¯ä¸ªåºåˆ—çš„å‰ 500 ä¸ªå•è¯ï¼Œè¿˜æœ‰ä¸€ä¸ªæ˜¯ SimpleRNN å…¶å®å¹¶ä¸æ“…é•¿å¤„ç†å¾ˆé•¿çš„åºåˆ—ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä¼šçœ‹å‡ ä¸ªèƒ½è¡¨ç°çš„æ›´å¥½çš„å¾ªç¯å±‚ã€‚</p>
<h4 id="lstm-å±‚å’Œ-gru-å±‚"><a class="markdownIt-Anchor" href="#lstm-å±‚å’Œ-gru-å±‚"></a> LSTM å±‚å’Œ GRU å±‚</h4>
<p>åœ¨ Keras ä¸­çš„å¾ªç¯å±‚ï¼Œé™¤äº† SimpleRNNï¼Œè¿˜æœ‰æ›´â€œä¸simpleâ€ä¸€äº›çš„ LSTM å±‚å’Œ GRU å±‚ï¼Œåé¢è¿™ä¸¤ç§ä¼šæ›´å¸¸ç”¨ã€‚</p>
<p>SimpleRNN æ˜¯æœ‰ä¸€äº›é—®é¢˜çš„ï¼Œç†è®ºä¸Šï¼Œåœ¨éå†åˆ°æ—¶é—´æ­¥ t çš„æ—¶å€™ï¼Œå®ƒåº”è¯¥æ˜¯èƒ½ç•™å­˜ç€ä¹‹å‰è®¸å¤šæ­¥ä»¥æ¥è§è¿‡çš„ä¿¡æ¯çš„ï¼Œä½†å®é™…çš„åº”ç”¨ä¸­ï¼Œç”±äºæŸç§å«åš vanishing gradient problemï¼ˆæ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼‰çš„ç°è±¡ï¼Œå®ƒå¹¶ä¸èƒ½å­¦åˆ°è¿™ç§é•¿æœŸä¾èµ–ã€‚</p>
<p>æ¢¯åº¦æ¶ˆå¤±é—®é¢˜å…¶å®åœ¨å±‚æ•°æ¯”è¾ƒå¤šçš„å‰é¦ˆç½‘ç»œé‡Œé¢ä¹Ÿä¼šæœ‰å‘ç”Ÿï¼Œä¸»è¦è¡¨ç°å°±æ˜¯éšç€å±‚æ•°å¤šäº†ä¹‹åï¼Œç½‘ç»œæ— æ³•è®­ç»ƒäº†ã€‚LSTM å±‚å’Œ GRU å±‚å°±æ˜¯å¯¹æŠ—è¿™ç§é—®é¢˜è€Œç”Ÿçš„ã€‚</p>
<p><strong>LSTM</strong> å±‚æ˜¯åŸºäº LSTM (é•¿çŸ­æœŸè®°å¿†ï¼Œlong short-term memory) ç®—æ³•çš„ï¼Œè¿™ç®—æ³•å°±æ˜¯ä¸“é—¨ç ”ç©¶äº†å¤„ç†æ¢¯åº¦æ¶ˆå¤±é—®é¢˜çš„ã€‚å…¶å®å®ƒçš„æ ¸å¿ƒæ€æƒ³å°±æ˜¯è¦ä¿å­˜ä¿¡æ¯ä»¥ä¾¿åé¢ä½¿ç”¨ï¼Œé˜²æ­¢å‰é¢å¾—åˆ°çš„ä¿¡æ¯åœ¨åé¢çš„å¤„ç†ä¸­é€æ¸æ¶ˆå¤±ã€‚</p>
<p>LSTM åœ¨ SimpleRNN çš„åŸºç¡€ä¸Šï¼Œå¢åŠ äº†ä¸€ç§è·¨è¶Šå¤šä¸ªæ—¶é—´æ­¥ä¼ é€’ä¿¡æ¯çš„æ–¹æ³•ã€‚è¿™ä¸ªæ–°æ–¹æ³•åšçš„äº‹æƒ…å°±åƒä¸€æ¡åœ¨åºåˆ—æ—è¾¹çš„è¾…åŠ©ä¼ é€å¸¦ï¼Œåºåˆ—ä¸­çš„ä¿¡æ¯å¯ä»¥åœ¨ä»»æ„ä½ç½®è·³ä¸Šä¼ é€å¸¦ï¼Œ ç„¶åè¢«ä¼ é€åˆ°æ›´æ™šçš„æ—¶é—´æ­¥ï¼Œå¹¶åœ¨éœ€è¦æ—¶åŸå°ä¸åŠ¨åœ°è·³å›æ¥ã€‚</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghhebke5inj31p80rq78o.jpg" alt="å‰–æ LSTMï¼Œä» SimpleRNN åˆ° LSTM:æ·»åŠ ä¸€ä¸ªæºå¸¦è½¨é“"></p>
<p>è¿™é‡ŒæŠŠä¹‹å‰ SimpleRNN é‡Œé¢çš„æƒé‡ Wã€U é‡å‘½åä¸º Woã€Uo äº†ï¼ˆo è¡¨ç¤º outputï¼‰ã€‚ç„¶ååŠ äº†ä¸€ä¸ªâ€œæºå¸¦è½¨é“â€æ•°æ®æµï¼Œè¿™ä¸ªæºå¸¦è½¨é“å°±æ˜¯ç”¨æ¥æºå¸¦ä¿¡æ¯è·¨è¶Šæ—¶é—´æ­¥çš„ã€‚è¿™ä¸ªæºå¸¦è½¨é“ä¸Šé¢æ”¾ç€æ—¶é—´æ­¥ t çš„ ct ä¿¡æ¯ï¼ˆc è¡¨ç¤º carryï¼‰ï¼Œè¿™äº›ä¿¡æ¯å°†ä¸è¾“å…¥ã€çŠ¶æ€ä¸€èµ·è¿›è¡Œè¿ç®—ï¼Œè€Œå½±å“ä¼ é€’åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„çŠ¶æ€ï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">output_t = activation(dot(state_t, Uo) + dot(input_t, Wo) + dot(C_t, Vo) + bo)</span><br><span class="line"></span><br><span class="line">i_t = activation(dot(state_t, Ui) + dot(input_t, Wi) + bi)</span><br><span class="line">f_t = activation(dot(state_t, Uf) + dot(input_t, Wf) + bf)</span><br><span class="line">k_t = activation(dot(state_t, Uk) + dot(input_t, Wk) + bk)</span><br><span class="line"></span><br><span class="line">c_t_next = i_t * k_t + c_t * f_t</span><br></pre></td></tr></table></figure>
<p>å…³äº LSTM æ›´å¤šçš„ç»†èŠ‚ã€å†…éƒ¨å®ç°å°±ä¸ä»‹ç»äº†ã€‚å’±å®Œå…¨ä¸éœ€è¦ç†è§£å…³äº LSTM å•å…ƒçš„å…·ä½“æ¶æ„ï¼Œç†è§£è¿™ä¸œè¥¿å°±ä¸æ˜¯äººå¹²çš„äº‹ã€‚æˆ‘ä»¬åªéœ€è¦è®°ä½ LSTM å•å…ƒçš„ä½œç”¨: å…è®¸æŠŠè¿‡å»çš„ä¿¡æ¯ç¨åå†æ¬¡æ‹¿è¿›æ¥ç”¨ï¼Œä»è€Œå¯¹æŠ—æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚</p>
<p>(P.S. ä½œè€…è¯´è¿™é‡Œæ˜¯ç„å­¦ï¼Œä¿¡ä»–å°±è¡Œäº†ã€‚ğŸ¤ª Emmmï¼Œè¿™å¥æ˜¯æˆ‘èƒ¡ç¿»çš„ï¼ŒåŸè¯æ˜¯:â€œit may seem a bit arbitrary, but bear with me.â€)</p>
<p><strong>GRU</strong>ï¼ˆGated Recurrent Unit, é—¨æ§å¾ªç¯å•å…ƒï¼‰ï¼Œä¹¦ä¸Šæçš„æ¯”è¾ƒå°‘ï¼Œå‚è€ƒè¿™ç¯‡ ã€Š<a href="https://zhuanlan.zhihu.com/p/32481747" target="_blank" rel="noopener">äººäººéƒ½èƒ½çœ‹æ‡‚çš„GRU</a>ã€‹ï¼Œè¯´ GRU å¤§æ¦‚æ˜¯ LSTM çš„ä¸€ç§å˜ç§å§ï¼ŒäºŒè€…åŸç†åŒºåˆ«ä¸å¤§ã€å®é™…æ•ˆæœä¸Šä¹Ÿå·®ä¸å¤šã€‚ä½† GRU æ¯” LSTM æ–°ä¸€äº›ï¼Œå®ƒåšäº†ä¸€äº›ç®€åŒ–ï¼Œæ›´å®¹æ˜“è®¡ç®—ä¸€äº›ï¼Œä½†ç›¸åº”è¡¨ç¤ºèƒ½åŠ›å¯èƒ½ç¨å·®ä¸€ç‚¹ç‚¹ã€‚</p>
<h4 id="keras-ä¸­ä½¿ç”¨-lstm"><a class="markdownIt-Anchor" href="#keras-ä¸­ä½¿ç”¨-lstm"></a> Keras ä¸­ä½¿ç”¨ LSTM</h4>
<p>æˆ‘ä»¬è¿˜æ˜¯ç»§ç»­ç”¨ä¹‹å‰å¤„ç†å¥½çš„çš„ IMDB æ•°æ®æ¥è·‘ä¸€ä¸ª LSTMï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(max_features, <span class="number">32</span>))</span><br><span class="line">model.add(LSTM(<span class="number">32</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>, </span><br><span class="line">              loss=<span class="string">'binary_crossentropy'</span>, </span><br><span class="line">              metrics=[<span class="string">'acc'</span>])</span><br><span class="line"></span><br><span class="line">history = model.fit(input_train, y_train, </span><br><span class="line">                    epochs=<span class="number">10</span>, </span><br><span class="line">                    batch_size=<span class="number">128</span>, </span><br><span class="line">                    validation_split=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_5 (Embedding)      (None, None, 32)          320000    
_________________________________________________________________
lstm (LSTM)                  (None, 32)                8320      
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 33        
=================================================================
Total params: 328,353
Trainable params: 328,353
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
157/157 [==============================] - 37s 236ms/step - loss: 0.5143 - acc: 0.7509 - val_loss: 0.3383 - val_acc: 0.8672
Epoch 2/10
157/157 [==============================] - 37s 235ms/step - loss: 0.3010 - acc: 0.8834 - val_loss: 0.2817 - val_acc: 0.8862
Epoch 3/10
157/157 [==============================] - 34s 215ms/step - loss: 0.2357 - acc: 0.9129 - val_loss: 0.2766 - val_acc: 0.8876
Epoch 4/10
157/157 [==============================] - 34s 215ms/step - loss: 0.2062 - acc: 0.9255 - val_loss: 0.4392 - val_acc: 0.8310
Epoch 5/10
157/157 [==============================] - 34s 215ms/step - loss: 0.1762 - acc: 0.9360 - val_loss: 0.3078 - val_acc: 0.8670
Epoch 6/10
157/157 [==============================] - 34s 215ms/step - loss: 0.1575 - acc: 0.9436 - val_loss: 0.3293 - val_acc: 0.8902
Epoch 7/10
157/157 [==============================] - 35s 222ms/step - loss: 0.1419 - acc: 0.9506 - val_loss: 0.2993 - val_acc: 0.8898
Epoch 8/10
157/157 [==============================] - 39s 246ms/step - loss: 0.1277 - acc: 0.9546 - val_loss: 0.4179 - val_acc: 0.8234
Epoch 9/10
157/157 [==============================] - 35s 225ms/step - loss: 0.1199 - acc: 0.9585 - val_loss: 0.4391 - val_acc: 0.8434
Epoch 10/10
157/157 [==============================] - 34s 217ms/step - loss: 0.1113 - acc: 0.9615 - val_loss: 0.4926 - val_acc: 0.8614
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç»˜åˆ¶ç»“æœ</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">acc = history.history[<span class="string">'acc'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_acc'</span>]</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line"></span><br><span class="line">epochs = range(len(acc))</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo-'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'rs-'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo-'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'rs-'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnsko5b0pj30al07cdg3.jpg" alt="png"></p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnskmosogj30al07cdg5.jpg" alt="png"></p>
<p>æ¯” SimpleRNN å¥½å¤šäº†ã€‚ä½†ä¹Ÿæ²¡æ¯”ä»¥å‰é‚£ç§ç”¨å…¨è¿æ¥å±‚çš„ç½‘ç»œå¥½å¤šå°‘ï¼Œè€Œä¸”è¿˜æ¯”è¾ƒæ…¢(è®¡ç®—ä»£ä»·å¤§)ï¼Œå…¶å®ä¸»è¦æ˜¯ç”±äºæƒ…æ„Ÿåˆ†æè¿™æ ·çš„é—®é¢˜ï¼Œç”¨ LSTM å»åˆ†æå…¨å±€çš„é•¿æœŸæ€§ç»“æ„å¸®åŠ©å¹¶ä¸æ˜¯å¾ˆå¤§ï¼ŒLSTM æ“…é•¿çš„æ˜¯æ›´å¤æ‚çš„è‡ªç„¶è¯­è¨€å¤„ç†é—®é¢˜ï¼Œæ¯”å¦‚æœºå™¨ç¿»è¯‘ã€‚ç”¨å…¨è¿æ¥çš„æ–¹æ³•ï¼Œå…¶å®æ˜¯åšäº†çœ‹å‡ºç°äº†å“ªäº›è¯åŠå…¶å‡ºç°é¢‘ç‡ï¼Œè¿™ä¸ªå¯¹è¿™ç§ç®€å•é—®é¢˜è¿˜æ¯”è¾ƒæœ‰æ•ˆã€‚</p>
<p>ç„¶åï¼Œæˆ‘ä»¬å†è¯•è¯•ä¹¦ä¸Šæ²¡æçš„ GRUï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æŠŠ LSTM æ”¹æˆç”¨ GRU</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> GRU</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(max_features, <span class="number">32</span>))</span><br><span class="line">model.add(GRU(<span class="number">32</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>, </span><br><span class="line">              loss=<span class="string">'binary_crossentropy'</span>, </span><br><span class="line">              metrics=[<span class="string">'acc'</span>])</span><br><span class="line"></span><br><span class="line">history = model.fit(input_train, y_train, </span><br><span class="line">                    epochs=<span class="number">10</span>, </span><br><span class="line">                    batch_size=<span class="number">128</span>, </span><br><span class="line">                    validation_split=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç»˜åˆ¶ç»“æœ</span></span><br><span class="line"></span><br><span class="line">acc = history.history[<span class="string">'acc'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_acc'</span>]</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line"></span><br><span class="line">epochs = range(len(acc))</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo-'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'rs-'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo-'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'rs-'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_6&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_6 (Embedding)      (None, None, 32)          320000    
_________________________________________________________________
gru (GRU)                    (None, 32)                6336      
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 33        
=================================================================
Total params: 326,369
Trainable params: 326,369
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
157/157 [==============================] - 37s 238ms/step - loss: 0.5119 - acc: 0.7386 - val_loss: 0.3713 - val_acc: 0.8434
Epoch 2/10
157/157 [==============================] - 36s 232ms/step - loss: 0.2971 - acc: 0.8806 - val_loss: 0.3324 - val_acc: 0.8722
Epoch 3/10
157/157 [==============================] - 37s 235ms/step - loss: 0.2495 - acc: 0.9034 - val_loss: 0.3148 - val_acc: 0.8722
Epoch 4/10
157/157 [==============================] - 34s 217ms/step - loss: 0.2114 - acc: 0.9200 - val_loss: 0.3596 - val_acc: 0.8738
Epoch 5/10
157/157 [==============================] - 36s 231ms/step - loss: 0.1872 - acc: 0.9306 - val_loss: 0.5291 - val_acc: 0.8084
Epoch 6/10
157/157 [==============================] - 35s 226ms/step - loss: 0.1730 - acc: 0.9359 - val_loss: 0.3976 - val_acc: 0.8802
Epoch 7/10
157/157 [==============================] - 34s 217ms/step - loss: 0.1523 - acc: 0.9452 - val_loss: 0.4303 - val_acc: 0.8532
Epoch 8/10
157/157 [==============================] - 34s 217ms/step - loss: 0.1429 - acc: 0.9486 - val_loss: 0.4019 - val_acc: 0.8542
Epoch 9/10
157/157 [==============================] - 34s 217ms/step - loss: 0.1258 - acc: 0.9562 - val_loss: 0.3476 - val_acc: 0.8746
Epoch 10/10
157/157 [==============================] - 34s 216ms/step - loss: 0.1191 - acc: 0.9585 - val_loss: 0.3558 - val_acc: 0.8812
</code></pre>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnskl04gej30al07cjrn.jpg" alt="png"></p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnsklsn9gj30af07cglv.jpg" alt="png"></p>
<p>æ‰€ä»¥è¯´ï¼Œç»“æœåŒºåˆ«ä¸å¤§ã€‚</p>

  </div>
</article>
<!--Disqus-->


<!--Livere-->

    <div class="blog-post-comments">
        <div id="lv-container" data-id="city" data-uid="MTAyMC80NjEzMi8yMjY0Mw==">
            <noscript>ä¸å¯ç”¨ JavaScript æ”¯æŒçš„äººæ˜¯çœ‹ä¸åˆ°å¯çˆ±çš„è¯„è®ºåŒºçš„ã€‚ğŸ˜¥</noscript>
        </div>
    </div>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">é¦–é¡µ</a></li>
         
          <li><a href="/about/">å…³äº</a></li>
         
          <li><a href="/archives/">å½’æ¡£</a></li>
         
          <li><a href="https://github.com/cdfmlr">é¡¹ç›®</a></li>
         
          <li><a href="/search/">æœç´¢</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#deep-learning-with-python"><span class="toc-number">1.</span> <span class="toc-text"> Deep Learning with Python</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#62-understanding-recurrent-neural-networks"><span class="toc-number">1.1.</span> <span class="toc-text"> 6.2 Understanding recurrent neural networks</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#keras-ä¸­çš„å¾ªç¯å±‚"><span class="toc-number">1.1.1.</span> <span class="toc-text"> Keras ä¸­çš„å¾ªç¯å±‚</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#lstm-å±‚å’Œ-gru-å±‚"><span class="toc-number">1.1.1.1.</span> <span class="toc-text"> LSTM å±‚å’Œ GRU å±‚</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#keras-ä¸­ä½¿ç”¨-lstm"><span class="toc-number">1.1.1.2.</span> <span class="toc-text"> Keras ä¸­ä½¿ç”¨ LSTM</span></a></li></ol></li></ol></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&text=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&is_video=false&description=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ&body=Check out this article: https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://clownote.github.io/2020/08/12/DeepLearningWithPython/Deep-Learning with-Python-ch6_2/&name=Pythonæ·±åº¦å­¦ä¹ ä¹‹ç†è§£å¾ªç¯ç¥ç»ç½‘ç»œ&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> èœå•</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> ç›®å½•</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> åˆ†äº«</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> è¿”å›é¡¶éƒ¨</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2020 CDFMLR
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">é¦–é¡µ</a></li>
         
          <li><a href="/about/">å…³äº</a></li>
         
          <li><a href="/archives/">å½’æ¡£</a></li>
         
          <li><a href="https://github.com/cdfmlr">é¡¹ç›®</a></li>
         
          <li><a href="/search/">æœç´¢</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css">

    <!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<!-- clipboard -->

  <script src="/lib/clipboard/clipboard.min.js"></script>
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"å¤åˆ¶åˆ°ç²˜è´´æ¿!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight .code pre").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      target: function(trigger) {
        return trigger.nextElementSibling;
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "å¤åˆ¶æˆåŠŸ!");
      e.clearSelection();
    })
  })
  </script>

<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-146911386-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Baidu Analytics -->

    <script type="text/javascript">
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?9a0d2e6fde93dad496ac79f04f3aba97";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

<!-- Disqus Comments -->


<!--Livere Comments-->

    <script type="text/javascript">
      (function (d, s) {
        var j, e = d.getElementsByTagName(s)[0];

        if (typeof LivereTower === 'function') { return; }

        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;

        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>

</body>
</html>
