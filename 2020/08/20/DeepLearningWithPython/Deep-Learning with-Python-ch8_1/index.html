<!DOCTYPE html>
<html lang=zh>
<head><meta name="generator" content="Hexo 3.9.0">
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="Deep Learning with Python 这篇文章是我学习《Deep Learning with Python》(第二版，François Chollet 著) 时写的系列笔记之一。文章的内容是从  Jupyter notebooks 转成 Markdown 的，你可以去 GitHub 或 Gitee 找到原始的 .ipynb 笔记本。 你可以去这个网站在线阅读这本书的正版原文(英文)">
<meta name="keywords" content="Machine Learning,Deep Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Python深度学习之LSTM文本生成">
<meta property="og:url" content="https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/index.html">
<meta property="og:site_name" content="clownote">
<meta property="og:description" content="Deep Learning with Python 这篇文章是我学习《Deep Learning with Python》(第二版，François Chollet 著) 时写的系列笔记之一。文章的内容是从  Jupyter notebooks 转成 Markdown 的，你可以去 GitHub 或 Gitee 找到原始的 .ipynb 笔记本。 你可以去这个网站在线阅读这本书的正版原文(英文)">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghq58v9qd6j319c0ka41y.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghq692zm1nj316f0u0k9r.jpg">
<meta property="og:updated_time" content="2020-11-24T04:45:20.328Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python深度学习之LSTM文本生成">
<meta name="twitter:description" content="Deep Learning with Python 这篇文章是我学习《Deep Learning with Python》(第二版，François Chollet 著) 时写的系列笔记之一。文章的内容是从  Jupyter notebooks 转成 Markdown 的，你可以去 GitHub 或 Gitee 找到原始的 .ipynb 笔记本。 你可以去这个网站在线阅读这本书的正版原文(英文)">
<meta name="twitter:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghq58v9qd6j319c0ka41y.jpg">
    
    
        
          
              <link rel="shortcut icon" href="/images/rabbit.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/rabbit_192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/rabbit_180.png">
          
        
    
    <!-- title -->
    <title>Python深度学习之LSTM文本生成</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss -->
    
    
    <!--Google search varification (PRIVATE)-->
    <meta name="google-site-verification" content="MrqlpFAD8nDanw3Ypv7ZsIWHLnTdhRuLa4QhSVwxIvc">
    <!--Google AdSense 关联 (PRIVATE)-->
    <script data-ad-client="ca-pub-1510963483941114" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/about/">关于</a></li>
         
          <li><a href="/archives/">归档</a></li>
         
          <li><a href="https://github.com/cdfmlr">项目</a></li>
         
          <li><a href="/search/">搜索</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2020/08/21/DeepLearningWithPython/Deep-Learning with-Python-ch8_2/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2020/08/19/DeepLearningWithPython/Deep-Learning with-Python-ch7_3/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">上一篇</span>
      <span id="i-next" class="info" style="display:none;">下一篇</span>
      <span id="i-top" class="info" style="display:none;">返回顶部</span>
      <span id="i-share" class="info" style="display:none;">分享文章</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&text=Python深度学习之LSTM文本生成"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Python深度学习之LSTM文本生成"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&is_video=false&description=Python深度学习之LSTM文本生成"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Python深度学习之LSTM文本生成&body=Check out this article: https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Python深度学习之LSTM文本生成"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Python深度学习之LSTM文本生成"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Python深度学习之LSTM文本生成"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Python深度学习之LSTM文本生成"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&name=Python深度学习之LSTM文本生成&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#deep-learning-with-python"><span class="toc-number">1.</span> <span class="toc-text"> Deep Learning with Python</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#81-text-generation-with-lstm"><span class="toc-number">1.1.</span> <span class="toc-text"> 8.1 Text generation with LSTM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#序列数据的生成"><span class="toc-number">1.1.1.</span> <span class="toc-text"> 序列数据的生成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#采样策略"><span class="toc-number">1.1.2.</span> <span class="toc-text"> 采样策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#字符级-lstm-文本生成实现"><span class="toc-number">1.1.3.</span> <span class="toc-text"> 字符级 LSTM 文本生成实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#数据准备"><span class="toc-number">1.1.3.1.</span> <span class="toc-text"> 数据准备</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#构建网络"><span class="toc-number">1.1.3.2.</span> <span class="toc-text"> 构建网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#训练语言模型并从中采样"><span class="toc-number">1.1.3.3.</span> <span class="toc-text"> 训练语言模型并从中采样</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#附基于词嵌入的文本生成"><span class="toc-number">1.1.4.</span> <span class="toc-text"> 附：基于词嵌入的文本生成</span></a></li></ol></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Python深度学习之LSTM文本生成
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">clownote</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2020-08-20T11:21:34.000Z" itemprop="datePublished">2020-08-20</time>
        
        (Updated: <time datetime="2020-11-24T04:45:20.328Z" itemprop="dateModified">2020-11-24</time>)
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/Machine-Learning/">Machine Learning</a> › <a class="category-link" href="/categories/Machine-Learning/Deep-Learning-with-Python/">Deep Learning with Python</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a>, <a class="tag-link" href="/tags/Machine-Learning/">Machine Learning</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h1 id="deep-learning-with-python"><a class="markdownIt-Anchor" href="#deep-learning-with-python"></a> Deep Learning with Python</h1>
<p>这篇文章是我学习《Deep Learning with Python》(第二版，François Chollet 著) 时写的系列笔记之一。文章的内容是从  Jupyter notebooks 转成 Markdown 的，你可以去 <a href="https://github.com/cdfmlr/Deep-Learning-with-Python-Notebooks" target="_blank" rel="noopener">GitHub</a> 或 <a href="https://gitee.com/cdfmlr/Deep-Learning-with-Python-Notebooks" target="_blank" rel="noopener">Gitee</a> 找到原始的 <code>.ipynb</code> 笔记本。</p>
<p>你可以去<a href="https://livebook.manning.com/book/deep-learning-with-python" target="_blank" rel="noopener">这个网站在线阅读这本书的正版原文</a>(英文)。这本书的作者也给出了配套的 <a href="https://github.com/fchollet/deep-learning-with-python-notebooks" target="_blank" rel="noopener">Jupyter notebooks</a>。</p>
<p>本文为 <strong>第8章  生成式深度学习</strong> (Chapter 8. <em>Generative deep learning</em>) 的笔记之一。</p>
<p>[TOC]</p>
<h2 id="81-text-generation-with-lstm"><a class="markdownIt-Anchor" href="#81-text-generation-with-lstm"></a> 8.1 Text generation with LSTM</h2>
<blockquote>
<p>使用 LSTM 生成文本</p>
</blockquote>
<p>以前有人说过：“generating sequential data is the closest computers get to dreaming”，让计算机生成序列是很有魅力的事情。我们将以文本生成为例，探讨如何将循环神经网络用于生成序列数据。这项技术也可以用于音乐的生成、语音合成、聊天机器人对话生成、甚至是电影剧本的编写等等。</p>
<p>其实，我们现在熟知的 LSTM 算法，最早被开发出来的时候，就是用于逐字符地生成文本的。</p>
<h3 id="序列数据的生成"><a class="markdownIt-Anchor" href="#序列数据的生成"></a> 序列数据的生成</h3>
<p>用深度学习生成序列的通用方法，就是训练一个网络(一般用 RNN 或 CNN)，输入前面的 Token，预测序列中接下来的 Token。</p>
<p>说的术语化一些：给定前面的 Token，能够对下一个 Token 的概率进行建模的网络叫作「语言模型(language model)」。语言模型能够捕捉到语言的统计结构 ——「潜在空间(latent space)」。训练好一个语言模型，输入初始文本字符串（称为「条件数据」，conditioning data），从语言模型中采样，就可以生成新 Token，把新的 Token 加入条件数据中，再次输入，重复这个过程就可以生成出任意长度的序列。</p>
<p>我们从一个简单的例子开始：用一个 LSTM 层，输入文本语料的 N 个字符组成的字符串，训练模型来生成第 N+1 个字符。模型的输出是做 softmax，在所有可能的字符上，得到下一个字符的概率分布。这个模型叫作「字符级的神经语言模型」(character-level neural language model)。</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghq58v9qd6j319c0ka41y.jpg" alt="使用语言模型逐个字符生成文本的过程"></p>
<h3 id="采样策略"><a class="markdownIt-Anchor" href="#采样策略"></a> 采样策略</h3>
<p>使用字符级的神经语言模型生成文本时，最重要的问题是如何选择下一个字符。这里有几张常用方法：</p>
<ul>
<li>贪婪采样(greedy sampling)：始终选择可能性最大的下一个字符。这个方法很可能得到重复的、可预测的字符串，而且可能意思不连贯。（输入法联想）</li>
<li>纯随机采样：从均匀概率分布中抽取下一个字符，其中每个字符的概率相同。这样随机性太高，几乎不会生成出有趣的内容。（就是胡乱输出字符的组合）</li>
<li>随机采样(stochastic sampling)：根据语言模型的结果，如果下一个字符是 e 的概率为 0.3，那么你会有 30% 的概率选择它。有一点的随机性，让生成的内容更<s>随意</s>富有变化，但又不是完全随机，输出可以比较有意思。</li>
</ul>
<p>随机采样看上去很好，很有创造性，但有个问题是无法控制随机性的大小：随机性越大，可能富有创造性，但可能胡乱输出；随机性越小，可能更接近真实词句，但太死板、可预测。</p>
<p>为了在采样过程中控制随机性的大小，引入一个参数：「softmax 温度」(softmax temperature)，用于表示采样概率分布的熵，即表示所选择的下一个字符会有多么出人意料或多么可预测：</p>
<ul>
<li>更高的温度：熵更大的采样分布，会生成更加出人意料、更加无结构的数据；</li>
<li>更低的温度：对应更小的随机性，会生成更加可预测的数据。</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghq692zm1nj316f0u0k9r.jpg" alt="对同一个概率分布进行不同的重新加权：更低的温度=更确定，更高的温度=更随机"></p>
<p>具体的实现是，给定 temperature 值，对模型的 softmax 输出重新加权，得到新的概率分布：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rewight_distribution</span><span class="params">(original_distributon, temperature=<span class="number">0.5</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    对于不同的 softmax 温度，对概率分布进行重新加权</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    distribution = np.log(original_distribution) / temperature</span><br><span class="line">    distribution = np.exp(distribution)</span><br><span class="line">    <span class="keyword">return</span> distribution / np.sum(distribution)</span><br></pre></td></tr></table></figure>
<h3 id="字符级-lstm-文本生成实现"><a class="markdownIt-Anchor" href="#字符级-lstm-文本生成实现"></a> 字符级 LSTM 文本生成实现</h3>
<p>理论就上面那些了，现在，我们要用 Keras 来实现字符级的 LSTM 文本生成了。</p>
<h4 id="数据准备"><a class="markdownIt-Anchor" href="#数据准备"></a> 数据准备</h4>
<p>首先，我们需要大量的文本数据(语料，corpus)来训练语言模型。可以去找足够大的一个或多个文本文件：维基百科、各种书籍等都可。这里我们选择用一些尼采的作品（英文译本），这样我们学习出来的语言模型将是有尼采的写作风格和主题的。（插：我，我以前自己写野生模型玩，都是用鲁迅😂）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载语料，并将其转换为全小写</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">path = keras.utils.get_file(</span><br><span class="line">    <span class="string">'nietzsche.txt'</span>, </span><br><span class="line">    origin=<span class="string">'https://s3.amazonaws.com/text-datasets/nietzsche.txt'</span>)</span><br><span class="line">text = open(path).read().lower()</span><br><span class="line">print(<span class="string">'Corpus length:'</span>, len(text))</span><br></pre></td></tr></table></figure>
<pre><code>/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
  return f(*args, **kwds)
/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
  return f(*args, **kwds)


Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt
606208/600901 [==============================] - 430s 709us/step
Corpus length: 600893
</code></pre>
<p>接下来，我们要把文本做成数据 (向量化)：从 text 里提取长度为 <code>maxlen</code> 的序列(序列之间存在部分重叠)，进行 one-hot 编码，然后打包成 <code>(sequences, maxlen, unique_characters)</code> 形状的。同时，还需要准备数组 <code>y</code>，包含对应的目标，即在每一个所提取的序列之后出现的字符(也是 one-hot 编码的)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将字符序列向量化</span></span><br><span class="line"></span><br><span class="line">maxlen = <span class="number">60</span>     <span class="comment"># 每个序列的长度</span></span><br><span class="line">step = <span class="number">3</span>        <span class="comment"># 每 3 个字符采样一个新序列</span></span><br><span class="line">sentences = []  <span class="comment"># 保存所提取的序列</span></span><br><span class="line">next_chars = [] <span class="comment"># sentences 的下一个字符</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(text) - maxlen, step):</span><br><span class="line">    sentences.append(text[i: i+maxlen])</span><br><span class="line">    next_chars.append(text[i+maxlen])</span><br><span class="line">print(<span class="string">'Number of sequences:'</span>, len(sentences))</span><br><span class="line"></span><br><span class="line">chars = sorted(list(set(text)))</span><br><span class="line">char_indices = dict((char, chars.index(char)) <span class="keyword">for</span> char <span class="keyword">in</span> chars)</span><br><span class="line"><span class="comment"># 插：上面这两行代码 6</span></span><br><span class="line">print(<span class="string">'Unique characters:'</span>, len(chars))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Vectorization...'</span>)</span><br><span class="line"></span><br><span class="line">x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)</span><br><span class="line">y = np.zeros((len(sentences), len(chars)), dtype=np.bool)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, sentence <span class="keyword">in</span> enumerate(sentences):</span><br><span class="line">    <span class="keyword">for</span> t, char <span class="keyword">in</span> enumerate(sentence):</span><br><span class="line">        x[i, t, char_indices[char]] = <span class="number">1</span></span><br><span class="line">    y[i, char_indices[next_chars[i]]] = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<pre><code>Number of sequences: 200278
Unique characters: 57
Vectorization...
</code></pre>
<h4 id="构建网络"><a class="markdownIt-Anchor" href="#构建网络"></a> 构建网络</h4>
<p>我们要用到的网络其实很简单，一个 LSTM 层 + 一个 softmax 激活的 Dense 层就可以了。其实并不一定要用 LSTM，用一维卷积层也是可以生成序列的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于预测下一个字符的单层 LSTM 模型</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> LSTM, Dense</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">128</span>, input_shape=(maxlen, len(chars))))</span><br><span class="line">model.add(Dense(len(chars), activation=<span class="string">'softmax'</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型编译配置</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line">optimizer = optimizers.RMSprop(lr=<span class="number">0.01</span>)</span><br><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">              optimizer=optimizer)</span><br></pre></td></tr></table></figure>
<h4 id="训练语言模型并从中采样"><a class="markdownIt-Anchor" href="#训练语言模型并从中采样"></a> 训练语言模型并从中采样</h4>
<p>给定一个语言模型和一个种子文本片段，就可以通过重复以下操作来生成新的文本：</p>
<ol>
<li>给定目前已有文本，从模型中得到下一个字符的概率分布；</li>
<li>根据某个温度对分布进行重新加权；</li>
<li>根据重新加权后的分布对下一个字符进行随机采样；</li>
<li>将新字符添加到文本末尾。</li>
</ol>
<p>在训练模型之前，我们先把「采样函数」写了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(preds, temperature=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    对模型得到的原始概率分布重新加权，并从中抽取一个字符索引</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    preds = np.asarray(preds).astype(<span class="string">'float64'</span>)</span><br><span class="line">    preds = np.log(preds) / temperature</span><br><span class="line">    exp_preds = np.exp(preds)</span><br><span class="line">    preds = exp_preds / np.sum(exp_preds)</span><br><span class="line">    probas = np.random.multinomial(<span class="number">1</span>, preds, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> np.argmax(probas)</span><br></pre></td></tr></table></figure>
<p>最后，再来训练并生成文本。我们在每轮完成后都使用一系列不同的温度值来生成文本，这样就可以看到，随着模型收敛，生成的文本如何变化，以及温度对采样策略的影响：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 文本生成循环</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">60</span>):    <span class="comment"># 训练 60 个轮次</span></span><br><span class="line">    print(<span class="string">f'👉\033[1;35m epoch <span class="subst">&#123;epoch&#125;</span> \033[0m'</span>)    <span class="comment"># print('epoch', epoch)</span></span><br><span class="line">    </span><br><span class="line">    model.fit(x, y,</span><br><span class="line">              batch_size=<span class="number">128</span>,</span><br><span class="line">              epochs=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    start_index = random.randint(<span class="number">0</span>, len(text) - maxlen - <span class="number">1</span>)</span><br><span class="line">    generated_text = text[start_index: start_index + maxlen]</span><br><span class="line">    print(<span class="string">f'  📖 Generating with seed: "\033[1;32;43m<span class="subst">&#123;generated_text&#125;</span>\033[0m"'</span>)    <span class="comment"># print(f' Generating with seed: "&#123;generated_text&#125;"')</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> temperature <span class="keyword">in</span> [<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">1.2</span>]:</span><br><span class="line">        print(<span class="string">f'\n   \033[1;36m 🌡️ temperature: <span class="subst">&#123;temperature&#125;</span>\033[0m'</span>)    <span class="comment"># print('\n  temperature:', temperature)</span></span><br><span class="line">        print(generated_text, end=<span class="string">''</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">400</span>):    <span class="comment"># 生成 400 个字符</span></span><br><span class="line">            <span class="comment"># one-hot 编码目前有的文本</span></span><br><span class="line">            sampled = np.zeros((<span class="number">1</span>, maxlen, len(chars)))</span><br><span class="line">            <span class="keyword">for</span> t, char <span class="keyword">in</span> enumerate(generated_text):</span><br><span class="line">                sampled[<span class="number">0</span>, t, char_indices[char]] = <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 预测，采样，生成下一字符</span></span><br><span class="line">            preds = model.predict(sampled, verbose=<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">            next_index = sample(preds, temperature)</span><br><span class="line">            next_char = chars[next_index]</span><br><span class="line">            print(next_char, end=<span class="string">''</span>)</span><br><span class="line">            </span><br><span class="line">            generated_text = generated_text[<span class="number">1</span>:] + next_char</span><br><span class="line">            </span><br><span class="line">    print(<span class="string">'\n'</span> + <span class="string">'-'</span> * <span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<pre><code>👉 epoch 1 
1565/1565 [==============================] - 170s 108ms/step - loss: 1.4089
  📖 Generating with seed: &quot;ary!--will at least be entitled to demand in return that
psy&quot;

    🌡️ temperature: 0.2
ary!--will at least be entitled to demand in return that
psychological senses of the the most comprehensed that is a sense of a perhaps the experience of the heart the present that the profound that the experience of the exploition and present that is a self and the present that is a more of the senses of a more and the sense of a more art and the the exploition and self-contempt of a perhaps the superiom and perhaps the contempt of the superiom and all th
    🌡️ temperature: 0.5
superiom and perhaps the contempt of the superiom and all the instance and plays place of comprehensed and so in morals and all the auther to present mettoral of the senses and fellines to have the conceive that the
possibility of the expendeness, the hasters as how to really expendened and
all that the forenies; and all the most consequently comes that the most constanter to constantering only all the expearated the expendeness is in the delight and one w
    🌡️ temperature: 1.0
l the expearated the expendeness is in the delight and one would be persists more and world, others which in the utility of the fellows
among and deceeth, virtuery, mode. one
soul the most conterrites and ly under that conservate to mapt of the own toweration here old taste inilt, the &quot;frew-well
to openhanss&quot;--and the way could easily hamint; becoming being, thrien himself, very deteruence who usked slaver and own scientification, of the eever,&quot; wand
undou
    🌡️ temperature: 1.2
ed slaver and own scientification, of the eever,&quot; wand
undoupible &quot;befost suldeces.&quot; it weim even astreated drwadged,
owing parits, word of hister&quot;
enocest.-
sychea, that that words in the savery: 
y allverowed&quot;, when and liqksis felling, them soperation of clentous
and blendiers.
the pleasrvation humiturring, likeford of feit-rum. i must &quot;nrightenmy,&quot; beneveral man.&quot; the goods-
the cerses is christrantss and lightence--not man goemin love,
frro-akem.y tix
--------------------
...
👉 epoch 30 
1565/1565 [==============================] - 452s 289ms/step - loss: 1.2692
  📖 Generating with seed: &quot;y system of morals, is that it is a
long constraint. in orde&quot;

    🌡️ temperature: 0.2
y system of morals, is that it is a
long constraint. in order to be stronger and according to the same the standand, as a men and sanctity, and all the sense of the strength to the sense of the strong the striving of the strong the striving of the sense of the same this consequently and something and in a man with the sense of the sense of the same the strong of the same the sense of the strength to the sense of the same the artist the strong more and the 
    🌡️ temperature: 0.5
to the sense of the same the artist the strong more and the intellectually in the called bet of the more of such as something of standand, the experience and profound, and in the delusions of the morality of the propeted and the more of a good and one has a sorts of the constitute in the same the religion
in the same the human condition, the old proper all this taste which seeming and the standand, and are to the person of the strength and the latten more 
    🌡️ temperature: 1.0
, and are to the person of the strength and the latten more matter, fith, niquet of nature of rove seemsion and proxible is itself, it has
 final &quot;genion&quot; in coptent,
and un so larmor, romant.

bicident, with which fur one remain echo of
called in this acqueis forceek of consciate convoled,
asceticilies
invaluable demardinatid.

          he in respons himons, which, a engliches bad hope feels these see,
fermines &quot;only he will&quot;n--as stapty pullens of bad a
    🌡️ temperature: 1.2
se see,
fermines &quot;only he will&quot;n--as stapty pullens of bad adaval inexcepning at the unvery in all, whose in--that is a power be many trainitg prtunce--by the crueled him is every
noble,
as he society of this
sneke viged, has to telless all juscallers. we megnant cominghik, as gray illow and of holy este, &quot;the knowing&quot; how videly upon the adventive. there is discived and it attine to jesubuc'--the .=--what
lived
a! iapower, profoundc: of himself, it is lie
--------------------
...
👉 epoch 59 
1565/1565 [==============================] - 173s 110ms/step - loss: 1.2279
  📖 Generating with seed: &quot;inward self-contempt, seek to get out of
the business, no ma&quot;

    🌡️ temperature: 0.2
inward self-contempt, seek to get out of
the business, no may be only and the ascetiably sense of the real and the sense of the more sense of the community of the moral and profound the way there is the sense of the most contempt of the spirit in a perceive, and the interpreting the sense of the world as it is the soul is the artist of the sense and the world as in the entire
complication of the world as it is the strong of the most profound to the world a
    🌡️ temperature: 0.5
orld as it is the strong of the most profound to the world as the self nowadays to me that all the artifure in the mother of significance of the roman and we are this from the strength of existing and faith enthurable to the discover of the contrain to
religious were and self-grades the world with the way to the present think there are also all the plato-pit firels made a weart for the person of the rank on a way of the ethical prombates, to reason of the 
    🌡️ temperature: 1.0
he rank on a way of the ethical prombates, to reason of the mortand: that pureon good lack as has refree, in a herore proposition is
pronounce
the last the reasonably book of will calued and vexeme, and no means mentary honour pertimate our new, conversations. it is that
the sense ciertably with our distins of the remare of counter that german &quot;miswome centurially instinct&quot; in course,.
 hsyaulity he in their minds and matter of mystimalsing of itplupetin
    🌡️ temperature: 1.2
y he in their minds and matter of mystimalsing of itplupeting.t his asserated approysely to special,
are devial.; the finerevings
in orieicalous also mistakeng time, a :     this
benurion and
european voightry
ands centuries: it problem as place into the errords for triubtly etsibints, vetter after distrinitionn, where it lacking sole .=-vow accorded.

12u borany utmansishe and diffire being savest his
cardij(l qualition. neeked upon this
essentially, his 
--------------------
</code></pre>
<p>利用更多的数据训练更大的模型，训练时间更长，生成的样本会更连贯、更真实。但是，这样生成的文本并没有任何意义。机器所做的仅仅是从统计模型中对数据进行采样，它并没有理解人类的语言，也不知道自己在说什么。</p>
<h3 id="附基于词嵌入的文本生成"><a class="markdownIt-Anchor" href="#附基于词嵌入的文本生成"></a> 附：基于词嵌入的文本生成</h3>
<p>如果要生成中文文本，我们的汉字太多了，逐字符去做我认为不是很好的选择。所以可以考虑基于词嵌入来生成文本。在之前的字符级 LSTM 文本生成的基础上，将编码/解码方式稍作修改、添加 Embedding 层即可实现一个初级的基于词嵌入的文本生成：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> optimizers</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> jieba    <span class="comment"># 使用 jieba 做中文分词</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">"TF_CPP_MIN_LOG_LEVEL"</span>] = <span class="string">"3"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入文本</span></span><br><span class="line"></span><br><span class="line">path = <span class="string">'~/Desktop/txt_zh_cn.txt'</span></span><br><span class="line">text = open(path).read().lower()</span><br><span class="line">print(<span class="string">'Corpus length:'</span>, len(text))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将文本序列向量化</span></span><br><span class="line"></span><br><span class="line">maxlen = <span class="number">60</span>     <span class="comment"># 每个序列的长度</span></span><br><span class="line">step = <span class="number">3</span>        <span class="comment"># 每 3 个 token 采样一个新序列</span></span><br><span class="line">sentences = []  <span class="comment"># 保存所提取的序列</span></span><br><span class="line">next_tokens = []  <span class="comment"># sentences 的下一个 token</span></span><br><span class="line"></span><br><span class="line">token_text = list(jieba.cut(text))</span><br><span class="line"></span><br><span class="line">tokens = list(set(token_text))</span><br><span class="line">tokens_indices = &#123;token: tokens.index(token) <span class="keyword">for</span> token <span class="keyword">in</span> tokens&#125;</span><br><span class="line">print(<span class="string">'Number of tokens:'</span>, len(tokens))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(token_text) - maxlen, step):</span><br><span class="line">    sentences.append(</span><br><span class="line">        list(map(<span class="keyword">lambda</span> t: tokens_indices[t], token_text[i: i+maxlen])))</span><br><span class="line">    next_tokens.append(tokens_indices[token_text[i+maxlen]])</span><br><span class="line">print(<span class="string">'Number of sequences:'</span>, len(sentences))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将目标 one-hot 编码</span></span><br><span class="line">next_tokens_one_hot = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> next_tokens:</span><br><span class="line">    y = np.zeros((len(tokens),), dtype=np.bool)</span><br><span class="line">    y[i] = <span class="number">1</span></span><br><span class="line">    next_tokens_one_hot.append(y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 做成数据集</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((sentences, next_tokens_one_hot))</span><br><span class="line">dataset = dataset.shuffle(buffer_size=<span class="number">4096</span>)</span><br><span class="line">dataset = dataset.batch(<span class="number">128</span>)</span><br><span class="line">dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建、编译模型</span></span><br><span class="line"></span><br><span class="line">model = models.Sequential([</span><br><span class="line">    layers.Embedding(len(tokens), <span class="number">256</span>),</span><br><span class="line">    layers.LSTM(<span class="number">256</span>),</span><br><span class="line">    layers.Dense(len(tokens), activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">optimizer = optimizers.RMSprop(lr=<span class="number">0.1</span>)</span><br><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">              optimizer=optimizer)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 采样函数</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(preds, temperature=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    对模型得到的原始概率分布重新加权，并从中抽取一个 token 索引</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    preds = np.asarray(preds).astype(<span class="string">'float64'</span>)</span><br><span class="line">    preds = np.log(preds) / temperature</span><br><span class="line">    exp_preds = np.exp(preds)</span><br><span class="line">    preds = exp_preds / np.sum(exp_preds)</span><br><span class="line">    probas = np.random.multinomial(<span class="number">1</span>, preds, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> np.argmax(probas)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"></span><br><span class="line">callbacks_list = [</span><br><span class="line">    keras.callbacks.ModelCheckpoint(  <span class="comment"># 在每轮完成后保存权重</span></span><br><span class="line">        filepath=<span class="string">'text_gen.h5'</span>,</span><br><span class="line">        monitor=<span class="string">'loss'</span>,</span><br><span class="line">        save_best_only=<span class="literal">True</span>,</span><br><span class="line">    ),</span><br><span class="line">    keras.callbacks.ReduceLROnPlateau(  <span class="comment"># 不再改善时降低学习率</span></span><br><span class="line">        monitor=<span class="string">'loss'</span>,</span><br><span class="line">        factor=<span class="number">0.5</span>,</span><br><span class="line">        patience=<span class="number">1</span>,</span><br><span class="line">    ),</span><br><span class="line">    keras.callbacks.EarlyStopping(  <span class="comment"># 不再改善时中断训练</span></span><br><span class="line">        monitor=<span class="string">'loss'</span>,</span><br><span class="line">        patience=<span class="number">3</span>,</span><br><span class="line">    ),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">model.fit(dataset, epochs=<span class="number">30</span>, callbacks=callbacks_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文本生成</span></span><br><span class="line"></span><br><span class="line">start_index = random.randint(<span class="number">0</span>, len(text) - maxlen - <span class="number">1</span>)</span><br><span class="line">generated_text = text[start_index: start_index + maxlen]</span><br><span class="line">print(<span class="string">f' 📖 Generating with seed: "<span class="subst">&#123;generated_text&#125;</span>"'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> temperature <span class="keyword">in</span> [<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">1.2</span>]:</span><br><span class="line">    print(<span class="string">'\n  🌡️ temperature:'</span>, temperature)</span><br><span class="line">    print(generated_text, end=<span class="string">''</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):    <span class="comment"># 生成 100 个 token</span></span><br><span class="line">        <span class="comment"># 编码当前文本</span></span><br><span class="line">        text_cut = jieba.cut(generated_text)</span><br><span class="line">        sampled = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> text_cut:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> tokens_indices:</span><br><span class="line">                sampled.append(tokens_indices[i])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                sampled.append(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 预测，采样，生成下一个 token</span></span><br><span class="line">        preds = model.predict(sampled, verbose=<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">        next_index = sample(preds, temperature)</span><br><span class="line">        next_token = tokens[next_index]</span><br><span class="line">        print(next_token, end=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">        generated_text = generated_text[<span class="number">1</span>:] + next_token</span><br></pre></td></tr></table></figure>
<p>我用一些鲁迅的文章去训练，得到的结果大概是这样的：</p>
<blockquote>
<p>忘却一样，佳作有些这就……在未庄一阵，但游街正是倒不如是几年攻击罢一堆去再的是有怕就准的话是未庄指也添未庄不朽大家９转５，公共未庄他的他了虽然还成了，但豆种他女人是未庄很的窜的寻也的并我—水生是但收正是本但太爷两个要五是几乎太爷终于硬辫子</p>
</blockquote>
<p>可以看到，这些句子都说不通，看着很难受。所以我们还可以把分 token 的方法改一改，不是分词，而是去分句子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">text = text.replace(<span class="string">'，'</span>, <span class="string">' ，'</span>).replace(<span class="string">'。'</span>, <span class="string">' 。'</span>).replace(<span class="string">'？'</span>, <span class="string">' ？'</span>).replace(<span class="string">'：'</span>, <span class="string">' ：'</span>)</span><br><span class="line">token_text = tf.keras.preprocessing.text.text_to_word_sequence(text, split=<span class="string">' '</span>)</span><br></pre></td></tr></table></figure>
<p>其他的地方基本不变，这样也可以得到比较有意思的文本。比如这是我用一些余秋雨的文章去训练的结果：</p>
<blockquote>
<p>几个短衣人物也和他同坐在一处这车立刻走动了，贝壳天气还早，赊了两碗酒没有吃过人的孩子，米要钱买这一点粗浅事情都不知道……天气还早不妨事么他……全屋子都很静这时红鼻子老拱的小曲，而且又破费了二十千的赏钱，他一定须在夜里的十二点钟才回家。</p>
</blockquote>
<hr>
<p>By(“CDFMLR”, “2020-08-20”);</p>

  </div>
</article>
<!--Disqus-->


<!--Livere-->

    <div class="blog-post-comments">
        <div id="lv-container" data-id="city" data-uid="MTAyMC80NjEzMi8yMjY0Mw==">
            <noscript>不启用 JavaScript 支持的人是看不到可爱的评论区的。😥</noscript>
        </div>
    </div>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/about/">关于</a></li>
         
          <li><a href="/archives/">归档</a></li>
         
          <li><a href="https://github.com/cdfmlr">项目</a></li>
         
          <li><a href="/search/">搜索</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#deep-learning-with-python"><span class="toc-number">1.</span> <span class="toc-text"> Deep Learning with Python</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#81-text-generation-with-lstm"><span class="toc-number">1.1.</span> <span class="toc-text"> 8.1 Text generation with LSTM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#序列数据的生成"><span class="toc-number">1.1.1.</span> <span class="toc-text"> 序列数据的生成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#采样策略"><span class="toc-number">1.1.2.</span> <span class="toc-text"> 采样策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#字符级-lstm-文本生成实现"><span class="toc-number">1.1.3.</span> <span class="toc-text"> 字符级 LSTM 文本生成实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#数据准备"><span class="toc-number">1.1.3.1.</span> <span class="toc-text"> 数据准备</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#构建网络"><span class="toc-number">1.1.3.2.</span> <span class="toc-text"> 构建网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#训练语言模型并从中采样"><span class="toc-number">1.1.3.3.</span> <span class="toc-text"> 训练语言模型并从中采样</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#附基于词嵌入的文本生成"><span class="toc-number">1.1.4.</span> <span class="toc-text"> 附：基于词嵌入的文本生成</span></a></li></ol></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&text=Python深度学习之LSTM文本生成"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Python深度学习之LSTM文本生成"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&is_video=false&description=Python深度学习之LSTM文本生成"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Python深度学习之LSTM文本生成&body=Check out this article: https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Python深度学习之LSTM文本生成"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Python深度学习之LSTM文本生成"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Python深度学习之LSTM文本生成"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&title=Python深度学习之LSTM文本生成"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://clownote.github.io/2020/08/20/DeepLearningWithPython/Deep-Learning with-Python-ch8_1/&name=Python深度学习之LSTM文本生成&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> 菜单</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> 目录</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> 分享</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> 返回顶部</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2020 CDFMLR
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/about/">关于</a></li>
         
          <li><a href="/archives/">归档</a></li>
         
          <li><a href="https://github.com/cdfmlr">项目</a></li>
         
          <li><a href="/search/">搜索</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css">

    <!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<!-- clipboard -->

  <script src="/lib/clipboard/clipboard.min.js"></script>
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"复制到粘贴板!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight .code pre").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      target: function(trigger) {
        return trigger.nextElementSibling;
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "复制成功!");
      e.clearSelection();
    })
  })
  </script>

<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-146911386-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Baidu Analytics -->

    <script type="text/javascript">
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?9a0d2e6fde93dad496ac79f04f3aba97";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

<!-- Disqus Comments -->


<!--Livere Comments-->

    <script type="text/javascript">
      (function (d, s) {
        var j, e = d.getElementsByTagName(s)[0];

        if (typeof LivereTower === 'function') { return; }

        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;

        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>

</body>
</html>
