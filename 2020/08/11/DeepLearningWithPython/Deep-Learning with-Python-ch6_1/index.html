<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="Deep Learning with Pythonè¿™ç¯‡æ–‡ç« æ˜¯æˆ‘å­¦ä¹ ã€ŠDeep Learning with Pythonã€‹(ç¬¬äºŒç‰ˆï¼ŒFranÃ§ois Chollet è‘—) æ—¶å†™çš„ç³»åˆ—ç¬”è®°ä¹‹ä¸€ã€‚æ–‡ç« çš„å†…å®¹æ˜¯ä»  Jupyter notebooks è½¬æˆ Markdown çš„ï¼Œä½ å¯ä»¥å» GitHub æˆ– Gitee æ‰¾åˆ°åŸå§‹çš„ .ipynb ç¬”è®°æœ¬ã€‚ ä½ å¯ä»¥å»è¿™ä¸ªç½‘ç«™åœ¨çº¿é˜…è¯»è¿™æœ¬ä¹¦çš„æ­£ç‰ˆåŸæ–‡(è‹±æ–‡)ã€‚è¿™">
<meta property="og:type" content="article">
<meta property="og:title" content="Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®">
<meta property="og:url" content="https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/index.html">
<meta property="og:site_name" content="clownote">
<meta property="og:description" content="Deep Learning with Pythonè¿™ç¯‡æ–‡ç« æ˜¯æˆ‘å­¦ä¹ ã€ŠDeep Learning with Pythonã€‹(ç¬¬äºŒç‰ˆï¼ŒFranÃ§ois Chollet è‘—) æ—¶å†™çš„ç³»åˆ—ç¬”è®°ä¹‹ä¸€ã€‚æ–‡ç« çš„å†…å®¹æ˜¯ä»  Jupyter notebooks è½¬æˆ Markdown çš„ï¼Œä½ å¯ä»¥å» GitHub æˆ– Gitee æ‰¾åˆ°åŸå§‹çš„ .ipynb ç¬”è®°æœ¬ã€‚ ä½ å¯ä»¥å»è¿™ä¸ªç½‘ç«™åœ¨çº¿é˜…è¯»è¿™æœ¬ä¹¦çš„æ­£ç‰ˆåŸæ–‡(è‹±æ–‡)ã€‚è¿™">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghek3mhp38j31320mg0v8.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1gheskpva1tj31fq0u0aeq.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghetlonkiij30i40lmmyf.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1gheu1p4zqdj316i046aau.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghmvtdmhl3j30af07cmxf.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghmvtbyf9tj30af07cglv.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghmvtd56u4j30af07c3yq.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghmvtcoi15j30af07cdg2.jpg">
<meta property="article:published_time" content="2020-08-11T15:00:52.000Z">
<meta property="article:modified_time" content="2021-02-18T09:40:06.670Z">
<meta property="article:author" content="CDFMLR">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghek3mhp38j31320mg0v8.jpg">
    
    
        
          
              <link rel="shortcut icon" href="/images/rabbit.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/rabbit_192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/rabbit_180.png">
          
        
    
    <!-- title -->
    <title>Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
      
<link rel="stylesheet" href="/css/rtl.css">

    
    <!-- rss -->
    
    
    <!--Google search varification (PRIVATE)-->
    <meta name="google-site-verification" content="MrqlpFAD8nDanw3Ypv7ZsIWHLnTdhRuLa4QhSVwxIvc" />
    <!--Google AdSense å…³è” (PRIVATE)-->
    <script data-ad-client="ca-pub-1510963483941114" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<meta name="generator" content="Hexo 5.3.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">é¦–é¡µ</a></li>
         
          <li><a href="/about/">å…³äº</a></li>
         
          <li><a href="/archives/">å½’æ¡£</a></li>
         
          <li><a target="_blank" rel="noopener" href="https://github.com/cdfmlr">é¡¹ç›®</a></li>
         
          <li><a href="/search/">æœç´¢</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2020/08/12/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_2/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2020/07/29/DeepLearningWithPython/Deep-Learning%20with-Python-ch5/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">ä¸Šä¸€ç¯‡</span>
      <span id="i-next" class="info" style="display:none;">ä¸‹ä¸€ç¯‡</span>
      <span id="i-top" class="info" style="display:none;">è¿”å›é¡¶éƒ¨</span>
      <span id="i-share" class="info" style="display:none;">åˆ†äº«æ–‡ç« </span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&text=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&is_video=false&description=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®&body=Check out this article: https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&name=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Deep-Learning-with-Python"><span class="toc-number">1.</span> <span class="toc-text">Deep Learning with Python</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1-Working-with-text-data"><span class="toc-number">1.1.</span> <span class="toc-text">6.1  Working with text data</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#n-grams-%E5%92%8C%E8%AF%8D%E8%A2%8B-bag-of-words"><span class="toc-number">1.1.1.</span> <span class="toc-text">n-grams å’Œè¯è¢‹(bag-of-words)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#one-hot-%E7%BC%96%E7%A0%81"><span class="toc-number">1.1.2.</span> <span class="toc-text">one-hot ç¼–ç </span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%8D%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.3.</span> <span class="toc-text">è¯åµŒå…¥</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A9%E7%94%A8-Embedding-%E5%B1%82%E5%AD%A6%E4%B9%A0%E8%AF%8D%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.3.1.</span> <span class="toc-text">åˆ©ç”¨ Embedding å±‚å­¦ä¹ è¯åµŒå…¥</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E8%AF%8D%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.3.2.</span> <span class="toc-text">ä½¿ç”¨é¢„è®­ç»ƒçš„è¯åµŒå…¥</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8E%E5%8E%9F%E5%A7%8B%E6%96%87%E6%9C%AC%E5%88%B0%E8%AF%8D%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.4.</span> <span class="toc-text">ä»åŸå§‹æ–‡æœ¬åˆ°è¯åµŒå…¥</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD-IMDB-%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8E%9F%E5%A7%8B%E6%96%87%E6%9C%AC"><span class="toc-number">1.1.4.1.</span> <span class="toc-text">ä¸‹è½½ IMDB æ•°æ®çš„åŸå§‹æ–‡æœ¬</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%88%86%E8%AF%8D"><span class="toc-number">1.1.4.2.</span> <span class="toc-text">å¯¹æ•°æ®è¿›è¡Œåˆ†è¯</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD-GloVe-%E8%AF%8D%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.4.3.</span> <span class="toc-text">ä¸‹è½½ GloVe è¯åµŒå…¥</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E5%B5%8C%E5%85%A5%E8%BF%9B%E8%A1%8C%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.1.4.4.</span> <span class="toc-text">å¯¹åµŒå…¥è¿›è¡Œé¢„å¤„ç†</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.4.5.</span> <span class="toc-text">å®šä¹‰æ¨¡å‹</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8A%8A-GloVe-%E8%AF%8D%E5%B5%8C%E5%85%A5%E5%8A%A0%E8%BD%BD%E8%BF%9B%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.4.6.</span> <span class="toc-text">æŠŠ GloVe è¯åµŒå…¥åŠ è½½è¿›æ¨¡å‹</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E4%B8%8E%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.4.7.</span> <span class="toc-text">è®­ç»ƒä¸è¯„ä¼°æ¨¡å‹</span></a></li></ol></li></ol></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">clownote</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2020-08-11T15:00:52.000Z" itemprop="datePublished">2020-08-11</time>
        
        (Updated: <time datetime="2021-02-18T09:40:06.670Z" itemprop="dateModified">2021-02-18</time>)
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/Machine-Learning/">Machine Learning</a> â€º <a class="category-link" href="/categories/Machine-Learning/Deep-Learning-with-Python/">Deep Learning with Python</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a>, <a class="tag-link-link" href="/tags/Machine-Learning/" rel="tag">Machine Learning</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h1 id="Deep-Learning-with-Python"><a href="#Deep-Learning-with-Python" class="headerlink" title="Deep Learning with Python"></a>Deep Learning with Python</h1><p>è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘å­¦ä¹ ã€ŠDeep Learning with Pythonã€‹(ç¬¬äºŒç‰ˆï¼ŒFranÃ§ois Chollet è‘—) æ—¶å†™çš„ç³»åˆ—ç¬”è®°ä¹‹ä¸€ã€‚æ–‡ç« çš„å†…å®¹æ˜¯ä»  Jupyter notebooks è½¬æˆ Markdown çš„ï¼Œä½ å¯ä»¥å» <a target="_blank" rel="noopener" href="https://github.com/cdfmlr/Deep-Learning-with-Python-Notebooks">GitHub</a> æˆ– <a target="_blank" rel="noopener" href="https://gitee.com/cdfmlr/Deep-Learning-with-Python-Notebooks">Gitee</a> æ‰¾åˆ°åŸå§‹çš„ <code>.ipynb</code> ç¬”è®°æœ¬ã€‚</p>
<p>ä½ å¯ä»¥å»<a target="_blank" rel="noopener" href="https://livebook.manning.com/book/deep-learning-with-python">è¿™ä¸ªç½‘ç«™åœ¨çº¿é˜…è¯»è¿™æœ¬ä¹¦çš„æ­£ç‰ˆåŸæ–‡</a>(è‹±æ–‡)ã€‚è¿™æœ¬ä¹¦çš„ä½œè€…ä¹Ÿç»™å‡ºäº†é…å¥—çš„ <a target="_blank" rel="noopener" href="https://github.com/fchollet/deep-learning-with-python-notebooks">Jupyter notebooks</a>ã€‚</p>
<p>æœ¬æ–‡ä¸º <strong>ç¬¬6ç«   æ·±åº¦å­¦ä¹ ç”¨äºæ–‡æœ¬å’Œåºåˆ—</strong> (Chapter 6. <em>Deep learning for text and sequences</em>) çš„ç¬”è®°ã€‚</p>
<p>[TOC]</p>
<h2 id="6-1-Working-with-text-data"><a href="#6-1-Working-with-text-data" class="headerlink" title="6.1  Working with text data"></a>6.1  Working with text data</h2><blockquote>
<p>å¤„ç†æ–‡æœ¬æ•°æ®</p>
</blockquote>
<p>è¦ç”¨æ·±åº¦å­¦ä¹ çš„ç¥ç»ç½‘ç»œå¤„ç†æ–‡æœ¬æ•°æ®ï¼Œå’Œå›¾ç‰‡ç±»ä¼¼ï¼Œä¹Ÿè¦æŠŠæ•°æ®å‘é‡åŒ–ï¼šæ–‡æœ¬ -&gt; æ•°å€¼å¼ é‡ã€‚</p>
<p>è¦åšè¿™ç§äº‹æƒ…å¯ä»¥æŠŠæ¯ä¸ªå•è¯å˜æˆå‘é‡ï¼Œä¹Ÿå¯ä»¥æŠŠå­—ç¬¦å˜æˆå‘é‡ï¼Œè¿˜å¯ä»¥æŠŠå¤šä¸ªè¿ç»­å•è¯æˆ–å­—ç¬¦(ç§°ä¸º <em>N-grams</em>)å˜æˆå‘é‡ã€‚</p>
<p>åæ­£ä¸ç®¡å¦‚ä½•åˆ’åˆ†ï¼Œæˆ‘ä»¬æŠŠæ–‡æœ¬æ‹†åˆ†å‡ºæ¥çš„å•å…ƒå«åš <em>tokens</em>ï¼ˆæ ‡è®°ï¼‰ï¼Œæ‹†åˆ†æ–‡æœ¬çš„è¿‡ç¨‹å«åš <em>tokenization</em>(åˆ†è¯)ã€‚</p>
<blockquote>
<p>æ³¨ï¼štoken çš„ä¸­æ–‡ç¿»è¯‘æ˜¯â€œæ ‡è®°â€ğŸ˜‚ã€‚è¿™äº›ç¿»è¯‘éƒ½æ€ªæ€ªçš„ï¼Œè™½ç„¶ token ç¡®å®æœ‰æ ‡è®°è¿™ä¸ªæ„æ€ï¼Œä½†æŠŠè¿™é‡Œçš„ token ç¿»è¯‘æˆæ ‡è®°å°±æ²¡å†…å‘³å„¿äº†ã€‚æˆ‘è§‰å¾— token æ˜¯é‚£ç§ä»¥ä¸€ä¸ªä¸œè¥¿ä»£è¡¨å¦ä¸€ä¸ªä¸œè¥¿æ¥ä½¿ç”¨çš„æ„æ€ï¼Œè¿™ç§ token æ˜¯ä¸€ç§æœ‰å®ä½“çš„ä¸œè¥¿ï¼Œæ¯”å¦‚ä»£é‡‘åˆ¸ã€‚â€œæ ‡è®°â€è¿™ä¸ªè¯åœ¨å­—å…¸ä¸Šä½œåè¯æ˜¯ã€Œèµ·æ ‡ç¤ºä½œç”¨çš„è®°å·ã€çš„æ„æ€ï¼Œè€Œæˆ‘è§‰å¾—è®°å·ä¸æ˜¯ä¸ªå¾ˆå®ä½“çš„ä¸œè¥¿ã€‚ä»£é‡‘åˆ¸ä¸æ˜¯ä¸€ç§è®°å·ã€ä¹Ÿå°±èƒ½è¯´æ˜¯æ ‡è®°ï¼ŒåŒæ ·çš„ï¼Œè¿™é‡Œçš„ token ä¹Ÿæ˜¯ä¸€ç§å®ä½“çš„ä¸œè¥¿ï¼Œæˆ‘è§‰å¾—ä¸èƒ½æŠŠå®ƒè¯´æˆæ˜¯â€œæ ‡è®°â€ã€‚æˆ‘ä¸èµåŒè¿™ç§è¯‘æ³•ï¼Œæ‰€ä»¥ä¸‹æ–‡æ‰€æœ‰æ¶‰åŠ token çš„åœ°æ–¹ç»Ÿä¸€å†™æˆ â€œtokenâ€ï¼Œä¸ç¿»è¯‘æˆâ€œæ ‡è®°â€ã€‚</p>
</blockquote>
<p>æ–‡æœ¬çš„å‘é‡åŒ–å°±æ˜¯å…ˆä½œåˆ†è¯ï¼Œç„¶åæŠŠç”Ÿæˆå‡ºæ¥çš„ token é€ä¸ªä¸æ•°å€¼å‘é‡å¯¹åº”èµ·æ¥ï¼Œæœ€åæ‹¿å¯¹åº”çš„æ•°å€¼å‘é‡åˆæˆä¸€ä¸ªè¡¨è¾¾äº†åŸæ–‡æœ¬çš„å¼ é‡ã€‚å…¶ä¸­ï¼Œæ¯”è¾ƒæœ‰æ„æ€çš„æ˜¯å¦‚ä½•å»ºç«‹ token å’Œ æ•°å€¼å‘é‡ çš„è”ç³»ï¼Œä¸‹é¢ä»‹ç»ä¸¤ç§æè¿™ä¸ªçš„æ–¹æ³•ï¼šone-hot encoding(one-hotç¼–ç ) å’Œ token embedding(æ ‡è®°åµŒå…¥)ï¼Œå…¶ä¸­ token embedding ä¸€èˆ¬éƒ½ç”¨äºå•è¯ï¼Œå«ä½œè¯åµŒå…¥ã€Œword embeddingã€ã€‚</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghek3mhp38j31320mg0v8.jpg" alt="æ–‡æœ¬çš„å‘é‡åŒ–ï¼šä»æ–‡æœ¬åˆ°tokenå†åˆ°å¼ é‡"></p>
<h3 id="n-grams-å’Œè¯è¢‹-bag-of-words"><a href="#n-grams-å’Œè¯è¢‹-bag-of-words" class="headerlink" title="n-grams å’Œè¯è¢‹(bag-of-words)"></a>n-grams å’Œè¯è¢‹(bag-of-words)</h3><p>n-gram æ˜¯èƒ½ä»ä¸€ä¸ªå¥å­ä¸­æå–å‡ºçš„ â‰¤N ä¸ªè¿ç»­å•è¯çš„é›†åˆã€‚ä¾‹å¦‚ï¼šã€ŒThe cat sat on the mat.ã€</p>
<p>è¿™ä¸ªå¥å­åˆ†è§£æˆ 2-gram æ˜¯ï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;The&quot;, &quot;The cat&quot;, &quot;cat&quot;, &quot;cat sat&quot;, &quot;sat&quot;,</span><br><span class="line">  &quot;sat on&quot;, &quot;on&quot;, &quot;on the&quot;, &quot;the&quot;, &quot;the mat&quot;, &quot;mat&quot;&#125;</span><br></pre></td></tr></table></figure>
<p>è¿™ä¸ªé›†åˆè¢«å«åš bag-of-2-grams (äºŒå…ƒè¯­æ³•è¢‹)ã€‚</p>
<p>åˆ†è§£æˆ 3-gram æ˜¯ï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;The&quot;, &quot;The cat&quot;, &quot;cat&quot;, &quot;cat sat&quot;, &quot;The cat sat&quot;,</span><br><span class="line">  &quot;sat&quot;, &quot;sat on&quot;, &quot;on&quot;, &quot;cat sat on&quot;, &quot;on the&quot;, &quot;the&quot;,</span><br><span class="line">  &quot;sat on the&quot;, &quot;the mat&quot;, &quot;mat&quot;, &quot;on the mat&quot;&#125;</span><br></pre></td></tr></table></figure>
<p>è¿™ä¸ªé›†åˆè¢«å«åš bag-of-3-grams (ä¸‰å…ƒè¯­æ³•è¢‹)ã€‚</p>
<p>æŠŠè¿™ä¸œè¥¿å«åšã€Œè¢‹ã€æ˜¯å› ä¸ºå®ƒåªæ˜¯ tokens ç»„æˆçš„é›†åˆï¼Œæ²¡æœ‰åŸæ¥æ–‡æœ¬çš„é¡ºåºå’Œæ„ä¹‰ã€‚æŠŠæ–‡æœ¬åˆ†æˆè¿™ç§è¢‹çš„åˆ†è¯æ–¹æ³•å«åšã€Œè¯è¢‹(bag-of-words)ã€ã€‚</p>
<p>ç”±äºè¯è¢‹æ˜¯ä¸ä¿å­˜é¡ºåºçš„ï¼ˆåˆ†å‡ºæ¥æ˜¯é›†åˆï¼Œä¸æ˜¯åºåˆ—ï¼‰ï¼Œæ‰€ä»¥ä¸€èˆ¬ä¸åœ¨æ·±åº¦å­¦ä¹ é‡Œé¢ç”¨ã€‚ä½†åœ¨è½»é‡çº§çš„æµ…å±‚æ–‡æœ¬å¤„ç†æ¨¡å‹é‡Œé¢ï¼Œn-gram å’Œè¯è¢‹è¿˜æ˜¯å¾ˆé‡è¦çš„æ–¹æ³•çš„ã€‚</p>
<h3 id="one-hot-ç¼–ç "><a href="#one-hot-ç¼–ç " class="headerlink" title="one-hot ç¼–ç "></a>one-hot ç¼–ç </h3><p>one-hot æ˜¯æ¯”è¾ƒåŸºæœ¬ã€å¸¸ç”¨çš„ã€‚å…¶åšæ³•æ˜¯å°†æ¯ä¸ª token ä¸ä¸€ä¸ªå”¯ä¸€æ•´æ•°ç´¢å¼•å…³è”ï¼Œ ç„¶åå°†æ•´æ•°ç´¢å¼• i è½¬æ¢ä¸ºé•¿åº¦ä¸º N çš„äºŒè¿›åˆ¶å‘é‡(N æ˜¯è¯è¡¨å¤§å°)ï¼Œè¿™ä¸ªå‘é‡åªæœ‰ç¬¬ i ä¸ªå…ƒç´ ä¸º 1ï¼Œå…¶ä½™å…ƒç´ éƒ½ä¸º 0ã€‚</p>
<p>ä¸‹é¢ç»™å‡ºä¸¤ä¸ªç©å…·ç‰ˆæœ¬çš„ one-hot ç¼–ç ç¤ºä¾‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å•è¯çº§çš„ one-hot ç¼–ç </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">samples = [<span class="string">&#x27;The cat sat on the mat.&#x27;</span>, <span class="string">&#x27;The dog ate my homework.&#x27;</span>]</span><br><span class="line"></span><br><span class="line">token_index = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> sample <span class="keyword">in</span> samples:</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> sample.split():</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> token_index:</span><br><span class="line">            token_index[word] = <span class="built_in">len</span>(token_index) + <span class="number">1</span></span><br><span class="line">            </span><br><span class="line"><span class="comment"># å¯¹æ ·æœ¬è¿›è¡Œåˆ†è¯ã€‚åªè€ƒè™‘æ¯ä¸ªæ ·æœ¬å‰ max_length ä¸ªå•è¯</span></span><br><span class="line">max_length = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">results = np.zeros(shape=(<span class="built_in">len</span>(samples), </span><br><span class="line">                          max_length, </span><br><span class="line">                          <span class="built_in">max</span>(token_index.values()) + <span class="number">1</span>))</span><br><span class="line"><span class="keyword">for</span> i, sample <span class="keyword">in</span> <span class="built_in">enumerate</span>(samples):</span><br><span class="line">    <span class="keyword">for</span> j, word <span class="keyword">in</span> <span class="built_in">list</span>(<span class="built_in">enumerate</span>(sample.split()))[:max_length]:</span><br><span class="line">        index = token_index.get(word)</span><br><span class="line">        results[i, j, index] = <span class="number">1.</span></span><br><span class="line"></span><br><span class="line">print(results)</span><br></pre></td></tr></table></figure>
<pre><code>[[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]

 [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å­—ç¬¦çº§çš„ one-hot ç¼–ç </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"></span><br><span class="line">samples = [<span class="string">&#x27;The cat sat on the mat.&#x27;</span>, <span class="string">&#x27;The dog ate my homework.&#x27;</span>]</span><br><span class="line"></span><br><span class="line">characters = string.printable    <span class="comment"># æ‰€æœ‰å¯æ‰“å°çš„ ASCII å­—ç¬¦</span></span><br><span class="line">token_index = <span class="built_in">dict</span>(<span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(characters) + <span class="number">1</span>), characters))</span><br><span class="line"></span><br><span class="line">max_length = <span class="number">50</span></span><br><span class="line">results = np.zeros((<span class="built_in">len</span>(samples), max_length, <span class="built_in">max</span>(token_index.keys()) + <span class="number">1</span>))</span><br><span class="line"><span class="keyword">for</span> i, sample <span class="keyword">in</span> <span class="built_in">enumerate</span>(samples):</span><br><span class="line">    <span class="keyword">for</span> j, character <span class="keyword">in</span> <span class="built_in">enumerate</span>(sample):</span><br><span class="line">        index = token_index.get(character)</span><br><span class="line">        results[i, j, index] = <span class="number">1.</span></span><br><span class="line">        </span><br><span class="line">print(results)</span><br></pre></td></tr></table></figure>
<pre><code>[[[1. 1. 1. ... 1. 1. 1.]
  [1. 1. 1. ... 1. 1. 1.]
  [1. 1. 1. ... 1. 1. 1.]
  ...
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]]

 [[1. 1. 1. ... 1. 1. 1.]
  [1. 1. 1. ... 1. 1. 1.]
  [1. 1. 1. ... 1. 1. 1.]
  ...
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]]]</code></pre>
<p>Keras å†…ç½®äº†æ¯”åˆšæ‰å†™çš„è¿™ç§ç©å…·ç‰ˆæœ¬å¼ºå¤§å¾—å¤šçš„ one-hot ç¼–ç å·¥å…·ï¼Œåœ¨ç°å®ä½¿ç”¨ä¸­ï¼Œä½ åº”è¯¥ä½¿ç”¨è¿™ç§æ–¹æ³•ï¼Œè€Œä¸æ˜¯ä½¿ç”¨åˆšæ‰çš„ç©å…·ç‰ˆæœ¬ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"></span><br><span class="line">samples = [<span class="string">&#x27;The cat sat on the mat.&#x27;</span>, <span class="string">&#x27;The dog ate my homework.&#x27;</span>]</span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(num_words=<span class="number">1000</span>)    <span class="comment"># åªè€ƒè™‘å‰ 1000 ä¸ªæœ€å¸¸è§çš„å•è¯</span></span><br><span class="line">tokenizer.fit_on_texts(samples)</span><br><span class="line"></span><br><span class="line">sequences = tokenizer.texts_to_sequences(samples)    <span class="comment"># å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•´æ•°ç´¢å¼•ç»„æˆçš„åˆ—è¡¨</span></span><br><span class="line">print(<span class="string">&#x27;sequences:&#x27;</span>, sequences)</span><br><span class="line"></span><br><span class="line">one_hot_results = tokenizer.texts_to_matrix(samples, mode=<span class="string">&#x27;binary&#x27;</span>)  <span class="comment"># ç›´æ¥å¾—åˆ° one-hot äºŒè¿›åˆ¶è¡¨ç¤º</span></span><br><span class="line"></span><br><span class="line">word_index = tokenizer.word_index    <span class="comment"># å•è¯ç´¢å¼•ï¼Œå°±æ˜¯è¯è¡¨å­—å…¸å•¦ï¼Œç”¨è¿™ä¸ªå°±å¯ä»¥è¿˜åŸæ•°æ®</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;one_hot_results: shape=<span class="subst">&#123;one_hot_results.shape&#125;</span>:\n&#x27;</span>, one_hot_results, )</span><br><span class="line">print(<span class="string">f&#x27;Found <span class="subst">&#123;<span class="built_in">len</span>(word_index)&#125;</span> unique tokens.&#x27;</span>, <span class="string">&#x27;word_index:&#x27;</span>, word_index)</span><br></pre></td></tr></table></figure>
<pre><code>sequences: [[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]
one_hot_results: shape=(2, 1000):
 [[0. 1. 1. ... 0. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]]
Found 9 unique tokens. word_index: &#123;&#39;the&#39;: 1, &#39;cat&#39;: 2, &#39;sat&#39;: 3, &#39;on&#39;: 4, &#39;mat&#39;: 5, &#39;dog&#39;: 6, &#39;ate&#39;: 7, &#39;my&#39;: 8, &#39;homework&#39;: 9&#125;</code></pre>
<p>è¿™ç§ one-hot ç¼–ç è¿˜æœ‰ä¸€ç§ç®€å•çš„å˜ç§å«åš <em>one-hot hashing trick</em>ï¼ˆone-hot æ•£åˆ—æŠ€å·§ï¼‰ï¼Œè¿™ä¸ªæ–¹æ³•çš„æ€æƒ³æ˜¯ä¸å¯¹æ¯ä¸ª token å…³è”å”¯ä¸€çš„æ•´æ•°ç´¢å¼•ï¼Œè€Œæ˜¯ç”¨å“ˆå¸Œå‡½æ•°å»ä½œç”¨ï¼ŒæŠŠæ–‡æœ¬ç›´æ¥æ˜ å°„æˆä¸€ä¸ªå›ºå®šé•¿åº¦çš„å‘é‡ã€‚</p>
<p>ç”¨è¿™ç§æ–¹æ³•å¯ä»¥èŠ‚çœç»´æŠ¤å•è¯ç´¢å¼•çš„å†…å­˜å¼€é”€ï¼Œè¿˜å¯ä»¥å®ç°åœ¨çº¿ç¼–ç ï¼ˆæ¥ä¸€ä¸ªç¼–ç ä¸€ä¸ªï¼Œä¸å½±å“ä¹‹ã€ä¹‹åçš„ï¼‰ï¼›ä½†ä¹Ÿæœ‰ä¸€äº›å¼Šç«¯ï¼šå¯èƒ½å‡ºç°æ•£åˆ—å†²çªï¼Œç¼–ç åçš„æ•°æ®ä¹Ÿä¸èƒ½å¤Ÿè¿˜åŸã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä½¿ç”¨æ•£åˆ—æŠ€å·§çš„å•è¯çº§çš„ one-hot ç¼–ç ï¼Œç©å…·ç‰ˆæœ¬</span></span><br><span class="line"></span><br><span class="line">samples = [<span class="string">&#x27;The cat sat on the mat.&#x27;</span>, <span class="string">&#x27;The dog ate my homework.&#x27;</span>]</span><br><span class="line"></span><br><span class="line">dimensionality = <span class="number">1000</span>  <span class="comment"># å°†å•è¯ä¿å­˜ä¸ºé•¿åº¦ä¸º 1000 çš„å‘é‡ï¼Œå•è¯è¶Šå¤šè¿™ä¸ªå€¼å°±è¦è¶Šå¤§ï¼Œä¸ç„¶æ•£åˆ—å†²çªå¯èƒ½ä¼šåŠ å¤§</span></span><br><span class="line">max_length = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">results = np.zeros((<span class="built_in">len</span>(samples), max_length, dimensionality))</span><br><span class="line"><span class="keyword">for</span> i, sample <span class="keyword">in</span> <span class="built_in">enumerate</span>(samples):</span><br><span class="line">    <span class="keyword">for</span> j, word <span class="keyword">in</span> <span class="built_in">list</span>(<span class="built_in">enumerate</span>(sample.split()))[:max_length]:</span><br><span class="line">        index = <span class="built_in">abs</span>(<span class="built_in">hash</span>(word)) % dimensionality  <span class="comment"># å°†å•è¯æ•£åˆ—åˆ° 0~dimensionality èŒƒå›´å†…çš„ä¸€ä¸ªéšæœºæ•´æ•°ç´¢å¼•</span></span><br><span class="line">        results[i, j, index] = <span class="number">1.</span></span><br><span class="line"></span><br><span class="line">print(results.shape)</span><br><span class="line">print(results)</span><br></pre></td></tr></table></figure>
<pre><code>(2, 10, 1000)
[[[0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]
  ...
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]]

 [[0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]
  ...
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]]]</code></pre>
<h3 id="è¯åµŒå…¥"><a href="#è¯åµŒå…¥" class="headerlink" title="è¯åµŒå…¥"></a>è¯åµŒå…¥</h3><p>ä»å‰é¢çš„ä¾‹å­ä¸­ä¹Ÿå¯ä»¥çœ‹åˆ° one-hot çš„è¿™ç§ç¡¬ç¼–ç å¾—åˆ°çš„ç»“æœå‘é‡ååˆ†ç¨€ç–ï¼Œå¹¶ä¸”ç»´åº¦æ¯”è¾ƒé«˜ã€‚</p>
<p>è¯åµŒå…¥ï¼ˆword embeddingï¼‰æ˜¯å¦ä¸€ç§å°†å•è¯ä¸å‘é‡ç›¸å…³è”çš„å¸¸ç”¨æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•å¯ä»¥å¾—åˆ°æ¯” one-hot æ›´åŠ å¯†é›†ã€ä½ç»´çš„ç¼–ç ã€‚è¯åµŒå…¥çš„ç»“æœæ˜¯è¦ä»æ•°æ®ä¸­å­¦ä¹ å¾—åˆ°çš„ã€‚</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gheskpva1tj31fq0u0aeq.jpg" alt="one-hotç¼–ç ä¸è¯åµŒå…¥çš„åŒºåˆ«"></p>
<p>è¿ç”¨è¯åµŒå…¥æœ‰ä¸¤ç§æ–¹æ³•ï¼š</p>
<ol>
<li>åˆ©ç”¨ Embedding å±‚å­¦ä¹ è¯åµŒå…¥ï¼šåœ¨å®Œæˆç€æ‰‹è¿›è¡Œçš„ä¸»è¦ä»»åŠ¡(æ¯”å¦‚æ–‡æ¡£åˆ†ç±»æˆ–æƒ…æ„Ÿé¢„æµ‹)çš„åŒæ—¶å­¦ä¹ è¯åµŒå…¥ï¼šä¸€å¼€å§‹ä½¿ç”¨éšæœºçš„è¯å‘é‡ï¼Œç„¶åå¯¹è¯å‘é‡ç”¨ä¸å­¦ä¹ ç¥ç»ç½‘ç»œçš„æƒé‡ç›¸åŒçš„æ–¹æ³•è¿›è¡Œå­¦ä¹ ã€‚</li>
<li>åˆ©ç”¨é¢„è®­ç»ƒè¯åµŒå…¥(pretrained word embedding)ï¼šåœ¨ä¸åŒäºå¾…è§£å†³é—®é¢˜çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸Šé¢„è®­ç»ƒå¥½è¯åµŒå…¥ï¼Œç„¶åå°†å…¶åŠ è½½åˆ°æ¨¡å‹ä¸­ã€‚</li>
</ol>
<h4 id="åˆ©ç”¨-Embedding-å±‚å­¦ä¹ è¯åµŒå…¥"><a href="#åˆ©ç”¨-Embedding-å±‚å­¦ä¹ è¯åµŒå…¥" class="headerlink" title="åˆ©ç”¨ Embedding å±‚å­¦ä¹ è¯åµŒå…¥"></a>åˆ©ç”¨ Embedding å±‚å­¦ä¹ è¯åµŒå…¥</h4><p>ä¸€ä¸ªç†æƒ³çš„è¯åµŒå…¥ç©ºé—´åº”è¯¥æ˜¯å¯ä»¥æ¯”è¾ƒå®Œç¾åœ°æ˜ å°„äººç±»è¯­è¨€çš„ã€‚å®ƒæ˜¯æœ‰ç¬¦åˆç°å®çš„ç»“æ„çš„ï¼Œç›¸è¿‘çš„è¯åœ¨ç©ºé—´ä¸­å°±åº”è¯¥æ¯”è¾ƒæ¥è¿‘ï¼Œå¹¶ä¸”è¯åµŒå…¥ç©ºé—´ä¸­çš„æ–¹å‘ä¹Ÿæ˜¯è¦æœ‰æ„ä¹‰çš„ã€‚ä¾‹å¦‚ä¸€ä¸ªæ¯”è¾ƒç®€å•çš„ä¾‹å­ï¼š</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghetlonkiij30i40lmmyf.jpg" alt="è¯åµŒå…¥ç©ºé—´çš„ç®€å•ç¤ºä¾‹"></p>
<p>åœ¨è¿™ä¸ªè¯åµŒå…¥ç©ºé—´ä¸­ï¼Œå® ç‰©éƒ½åœ¨é ä¸‹çš„ä½ç½®ï¼Œé‡ç”ŸåŠ¨ç‰©éƒ½åœ¨é ä¸Šçš„ä½ç½®ï¼Œæ‰€ä»¥ä¸€ä¸ªä»ä¸‹åˆ°ä¸Šæ–¹å‘çš„å‘é‡å°±åº”è¯¥æ˜¯è¡¨ç¤ºä»å® ç‰©åˆ°é‡ç”ŸåŠ¨ç‰©çš„ï¼Œè¿™ä¸ªå‘é‡ä» cat åˆ° tiger æˆ–è€… dog -&gt; wolfã€‚ç±»ä¼¼çš„ï¼Œä¸€ä¸ªä»å·¦åˆ°å³çš„å‘é‡å¯ä»¥è§£é‡Šä¸ºä»çŠ¬ç§‘åˆ°çŒ«ç§‘ï¼Œè¿™ä¸ªå‘é‡å¯ä»¥ä» dog åˆ° catï¼Œæˆ–è€…ä» wolf åˆ° tigerã€‚</p>
<p>å†å¤æ‚ä¸€ç‚¹çš„ï¼Œæ¯”å¦‚è¦è¡¨ç¤ºè¯çš„æ€§åˆ«å…³ç³»ï¼Œå°† king å‘é‡åŠ ä¸Š female å‘é‡ï¼Œåº”è¯¥å¾—åˆ°çš„æ˜¯ queen å‘é‡ï¼Œè¿˜æœ‰å¤æ•°å…³ç³»ï¼šking + plural == kingsâ€¦â€¦</p>
<p>æ‰€ä»¥è¯´ï¼Œè¦æœ‰ä¸€ä¸ªè¿™æ ·å®Œç¾çš„è¯åµŒå…¥ç©ºé—´æ˜¯å¾ˆéš¾çš„ï¼Œç°åœ¨è¿˜æ²¡æœ‰ã€‚ä½†åˆ©ç”¨æ·±åº¦å­¦ä¹ ï¼Œæˆ‘ä»¬è¿˜æ˜¯å¯ä»¥å¾—åˆ°å¯¹äºç‰¹å®šé—®é¢˜æ¥è¯´æ¯”è¾ƒå¥½çš„è¯åµŒå…¥ç©ºé—´çš„ã€‚åœ¨ Keras ä½¿ä¸­ï¼Œæˆ‘ä»¬åªéœ€è¦è®©æ¨¡å‹å­¦ä¹ ä¸€ä¸ª Embedding å±‚çš„æƒé‡å°±å¯ä»¥å¾—åˆ°å¯¹å½“å‰ä»»åŠ¡çš„è¯åµŒå…¥ç©ºé—´ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Embedding</span><br><span class="line"></span><br><span class="line">embedding_layer = Embedding(<span class="number">1000</span>, <span class="number">64</span>)  <span class="comment"># Embedding(å¯èƒ½çš„tokenä¸ªæ•°, åµŒå…¥çš„ç»´åº¦)</span></span><br></pre></td></tr></table></figure>
<p>Embedding å±‚å…¶å®å°±ç›¸å½“äºæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå®ƒå°†ä¸€ä¸ªè¡¨ç¤ºç‰¹å®šå•è¯çš„æ•´æ•°ç´¢å¼•æ˜ å°„åˆ°ä¸€ä¸ªè¯å‘é‡ã€‚</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gheu1p4zqdj316i046aau.jpg" alt="Embedding å±‚"></p>
<p>Embedding å±‚çš„è¾“å…¥æ˜¯å½¢çŠ¶ä¸º <code>(samples, sequence_length)</code> çš„äºŒç»´æ•´æ•°å¼ é‡ã€‚è¿™ä¸ªè¾“å…¥å¼ é‡ä¸­çš„ä¸€ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªä»£è¡¨ä¸€ä¸ªæ–‡æœ¬åºåˆ—çš„æ•´æ•°åºåˆ—ï¼Œåº”è¯¥ä¿æŒè¾“å…¥çš„æ‰€æœ‰åºåˆ—é•¿åº¦ç›¸åŒï¼Œè¾ƒçŸ­çš„åºåˆ—åº”è¯¥ç”¨ 0 å¡«å……ï¼Œè¾ƒé•¿çš„åºåˆ—åº”è¯¥è¢«æˆªæ–­ã€‚</p>
<p>Embedding å±‚çš„è¾“å‡ºæ˜¯å½¢çŠ¶ä¸º <code>(samples, sequence_length, embedding_dimensionality)</code> çš„ä¸‰ç»´æµ®ç‚¹æ•°å¼ é‡ã€‚è¿™ä¸ªè¾“å‡ºå°±å¯ä»¥ç”¨ RNN æˆ–è€… Conv1D å»å¤„ç†åšå…¶ä»–äº‹æƒ…äº†ã€‚</p>
<p>Embedding å±‚ä¸€å¼€å§‹ä¹Ÿæ˜¯è¢«éšæœºåˆå§‹åŒ–çš„ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¼šåˆ©ç”¨åå‘ä¼ æ’­æ¥é€æ¸è°ƒèŠ‚è¯å‘é‡ã€æ”¹å˜ç©ºé—´ç»“æ„ï¼Œä¸€æ­¥æ­¥æ¥è¿‘æˆ‘ä»¬ä¹‹å‰æåˆ°çš„é‚£ç§ç†æƒ³çš„çŠ¶æ€ã€‚</p>
<p>å®ä¾‹ï¼šç”¨ Embedding å±‚å¤„ç† IMDB ç”µå½±è¯„è®ºæƒ…æ„Ÿé¢„æµ‹ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åŠ è½½ IMDB æ•°æ®ï¼Œå‡†å¤‡ç”¨äº Embedding å±‚</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> preprocessing</span><br><span class="line"></span><br><span class="line">max_features = <span class="number">10000</span>    <span class="comment"># ä½œä¸ºç‰¹å¾çš„å•è¯ä¸ªæ•°</span></span><br><span class="line">maxlen = <span class="number">20</span>    <span class="comment"># åœ¨ maxlen ä¸ªç‰¹å¾å•è¯åæˆªæ–­æ–‡æœ¬</span></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å°†æ•´æ•°åˆ—è¡¨è½¬æ¢æˆå½¢çŠ¶ä¸º (samples, maxlen) çš„äºŒç»´æ•´æ•°å¼ é‡</span></span><br><span class="line">x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)</span><br><span class="line">x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åœ¨ IMDB æ•°æ®ä¸Šä½¿ç”¨ Embedding å±‚å’Œåˆ†ç±»å™¨</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Embedding, Flatten, Dense</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(<span class="number">10000</span>, <span class="number">8</span>, input_length=maxlen))  <span class="comment"># (samples, maxlen, 8)</span></span><br><span class="line">model.add(Flatten())  <span class="comment"># (samles, maxlen*8)</span></span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))  <span class="comment"># top classifier</span></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">history = model.fit(x_train, y_train, </span><br><span class="line">                    epochs=<span class="number">10</span>, </span><br><span class="line">                    batch_size=<span class="number">32</span>, </span><br><span class="line">                    validation_split=<span class="number">0.2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_2 (Embedding)      (None, 20, 8)             80000     
_________________________________________________________________
flatten_1 (Flatten)          (None, 160)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 161       
=================================================================
Total params: 80,161
Trainable params: 80,161
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
625/625 [==============================] - 1s 1ms/step - loss: 0.6686 - acc: 0.6145 - val_loss: 0.6152 - val_acc: 0.6952
Epoch 2/10
625/625 [==============================] - 1s 929us/step - loss: 0.5370 - acc: 0.7525 - val_loss: 0.5214 - val_acc: 0.7318
Epoch 3/10
625/625 [==============================] - 1s 878us/step - loss: 0.4573 - acc: 0.7895 - val_loss: 0.4979 - val_acc: 0.7456
Epoch 4/10
625/625 [==============================] - 1s 889us/step - loss: 0.4182 - acc: 0.8116 - val_loss: 0.4937 - val_acc: 0.7512
Epoch 5/10
625/625 [==============================] - 1s 902us/step - loss: 0.3931 - acc: 0.8224 - val_loss: 0.4935 - val_acc: 0.7568
Epoch 6/10
625/625 [==============================] - 1s 931us/step - loss: 0.3721 - acc: 0.8360 - val_loss: 0.4969 - val_acc: 0.7582
Epoch 7/10
625/625 [==============================] - 1s 878us/step - loss: 0.3534 - acc: 0.8482 - val_loss: 0.5050 - val_acc: 0.7570
Epoch 8/10
625/625 [==============================] - 1s 873us/step - loss: 0.3356 - acc: 0.8579 - val_loss: 0.5103 - val_acc: 0.7556
Epoch 9/10
625/625 [==============================] - 1s 999us/step - loss: 0.3183 - acc: 0.8670 - val_loss: 0.5161 - val_acc: 0.7560
Epoch 10/10
625/625 [==============================] - 1s 886us/step - loss: 0.3017 - acc: 0.8766 - val_loss: 0.5260 - val_acc: 0.7508</code></pre>
<p>è¿™é‡Œæˆ‘ä»¬åªæŠŠè¯åµŒå…¥åºåˆ—å±•å¼€ä¹‹åç”¨ä¸€ä¸ª Dense å±‚å»å®Œæˆåˆ†ç±»ï¼Œä¼šå¯¼è‡´æ¨¡å‹å¯¹è¾“å…¥åºåˆ—ä¸­çš„æ¯ä¸ªè¯å•ç‹¬å¤„ç†ï¼Œè€Œä¸å»è€ƒè™‘å•è¯ä¹‹é—´çš„å…³ç³»å’Œå¥å­ç»“æ„ã€‚è¿™ä¼šå¯¼è‡´æ¨¡å‹è®¤ä¸ºã€Œthis movie is a bomb(è¿™ç”µå½±è¶…çƒ‚)ã€å’Œã€Œthis movie is the bomb(è¿™ç”µå½±è¶…èµ)ã€éƒ½æ˜¯è´Ÿé¢è¯„ä»·ã€‚è¦å­¦ä¹ å¥å­æ•´ä½“çš„è¯å°±è¦ç”¨åˆ° RNN æˆ–è€… Conv1D äº†ï¼Œè¿™äº›ä¹‹åå†ä»‹ç»ã€‚</p>
<h4 id="ä½¿ç”¨é¢„è®­ç»ƒçš„è¯åµŒå…¥"><a href="#ä½¿ç”¨é¢„è®­ç»ƒçš„è¯åµŒå…¥" class="headerlink" title="ä½¿ç”¨é¢„è®­ç»ƒçš„è¯åµŒå…¥"></a>ä½¿ç”¨é¢„è®­ç»ƒçš„è¯åµŒå…¥</h4><p>å’Œæˆ‘ä»¬åœ¨åšè®¡ç®—æœºè§†è§‰çš„æ—¶å€™ä½¿ç”¨é¢„è®­ç»ƒç½‘ç»œä¸€æ ·ï¼Œåœ¨æ‰‹å¤´æ•°æ®å°‘çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„è¯åµŒå…¥ï¼Œå€Ÿç”¨äººå®¶è®­ç»ƒå‡ºæ¥çš„å¯å¤ç”¨çš„æ¨¡å‹é‡Œçš„é€šç”¨ç‰¹å¾ã€‚</p>
<p>é€šç”¨çš„è¯åµŒå…¥é€šå¸¸æ˜¯åˆ©ç”¨è¯é¢‘ç»Ÿè®¡è®¡ç®—å¾—å‡ºçš„ï¼Œç°åœ¨ä¹Ÿæœ‰å¾ˆå¤šå¯ä¾›æˆ‘ä»¬é€‰ç”¨çš„äº†ï¼Œæ¯”å¦‚ word2vecã€GloVe ç­‰ç­‰ï¼Œå…·ä½“çš„åŸç†éƒ½æ¯”è¾ƒå¤æ‚ï¼Œæˆ‘ä»¬å…ˆä¼šç”¨å°±è¡Œäº†ã€‚</p>
<p>æˆ‘ä»¬ä¼šåœ¨ä¸‹æ–‡çš„ä¾‹å­ä¸­å°è¯•ä½¿ç”¨ GloVeã€‚</p>
<h3 id="ä»åŸå§‹æ–‡æœ¬åˆ°è¯åµŒå…¥"><a href="#ä»åŸå§‹æ–‡æœ¬åˆ°è¯åµŒå…¥" class="headerlink" title="ä»åŸå§‹æ–‡æœ¬åˆ°è¯åµŒå…¥"></a>ä»åŸå§‹æ–‡æœ¬åˆ°è¯åµŒå…¥</h3><p>æˆ‘ä»¬å°è¯•ä»åŸå§‹çš„ IMDB æ•°æ®ï¼ˆå°±æ˜¯ä¸€å¤§å †æ–‡æœ¬å•¦ï¼‰å¼€å§‹ï¼Œå¤„ç†æ•°æ®ï¼Œåšè¯åµŒå…¥ã€‚</p>
<h4 id="ä¸‹è½½-IMDB-æ•°æ®çš„åŸå§‹æ–‡æœ¬"><a href="#ä¸‹è½½-IMDB-æ•°æ®çš„åŸå§‹æ–‡æœ¬" class="headerlink" title="ä¸‹è½½ IMDB æ•°æ®çš„åŸå§‹æ–‡æœ¬"></a>ä¸‹è½½ IMDB æ•°æ®çš„åŸå§‹æ–‡æœ¬</h4><p>åŸå§‹çš„ IMDB æ•°æ®é›†å¯ä»¥ä» <a target="_blank" rel="noopener" href="http://mng.bz/0tIo">http://mng.bz/0tIo</a> ä¸‹è½½ï¼ˆæœ€åæ˜¯è·³è½¬åˆ°ä»s3ä¸‹çš„ <a target="_blank" rel="noopener" href="http://s3.amazonaws.com/text-datasets/aclImdb.zip">http://s3.amazonaws.com/text-datasets/aclImdb.zip</a> ï¼Œä¸ç§‘å­¦ä¸Šç½‘å¾ˆæ…¢å“¦ï¼‰ã€‚</p>
<p>ä¸‹è½½çš„æ•°æ®é›†è§£å‹åæ˜¯è¿™æ ·çš„ï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">aclImdb</span><br><span class="line">â”œâ”€â”€ test</span><br><span class="line">â”‚Â Â  â”œâ”€â”€ neg</span><br><span class="line">â”‚Â Â  â””â”€â”€ pos</span><br><span class="line">â””â”€â”€ train</span><br><span class="line">    â”œâ”€â”€ neg</span><br><span class="line">    â””â”€â”€ pos</span><br></pre></td></tr></table></figure>
<p>åœ¨æ¯ä¸ª neg/pos ç›®å½•ä¸‹é¢å°±æ˜¯ä¸€å¤§å † <code>.txt</code> æ–‡ä»¶äº†ï¼Œæ¯ä¸ªé‡Œé¢æ˜¯ä¸€æ¡è¯„è®ºã€‚</p>
<p>ä¸‹é¢ï¼Œæˆ‘ä»¬å°† train è¯„è®ºè½¬æ¢æˆå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œä¸€ä¸ªå­—ç¬¦ä¸²ä¸€æ¡è¯„è®ºï¼Œå¹¶æŠŠå¯¹åº”çš„æ ‡ç­¾(neg/pos)å†™åˆ° labels åˆ—è¡¨ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¤„ç† IMDB åŸå§‹æ•°æ®çš„æ ‡ç­¾</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">imdb_dir = <span class="string">&#x27;/Volumes/WD/Files/dataset/aclImdb&#x27;</span></span><br><span class="line">train_dir = os.path.join(imdb_dir, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line"></span><br><span class="line">texts = []</span><br><span class="line">labels = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> label_type <span class="keyword">in</span> [<span class="string">&#x27;neg&#x27;</span>, <span class="string">&#x27;pos&#x27;</span>]:</span><br><span class="line">    dir_name = os.path.join(train_dir, label_type)</span><br><span class="line">    <span class="keyword">for</span> fname <span class="keyword">in</span> os.listdir(dir_name):</span><br><span class="line">        <span class="keyword">if</span> fname.endswith(<span class="string">&#x27;.txt&#x27;</span>):</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(dir_name, fname)) <span class="keyword">as</span> f:</span><br><span class="line">                texts.append(f.read())</span><br><span class="line">            labels.append(<span class="number">0</span> <span class="keyword">if</span> label_type == <span class="string">&#x27;neg&#x27;</span> <span class="keyword">else</span> <span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(labels[<span class="number">0</span>], texts[<span class="number">0</span>], sep=<span class="string">&#x27; --&gt; &#x27;</span>)</span><br><span class="line">print(labels[-<span class="number">1</span>], texts[-<span class="number">1</span>], sep=<span class="string">&#x27; --&gt; &#x27;</span>)</span><br><span class="line">print(<span class="built_in">len</span>(texts), <span class="built_in">len</span>(labels))</span><br></pre></td></tr></table></figure>
<pre><code>0 --&gt; Working with one of the best Shakespeare sources, this film manages to be creditable to it&#39;s source, whilst still appealing to a wider audience.&lt;br /&gt;&lt;br /&gt;Branagh steals the film from under Fishburne&#39;s nose, and there&#39;s a talented cast on good form.
1 --&gt; Enchanted April is a tone poem, an impressionist painting, a masterpiece of conveying a message with few words. It has been one of my 10 favorite films since it came out. I continue to wait, albeit less patiently, for the film to come out in DVD format. Apparently, I am not alone.&lt;br /&gt;&lt;br /&gt;If parent company Amazon&#39;s listings are correct, there are many people who want this title in DVD format. Many people want to go to Italy with this cast and this script. Many people want to keep a permanent copy of this film in their libraries. The cast is spectacular, the cinematography and direction impeccable. The film is a definite keeper. Many have already asked. Please add our names to the list.
25000 25000</code></pre>
<h4 id="å¯¹æ•°æ®è¿›è¡Œåˆ†è¯"><a href="#å¯¹æ•°æ®è¿›è¡Œåˆ†è¯" class="headerlink" title="å¯¹æ•°æ®è¿›è¡Œåˆ†è¯"></a>å¯¹æ•°æ®è¿›è¡Œåˆ†è¯</h4><p>ç°åœ¨æ¥åˆ†è¯ï¼Œé¡ºä¾¿åˆ’åˆ†ä¸€ä¸‹è®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚ä¸ºäº†ä½“éªŒé¢„è®­ç»ƒè¯åµŒå…¥ï¼Œæˆ‘ä»¬å†æŠŠè®­ç»ƒé›†æå°ä¸€ç‚¹ï¼Œåªç•™200æ¡æ•°æ®ç”¨æ¥è®­ç»ƒã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¯¹ IMDB åŸå§‹æ•°æ®çš„æ–‡æœ¬è¿›è¡Œåˆ†è¯</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"></span><br><span class="line">maxlen = <span class="number">100</span>  <span class="comment"># åªçœ‹æ¯æ¡è¯„è®ºçš„å‰100ä¸ªè¯</span></span><br><span class="line">training_samples = <span class="number">200</span></span><br><span class="line">validation_samples = <span class="number">10000</span></span><br><span class="line">max_words = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(num_words=max_words)</span><br><span class="line">tokenizer.fit_on_texts(texts)</span><br><span class="line">sequences = tokenizer.texts_to_sequences(texts)</span><br><span class="line">word_index = tokenizer.word_index</span><br><span class="line">print(<span class="string">f&#x27;Found <span class="subst">&#123;<span class="built_in">len</span>(word_index)&#125;</span> unique tokens.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">data = pad_sequences(sequences, maxlen=maxlen)</span><br><span class="line"></span><br><span class="line">labels = np.asarray(labels)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Shape of data tensor:&#x27;</span>, data.shape)</span><br><span class="line">print(<span class="string">&#x27;Shape of label tensor:&#x27;</span>, labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ‰“ä¹±æ•°æ®</span></span><br><span class="line">indices = np.arange(labels.shape[<span class="number">0</span>])</span><br><span class="line">np.random.shuffle(indices)</span><br><span class="line">data = data[indices]</span><br><span class="line">labels = labels[indices]</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ’åˆ†è®­ç»ƒã€éªŒè¯é›†</span></span><br><span class="line">x_train = data[:training_samples]</span><br><span class="line">y_train = labels[:training_samples]</span><br><span class="line">x_val = data[training_samples: training_samples + validation_samples]</span><br><span class="line">y_val = labels[training_samples: training_samples + validation_samples]</span><br></pre></td></tr></table></figure>
<pre><code>Found 88582 unique tokens.
Shape of data tensor: (25000, 100)
Shape of label tensor: (25000,)</code></pre>
<h4 id="ä¸‹è½½-GloVe-è¯åµŒå…¥"><a href="#ä¸‹è½½-GloVe-è¯åµŒå…¥" class="headerlink" title="ä¸‹è½½ GloVe è¯åµŒå…¥"></a>ä¸‹è½½ GloVe è¯åµŒå…¥</h4><p>ä¸‹è½½é¢„è®­ç»ƒå¥½çš„ GloVe è¯åµŒå…¥ï¼š <a target="_blank" rel="noopener" href="http://nlp.stanford.edu/data/glove.6B.zip">http://nlp.stanford.edu/data/glove.6B.zip</a></p>
<p>å†™ä¸‹æ¥æŠŠå®ƒè§£å‹ï¼Œé‡Œé¢ç”¨çº¯æ–‡æœ¬ä¿å­˜äº†è®­ç»ƒå¥½çš„ 400000 ä¸ª tokens çš„ 100 ç»´è¯åµŒå…¥å‘é‡ã€‚</p>
<h4 id="å¯¹åµŒå…¥è¿›è¡Œé¢„å¤„ç†"><a href="#å¯¹åµŒå…¥è¿›è¡Œé¢„å¤„ç†" class="headerlink" title="å¯¹åµŒå…¥è¿›è¡Œé¢„å¤„ç†"></a>å¯¹åµŒå…¥è¿›è¡Œé¢„å¤„ç†</h4><p>è§£æè§£å‹åçš„æ–‡ä»¶ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">glove_dir = <span class="string">&#x27;/Volumes/WD/Files/glove.6B&#x27;</span></span><br><span class="line"></span><br><span class="line">embeddings_index = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(glove_dir, <span class="string">&#x27;glove.6B.100d.txt&#x27;</span>)) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        values = line.split()</span><br><span class="line">        word = values[<span class="number">0</span>]</span><br><span class="line">        coefs = np.asarray(values[<span class="number">1</span>:], dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">        embeddings_index[word] = coefs</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;Found <span class="subst">&#123;<span class="built_in">len</span>(embeddings_index)&#125;</span> word vectors.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Found 400000 word vectors.</code></pre>
<p>ç„¶åï¼Œæˆ‘ä»¬è¦æ„å»ºä¸€ä¸ªå¯ä»¥åŠ è½½è¿› Embedding å±‚çš„åµŒå…¥çŸ©é˜µï¼Œå…¶å½¢çŠ¶ä¸º <code>(max_words, embedding_dim)</code>ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">embedding_dim = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">embedding_matrix = np.zeros((max_words, embedding_dim))</span><br><span class="line"><span class="keyword">for</span> word, i <span class="keyword">in</span> word_index.items():</span><br><span class="line">    <span class="keyword">if</span> i &lt; max_words:</span><br><span class="line">        embedding_vector = embeddings_index.get(word)  <span class="comment"># æœ‰çš„å°±ç”¨ embeddings_index é‡Œçš„è¯å‘é‡</span></span><br><span class="line">        <span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:               <span class="comment"># æ²¡æœ‰å°±ç”¨å…¨é›¶</span></span><br><span class="line">            embedding_matrix[i] = embedding_vector</span><br><span class="line">            </span><br><span class="line">print(embedding_matrix)</span><br></pre></td></tr></table></figure>
<pre><code>[[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.038194   -0.24487001  0.72812003 ... -0.1459      0.82779998
   0.27061999]
 [-0.071953    0.23127     0.023731   ... -0.71894997  0.86894
   0.19539   ]
 ...
 [-0.44036001  0.31821999  0.10778    ... -1.29849994  0.11824
   0.64845002]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.54539001 -0.31817999 -0.016281   ... -0.44865     0.067047
   0.17975999]]</code></pre>
<h4 id="å®šä¹‰æ¨¡å‹"><a href="#å®šä¹‰æ¨¡å‹" class="headerlink" title="å®šä¹‰æ¨¡å‹"></a>å®šä¹‰æ¨¡å‹</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Embedding, Flatten, Dense</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(max_words, embedding_dim, input_length=maxlen))</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_2&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_3 (Embedding)      (None, 100, 100)          1000000   
_________________________________________________________________
flatten_2 (Flatten)          (None, 10000)             0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                320032    
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 33        
=================================================================
Total params: 1,320,065
Trainable params: 1,320,065
Non-trainable params: 0
_________________________________________________________________</code></pre>
<h4 id="æŠŠ-GloVe-è¯åµŒå…¥åŠ è½½è¿›æ¨¡å‹"><a href="#æŠŠ-GloVe-è¯åµŒå…¥åŠ è½½è¿›æ¨¡å‹" class="headerlink" title="æŠŠ GloVe è¯åµŒå…¥åŠ è½½è¿›æ¨¡å‹"></a>æŠŠ GloVe è¯åµŒå…¥åŠ è½½è¿›æ¨¡å‹</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.layers[<span class="number">0</span>].set_weights([embedding_matrix])</span><br><span class="line">model.layers[<span class="number">0</span>].trainable = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h4 id="è®­ç»ƒä¸è¯„ä¼°æ¨¡å‹"><a href="#è®­ç»ƒä¸è¯„ä¼°æ¨¡å‹" class="headerlink" title="è®­ç»ƒä¸è¯„ä¼°æ¨¡å‹"></a>è®­ç»ƒä¸è¯„ä¼°æ¨¡å‹</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, </span><br><span class="line">              metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">history = model.fit(x_train, y_train, </span><br><span class="line">                    epochs=<span class="number">10</span>, </span><br><span class="line">                    batch_size=<span class="number">32</span>, </span><br><span class="line">                    validation_data=(x_val, y_val))</span><br><span class="line">model.save_weights(<span class="string">&#x27;pre_trained_glove_model.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/10
7/7 [==============================] - 0s 64ms/step - loss: 1.3595 - acc: 0.5150 - val_loss: 0.6871 - val_acc: 0.5490
Epoch 2/10
7/7 [==============================] - 0s 42ms/step - loss: 0.6846 - acc: 0.7950 - val_loss: 0.7569 - val_acc: 0.5217
Epoch 3/10
7/7 [==============================] - 0s 42ms/step - loss: 0.3757 - acc: 0.8900 - val_loss: 0.8181 - val_acc: 0.5189
Epoch 4/10
7/7 [==============================] - 0s 41ms/step - loss: 0.3464 - acc: 0.8800 - val_loss: 0.8497 - val_acc: 0.4971
Epoch 5/10
7/7 [==============================] - 0s 41ms/step - loss: 0.2278 - acc: 0.9600 - val_loss: 0.8661 - val_acc: 0.5308
Epoch 6/10
7/7 [==============================] - 0s 42ms/step - loss: 0.1328 - acc: 0.9950 - val_loss: 0.6977 - val_acc: 0.5895
Epoch 7/10
7/7 [==============================] - 0s 42ms/step - loss: 0.1859 - acc: 0.9250 - val_loss: 0.6923 - val_acc: 0.5867
Epoch 8/10
7/7 [==============================] - 0s 42ms/step - loss: 0.0950 - acc: 0.9950 - val_loss: 0.7609 - val_acc: 0.5609
Epoch 9/10
7/7 [==============================] - 0s 50ms/step - loss: 0.0453 - acc: 1.0000 - val_loss: 0.7235 - val_acc: 0.5979
Epoch 10/10
7/7 [==============================] - 0s 49ms/step - loss: 0.0398 - acc: 1.0000 - val_loss: 1.1416 - val_acc: 0.5063</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç»˜åˆ¶ç»“æœ</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">acc = history.history[<span class="string">&#x27;acc&#x27;</span>]</span><br><span class="line">val_acc = history.history[<span class="string">&#x27;val_acc&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">epochs = <span class="built_in">range</span>(<span class="built_in">len</span>(acc))</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">&#x27;bo-&#x27;</span>, label=<span class="string">&#x27;Training acc&#x27;</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">&#x27;rs-&#x27;</span>, label=<span class="string">&#x27;Validation acc&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss, <span class="string">&#x27;bo-&#x27;</span>, label=<span class="string">&#x27;Training loss&#x27;</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">&#x27;rs-&#x27;</span>, label=<span class="string">&#x27;Validation loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghmvtdmhl3j30af07cmxf.jpg" alt="png"></p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghmvtbyf9tj30af07cglv.jpg" alt="png"></p>
<p>åªç”¨ 200 ä¸ªè®­ç»ƒæ ·æœ¬è¿˜æ˜¯å¤ªéš¾äº†ï¼Œä½†ç”¨é¢„è®­ç»ƒè¯åµŒå…¥è¿˜æ˜¯å¾—åˆ°äº†ä¸é”™çš„æˆæœçš„ã€‚ä½œä¸ºå¯¹æ¯”ï¼Œçœ‹çœ‹å¦‚æœä¸ä½¿ç”¨é¢„è®­ç»ƒï¼Œä¼šæ˜¯ä»€ä¹ˆæ ·çš„ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ„å»ºæ¨¡å‹</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Embedding, Flatten, Dense</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(max_words, embedding_dim, input_length=maxlen))</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸ä½¿ç”¨ GloVe è¯åµŒå…¥</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒ</span></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>, </span><br><span class="line">              loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, </span><br><span class="line">              metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">history = model.fit(x_train, y_train, </span><br><span class="line">                    epochs=<span class="number">10</span>, </span><br><span class="line">                    batch_size=<span class="number">32</span>, </span><br><span class="line">                    validation_data=(x_val, y_val))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç»˜åˆ¶ç»“æœ</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">acc = history.history[<span class="string">&#x27;acc&#x27;</span>]</span><br><span class="line">val_acc = history.history[<span class="string">&#x27;val_acc&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">epochs = <span class="built_in">range</span>(<span class="built_in">len</span>(acc))</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">&#x27;bo-&#x27;</span>, label=<span class="string">&#x27;Training acc&#x27;</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">&#x27;rs-&#x27;</span>, label=<span class="string">&#x27;Validation acc&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss, <span class="string">&#x27;bo-&#x27;</span>, label=<span class="string">&#x27;Training loss&#x27;</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">&#x27;rs-&#x27;</span>, label=<span class="string">&#x27;Validation loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_3&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_4 (Embedding)      (None, 100, 100)          1000000   
_________________________________________________________________
flatten_3 (Flatten)          (None, 10000)             0         
_________________________________________________________________
dense_4 (Dense)              (None, 32)                320032    
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 33        
=================================================================
Total params: 1,320,065
Trainable params: 1,320,065
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
7/7 [==============================] - 1s 72ms/step - loss: 0.6972 - acc: 0.4600 - val_loss: 0.6921 - val_acc: 0.5150
Epoch 2/10
7/7 [==============================] - 0s 46ms/step - loss: 0.4991 - acc: 1.0000 - val_loss: 0.6901 - val_acc: 0.5347
Epoch 3/10
7/7 [==============================] - 0s 46ms/step - loss: 0.2795 - acc: 1.0000 - val_loss: 0.6914 - val_acc: 0.5401
Epoch 4/10
7/7 [==============================] - 0s 52ms/step - loss: 0.1171 - acc: 1.0000 - val_loss: 0.6977 - val_acc: 0.5389
Epoch 5/10
7/7 [==============================] - 0s 45ms/step - loss: 0.0535 - acc: 1.0000 - val_loss: 0.7115 - val_acc: 0.5343
Epoch 6/10
7/7 [==============================] - 0s 44ms/step - loss: 0.0271 - acc: 1.0000 - val_loss: 0.7133 - val_acc: 0.5348
Epoch 7/10
7/7 [==============================] - 0s 44ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.7146 - val_acc: 0.5382
Epoch 8/10
7/7 [==============================] - 0s 44ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.7192 - val_acc: 0.5410
Epoch 9/10
7/7 [==============================] - 0s 44ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.7266 - val_acc: 0.5398
Epoch 10/10
7/7 [==============================] - 0s 53ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.7378 - val_acc: 0.5380</code></pre>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghmvtd56u4j30af07c3yq.jpg" alt="png"></p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghmvtcoi15j30af07cdg2.jpg" alt="png"></p>
<p>å¯ä»¥çœ‹åˆ°ï¼Œåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œé¢„è®­ç»ƒè¯åµŒå…¥çš„æ€§èƒ½è¦ä¼˜äºä¸ä»»åŠ¡ä¸€èµ·å­¦ä¹ çš„è¯åµŒå…¥ã€‚ä½†å¦‚æœæœ‰å¤§é‡çš„å¯ç”¨æ•°æ®ï¼Œç”¨ä¸€ä¸ª Embedding å±‚å»ä¸ä»»åŠ¡ä¸€èµ·è®­ç»ƒï¼Œé€šå¸¸æ¯”ä½¿ç”¨é¢„è®­ç»ƒè¯åµŒå…¥æ›´åŠ å¼ºå¤§ã€‚</p>
<p>æœ€åï¼Œå†æ¥çœ‹ä¸€ä¸‹æµ‹è¯•é›†ä¸Šçš„ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¯¹æµ‹è¯•é›†æ•°æ®è¿›è¡Œåˆ†è¯</span></span><br><span class="line"></span><br><span class="line">test_dir = os.path.join(imdb_dir, <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line"></span><br><span class="line">texts = []</span><br><span class="line">labels = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> label_type <span class="keyword">in</span> [<span class="string">&#x27;neg&#x27;</span>, <span class="string">&#x27;pos&#x27;</span>]:</span><br><span class="line">    dir_name = os.path.join(test_dir, label_type)</span><br><span class="line">    <span class="keyword">for</span> fname <span class="keyword">in</span> <span class="built_in">sorted</span>(os.listdir(dir_name)):</span><br><span class="line">        <span class="keyword">if</span> fname.endswith(<span class="string">&#x27;.txt&#x27;</span>):</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(dir_name, fname)) <span class="keyword">as</span> f:</span><br><span class="line">                texts.append(f.read())</span><br><span class="line">            labels.append(<span class="number">0</span> <span class="keyword">if</span> label_type == <span class="string">&#x27;neg&#x27;</span> <span class="keyword">else</span> <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">sequences = tokenizer.texts_to_sequences(texts)</span><br><span class="line">x_test = pad_sequences(sequences, maxlen=maxlen)</span><br><span class="line">y_test = np.asarray(labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹</span></span><br><span class="line"></span><br><span class="line">model.load_weights(<span class="string">&#x27;pre_trained_glove_model.h5&#x27;</span>)</span><br><span class="line">model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>
<pre><code>782/782 [==============================] - 1s 983us/step - loss: 1.1397 - acc: 0.5127





[1.1397335529327393, 0.512719988822937]</code></pre>
<p>emmmï¼Œæœ€åçš„è¿›åº¦æ˜¯ä»¤äººæƒŠè®¶çš„ 50%+ ï¼åªç”¨å¦‚æ­¤å°‘çš„æ•°æ®æ¥è®­ç»ƒè¿˜æ˜¯éš¾å•Šã€‚</p>

  </div>
</article>
<!--Disqus-->


<!--Livere-->

    <div class="blog-post-comments">
        <div id="lv-container" data-id="city" data-uid="MTAyMC80NjEzMi8yMjY0Mw==">
            <noscript>ä¸å¯ç”¨ JavaScript æ”¯æŒçš„äººæ˜¯çœ‹ä¸åˆ°å¯çˆ±çš„è¯„è®ºåŒºçš„ã€‚ğŸ˜¥</noscript>
        </div>
    </div>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">é¦–é¡µ</a></li>
         
          <li><a href="/about/">å…³äº</a></li>
         
          <li><a href="/archives/">å½’æ¡£</a></li>
         
          <li><a target="_blank" rel="noopener" href="https://github.com/cdfmlr">é¡¹ç›®</a></li>
         
          <li><a href="/search/">æœç´¢</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Deep-Learning-with-Python"><span class="toc-number">1.</span> <span class="toc-text">Deep Learning with Python</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1-Working-with-text-data"><span class="toc-number">1.1.</span> <span class="toc-text">6.1  Working with text data</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#n-grams-%E5%92%8C%E8%AF%8D%E8%A2%8B-bag-of-words"><span class="toc-number">1.1.1.</span> <span class="toc-text">n-grams å’Œè¯è¢‹(bag-of-words)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#one-hot-%E7%BC%96%E7%A0%81"><span class="toc-number">1.1.2.</span> <span class="toc-text">one-hot ç¼–ç </span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%8D%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.3.</span> <span class="toc-text">è¯åµŒå…¥</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%A9%E7%94%A8-Embedding-%E5%B1%82%E5%AD%A6%E4%B9%A0%E8%AF%8D%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.3.1.</span> <span class="toc-text">åˆ©ç”¨ Embedding å±‚å­¦ä¹ è¯åµŒå…¥</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E8%AF%8D%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.3.2.</span> <span class="toc-text">ä½¿ç”¨é¢„è®­ç»ƒçš„è¯åµŒå…¥</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8E%E5%8E%9F%E5%A7%8B%E6%96%87%E6%9C%AC%E5%88%B0%E8%AF%8D%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.4.</span> <span class="toc-text">ä»åŸå§‹æ–‡æœ¬åˆ°è¯åµŒå…¥</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD-IMDB-%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8E%9F%E5%A7%8B%E6%96%87%E6%9C%AC"><span class="toc-number">1.1.4.1.</span> <span class="toc-text">ä¸‹è½½ IMDB æ•°æ®çš„åŸå§‹æ–‡æœ¬</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%88%86%E8%AF%8D"><span class="toc-number">1.1.4.2.</span> <span class="toc-text">å¯¹æ•°æ®è¿›è¡Œåˆ†è¯</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD-GloVe-%E8%AF%8D%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.4.3.</span> <span class="toc-text">ä¸‹è½½ GloVe è¯åµŒå…¥</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E5%B5%8C%E5%85%A5%E8%BF%9B%E8%A1%8C%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.1.4.4.</span> <span class="toc-text">å¯¹åµŒå…¥è¿›è¡Œé¢„å¤„ç†</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.4.5.</span> <span class="toc-text">å®šä¹‰æ¨¡å‹</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8A%8A-GloVe-%E8%AF%8D%E5%B5%8C%E5%85%A5%E5%8A%A0%E8%BD%BD%E8%BF%9B%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.4.6.</span> <span class="toc-text">æŠŠ GloVe è¯åµŒå…¥åŠ è½½è¿›æ¨¡å‹</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E4%B8%8E%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.4.7.</span> <span class="toc-text">è®­ç»ƒä¸è¯„ä¼°æ¨¡å‹</span></a></li></ol></li></ol></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&text=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&is_video=false&description=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®&body=Check out this article: https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&title=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://clownote.github.io/2020/08/11/DeepLearningWithPython/Deep-Learning%20with-Python-ch6_1/&name=Pythonæ·±åº¦å­¦ä¹ ä¹‹å¤„ç†æ–‡æœ¬æ•°æ®&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> èœå•</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> ç›®å½•</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> åˆ†äº«</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> è¿”å›é¡¶éƒ¨</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2021 CDFMLR
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">é¦–é¡µ</a></li>
         
          <li><a href="/about/">å…³äº</a></li>
         
          <li><a href="/archives/">å½’æ¡£</a></li>
         
          <li><a target="_blank" rel="noopener" href="https://github.com/cdfmlr">é¡¹ç›®</a></li>
         
          <li><a href="/search/">æœç´¢</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->

<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">


<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css">


    <!-- jquery -->

<script src="/lib/jquery/jquery.min.js"></script>


<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>

<!-- clipboard -->

  
<script src="/lib/clipboard/clipboard.min.js"></script>

  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"å¤åˆ¶åˆ°ç²˜è´´æ¿!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight .code pre").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      target: function(trigger) {
        return trigger.nextElementSibling;
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "å¤åˆ¶æˆåŠŸ!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-146911386-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Baidu Analytics -->

    <script type="text/javascript">
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?9a0d2e6fde93dad496ac79f04f3aba97";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

<!-- Disqus Comments -->


<!--Livere Comments-->

    <script type="text/javascript">
      (function (d, s) {
        var j, e = d.getElementsByTagName(s)[0];

        if (typeof LivereTower === 'function') { return; }

        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;

        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>

</body>
</html>
