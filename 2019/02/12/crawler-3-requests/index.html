<!DOCTYPE html>
<html lang=zh>
<head><meta name="generator" content="Hexo 3.9.0">
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="爬虫请求库的使用之Requests  本文主要介绍 Requests 库。   requests 相较于 Python 内置的 Urllib，第三方库 Requests 为我们提供了一个更加优雅的解决方案。 得益于 requests 的强大，我们可以在解决 Cookies、登录验证、代理设置 等问题时更加方便快捷，而无需再琢磨 Urllib 的 Opener、Handler。  requests">
<meta name="keywords" content="Crawler">
<meta property="og:type" content="article">
<meta property="og:title" content="python请求库requests">
<meta property="og:url" content="https://clownote.github.io/2019/02/12/crawler-3-requests/index.html">
<meta property="og:site_name" content="clownote">
<meta property="og:description" content="爬虫请求库的使用之Requests  本文主要介绍 Requests 库。   requests 相较于 Python 内置的 Urllib，第三方库 Requests 为我们提供了一个更加优雅的解决方案。 得益于 requests 的强大，我们可以在解决 Cookies、登录验证、代理设置 等问题时更加方便快捷，而无需再琢磨 Urllib 的 Opener、Handler。  requests">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-09-10T15:02:21.001Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python请求库requests">
<meta name="twitter:description" content="爬虫请求库的使用之Requests  本文主要介绍 Requests 库。   requests 相较于 Python 内置的 Urllib，第三方库 Requests 为我们提供了一个更加优雅的解决方案。 得益于 requests 的强大，我们可以在解决 Cookies、登录验证、代理设置 等问题时更加方便快捷，而无需再琢磨 Urllib 的 Opener、Handler。  requests">
    
    
        
          
              <link rel="shortcut icon" href="/images/rabbit.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/rabbit_192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/rabbit_180.png">
          
        
    
    <!-- title -->
    <title>python请求库requests</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss -->
    
    
    <!--Google search varification (PRIVATE)-->
    <meta name="google-site-verification" content="MrqlpFAD8nDanw3Ypv7ZsIWHLnTdhRuLa4QhSVwxIvc">
</head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/about/">关于</a></li>
         
          <li><a href="/archives/">归档</a></li>
         
          <li><a href="https://github.com/cdfmlr">项目</a></li>
         
          <li><a href="/search/">搜索</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2019/02/13/crawler-4-re/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2019/02/11/crawler-2-urllib/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">上一篇</span>
      <span id="i-next" class="info" style="display:none;">下一篇</span>
      <span id="i-top" class="info" style="display:none;">返回顶部</span>
      <span id="i-share" class="info" style="display:none;">分享文章</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://clownote.github.io/2019/02/12/crawler-3-requests/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&text=python请求库requests"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&title=python请求库requests"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&is_video=false&description=python请求库requests"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=python请求库requests&body=Check out this article: https://clownote.github.io/2019/02/12/crawler-3-requests/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&title=python请求库requests"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&title=python请求库requests"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&title=python请求库requests"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&title=python请求库requests"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&name=python请求库requests&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#爬虫请求库的使用之requests"><span class="toc-number">1.</span> <span class="toc-text"> 爬虫请求库的使用之Requests</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#requests"><span class="toc-number">1.1.</span> <span class="toc-text"> requests</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#requestsget-get请求"><span class="toc-number">1.1.1.</span> <span class="toc-text"> requests.get() —— GET请求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#获取二进制数据"><span class="toc-number">1.1.2.</span> <span class="toc-text"> 获取二进制数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#抓取网页"><span class="toc-number">1.1.3.</span> <span class="toc-text"> 抓取网页</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#requestspost-post请求"><span class="toc-number">1.1.4.</span> <span class="toc-text"> requests.post() —— POST请求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#文件上传"><span class="toc-number">1.1.5.</span> <span class="toc-text"> 文件上传</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cookies"><span class="toc-number">1.1.6.</span> <span class="toc-text"> Cookies</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#获取cookies"><span class="toc-number">1.1.6.1.</span> <span class="toc-text"> 获取Cookies</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#调用cookies"><span class="toc-number">1.1.6.2.</span> <span class="toc-text"> 调用Cookies</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#会话维持"><span class="toc-number">1.1.6.3.</span> <span class="toc-text"> 会话维持</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#不使用会话维持"><span class="toc-number">1.1.6.3.0.1.</span> <span class="toc-text"> 不使用会话维持</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#使用会话维持"><span class="toc-number">1.1.6.3.0.2.</span> <span class="toc-text"> 使用会话维持</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ssl-证书验证"><span class="toc-number">1.1.6.4.</span> <span class="toc-text"> SSL 证书验证</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#代理设置"><span class="toc-number">1.1.6.5.</span> <span class="toc-text"> 代理设置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#http-基本认证"><span class="toc-number">1.1.6.6.</span> <span class="toc-text"> HTTP 基本认证</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#prepared-request"><span class="toc-number">1.1.6.7.</span> <span class="toc-text"> Prepared Request</span></a></li></ol></li></ol></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        python请求库requests
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">clownote</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2019-02-12T14:49:55.000Z" itemprop="datePublished">2019-02-12</time>
        
        (Updated: <time datetime="2019-09-10T15:02:21.001Z" itemprop="dateModified">2019-09-10</time>)
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/Crawler/">Crawler</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/Crawler/">Crawler</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h1 id="爬虫请求库的使用之requests"><a class="markdownIt-Anchor" href="#爬虫请求库的使用之requests"></a> 爬虫请求库的使用之Requests</h1>
<blockquote>
<p>本文主要介绍 <strong>Requests 库</strong>。</p>
</blockquote>
<h2 id="requests"><a class="markdownIt-Anchor" href="#requests"></a> requests</h2>
<p>相较于 Python 内置的 Urllib，第三方库 Requests 为我们提供了一个更加优雅的解决方案。<br>
得益于 <code>requests</code> 的强大，我们可以在解决 Cookies、登录验证、代理设置 等问题时更加方便快捷，而无需再琢磨 Urllib 的 Opener、Handler。</p>
<h3 id="requestsget-get请求"><a class="markdownIt-Anchor" href="#requestsget-get请求"></a> requests.get() —— GET请求</h3>
<p>使用 <code>requests.get(url, *params={}, headers={}, timeout=None)</code> 可以完成 GET 请求，返回 response 的各种内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">'http://httpbin.org/get'</span>)</span><br><span class="line">print(r.text)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'status_code: '</span>, type(r.status_code), r.status_code)</span><br><span class="line">print(<span class="string">'headers: '</span>, type(r.headers), r.headers)</span><br><span class="line">print(<span class="string">'cookies: '</span>, type(r.cookies), r.cookies)</span><br><span class="line">print(<span class="string">'url: '</span>, type(r.url), r.url)</span><br><span class="line">print(<span class="string">'history: '</span>, type(r.history), r.history)</span><br></pre></td></tr></table></figure>
<p>status_code 属性得到状态码， headers 属性得到 Response Headers，cookies 属性得到 Cookies，url 属性得到 URL，history 属性得到请求历史。</p>
<p>使用 <code>params={}</code> ，就等于在url中添加了 <code>'?xxx&amp;xxx'</code> 的信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'name'</span>: <span class="string">'germey'</span>,</span><br><span class="line">    <span class="string">'age'</span>: <span class="number">22</span></span><br><span class="line">&#125;</span><br><span class="line">r = requests.get(<span class="string">"http://httpbin.org/get"</span>, params=data)    <span class="comment"># 相当于 GET请求 ‘http://httpbin.org/get?name=germey&amp;age=22’</span></span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>在上例中，我们可以看到返回的 r.text 实际上是 JSON 的字符串，requests 提供了 一个 <code>Response.json()</code> 可以直接把 JSON 解析成 dict：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  承接上一代码块</span></span><br><span class="line">d = r.json()</span><br><span class="line">print(type(d), d, sep=<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure>
<p>若返回结果不是 Json 格式，调用 <code>Response.json()</code>，会抛出 <a href="https://www.zhihu.com/explorejson.decoder.JSONDecodeError" target="_blank" rel="noopener">https://www.zhihu.com/explorejson.decoder.JSONDecodeError</a> 的异常。</p>
<p>我们还可以在调用 requests.get() 的时候传入一个 dict 作为 headers：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0.3 Safari/605.1.15'</span>,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">response = requests.get(<span class="string">'http://httpbin.org/get'</span>, headers=headers)</span><br><span class="line">print(response.text)</span><br></pre></td></tr></table></figure>
<p>我们还可以设置超时，有三种方法：</p>
<ul>
<li><code>r = requests.get('https://www.taobao.com', timeout=None)</code>，connect 和 read 二者都是 永久等待，这是默认设置</li>
<li><code>r = requests.get('https://www.taobao.com', timeout=1)</code>，connect 和 read 二者的 timeout 总和设置为 1 秒</li>
<li><code>r = requests.get('https://www.taobao.com', timeout=(5, 11))</code>，connect 5秒，read 11秒</li>
</ul>
<h3 id="获取二进制数据"><a class="markdownIt-Anchor" href="#获取二进制数据"></a> 获取二进制数据</h3>
<p>当我们获取得二进制的数据时，Response.text 显然是不好用了，这时我们可以通过 <code>Response.content</code> 取得二进制数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">"https://github.com/favicon.ico"</span>)</span><br><span class="line"></span><br><span class="line">print(r.text)       <span class="comment"># 输出乱码</span></span><br><span class="line">print(r.content)    <span class="comment"># 输出十六进制码的bytes（b'\x..\x........'）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'favicon.ico'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:        <span class="comment"># 保存到文件</span></span><br><span class="line">    f.write(r.content)</span><br></pre></td></tr></table></figure>
<h3 id="抓取网页"><a class="markdownIt-Anchor" href="#抓取网页"></a> 抓取网页</h3>
<p>我们来做一个简单的爬虫实践————爬取 <a href="https://www.zhihu.com/explore" target="_blank" rel="noopener">知乎-发现</a> 里的问题。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment"># 知乎-发现的url</span></span><br><span class="line">url = <span class="string">'https://www.zhihu.com/explore'</span></span><br><span class="line"><span class="comment"># 匹配问题的正则表达式</span></span><br><span class="line">pattern = re.compile(<span class="string">'explore-feed.*?question_link.*?&gt;(.*?)&lt;/'</span>, re.S)       <span class="comment"># *？表示惰性匹配</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0.3 Safari/605.1.15'</span>,</span><br><span class="line">        <span class="string">'Accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = requests.get(url, headers=headers)</span><br><span class="line">    questions = re.findall(pattern, response.text)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> questions:</span><br><span class="line">        print(i)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    print(e)</span><br></pre></td></tr></table></figure>
<h3 id="requestspost-post请求"><a class="markdownIt-Anchor" href="#requestspost-post请求"></a> requests.post() —— POST请求</h3>
<p>用 <code>requests.post(url, data={})</code> 我们就可以 POST 请求，这和使用 requests.get() 非常类似。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">data = &#123;<span class="string">'Data'</span>: <span class="string">'Hello, world!'</span>&#125;</span><br><span class="line"></span><br><span class="line">r = requests.post(<span class="string">'http://httpbin.org/post'</span>, data=data)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>我们同样可以从 Response 中获取各种数据，例如：status_code 属性得到状态码， headers 属性得到 Response Headers，cookies 属性得到 Cookies，url 属性得到 URL，history 属性得到请求历史。</p>
<h3 id="文件上传"><a class="markdownIt-Anchor" href="#文件上传"></a> 文件上传</h3>
<p>我们可以使用 POST请求 来完成文件的上传。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">files = &#123;<span class="string">'file'</span>: open(<span class="string">'favicon.ico'</span>, <span class="string">'rb'</span>)&#125;</span><br><span class="line">r = requests.post(<span class="string">'http://httpbin.org/post'</span>, files=files)</span><br><span class="line"></span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<h3 id="cookies"><a class="markdownIt-Anchor" href="#cookies"></a> Cookies</h3>
<h4 id="获取cookies"><a class="markdownIt-Anchor" href="#获取cookies"></a> 获取Cookies</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">'https://www.baidu.com'</span>)</span><br><span class="line">print(r.cookies)</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> r.cookies.items():</span><br><span class="line">    print(key + <span class="string">'='</span> + value)</span><br></pre></td></tr></table></figure>
<h4 id="调用cookies"><a class="markdownIt-Anchor" href="#调用cookies"></a> 调用Cookies</h4>
<p>我们先登录一个网站，然后从记录下Cookies，在另一次登录中，把这个Cookies传上去，就可以维持登录。</p>
<p>例如，我们现在用浏览器登录「百度」，然后打开一次百度首页，我们检查 <code>www.baidu.com</code> 的 Request Headers，我们会发现一项 <code>Cookies</code>，我们把这个值复制下来，让爬虫伪造 headers，带上这个 Cookies，我们就可以模拟登录了:)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://www.baidu.com'</span></span><br><span class="line">headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0.3 Safari/605.1.15'</span>,</span><br><span class="line">        <span class="string">'Cookie'</span>: <span class="string">'BDORZ******3254'</span>,</span><br><span class="line">        <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>,</span><br><span class="line">        <span class="string">'Host'</span>: <span class="string">'www.baidu.com'</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">r = requests.get(url, headers=headers)</span><br><span class="line"></span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>从结果中，我们可以看到自己的名字，说明成功模仿登录！</p>
<p>也可以这样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">cookies = <span class="string">'q_c1=316******3b0'</span></span><br><span class="line">jar = requests.cookies.RequestsCookieJar()</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'Host'</span>: <span class="string">'www.zhihu.com'</span>,</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> cookie <span class="keyword">in</span> cookies.split(<span class="string">';'</span>):</span><br><span class="line">    key, value = cookie.split(<span class="string">'='</span>, <span class="number">1</span>)</span><br><span class="line">    jar.set(key, value)</span><br><span class="line">    </span><br><span class="line">r = requests.get(<span class="string">'http://www.zhihu.com'</span>, cookies=jar, headers=headers)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<h4 id="会话维持"><a class="markdownIt-Anchor" href="#会话维持"></a> 会话维持</h4>
<p>在 Requests 中，我们如果直接利用 get() 或 post() 等方法的确可以做到模拟网页的请求。<br>
但是这实际上是相当于不同的会话，即不同的 Session，也就是说<strong>每请求一次</strong>都相当于用<strong>不同浏览器打开</strong>，会话不会维持。<br>
但我们常需要模拟在一个浏览器中打开同一站点的不同页面，这就需要我们进行会话维持。</p>
<h6 id="不使用会话维持"><a class="markdownIt-Anchor" href="#不使用会话维持"></a> 不使用会话维持</h6>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">requests.get(<span class="string">'http://httpbin.org/cookies/set/number/123456789'</span>)     <span class="comment"># 一次会话</span></span><br><span class="line">r = requests.get(<span class="string">'http://httpbin.org/cookies'</span>)      <span class="comment"># 另一次会话</span></span><br><span class="line">print(r.text)</span><br><span class="line"></span><br><span class="line"><span class="string">'''(result)</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  "cookies": &#123;&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<p>我们得到的结果是空的，说明两次get不是同一会话了。</p>
<h6 id="使用会话维持"><a class="markdownIt-Anchor" href="#使用会话维持"></a> 使用会话维持</h6>
<p>使用会话维持最直接的办法就是我们可以获取上一次的 Cookies，下一次请求时把它传上去，但这样做过于繁琐，requests 为我们提供了更加简洁、优雅的解决方案 —— <code>requests.Session</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">s = requests.Session()      <span class="comment"># 开启一个新会话 s</span></span><br><span class="line">s.get(<span class="string">'http://httpbin.org/cookies/set/number/123456789'</span>)    <span class="comment"># 会话 s</span></span><br><span class="line">r = s.get(<span class="string">'http://httpbin.org/cookies'</span>)     <span class="comment"># 同样还是会话 s</span></span><br><span class="line">print(r.text)</span><br><span class="line"></span><br><span class="line"><span class="string">'''(result)</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  "cookies": &#123;</span></span><br><span class="line"><span class="string">    "number": "123456789"</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
<p>这一次，我们就维持了会话了。</p>
<h4 id="ssl-证书验证"><a class="markdownIt-Anchor" href="#ssl-证书验证"></a> SSL 证书验证</h4>
<p>Requests 提供了证书验证的功能，当发送 HTTP 请求的时候，它会检查 SSL 证书（针对https），我们可以使用 <code>verify</code> 参数来控制是否检查此证书，缺省值是 True，会自动验证。<br>
如果我们不需要检查证书，可以让 <code>verify=False</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">response = requests.get(<span class="string">'https://www.12306.cn'</span>, verify=<span class="literal">False</span>)</span><br><span class="line">print(response.status_code)</span><br></pre></td></tr></table></figure>
<p>指定本地证书用作客户端证书:</p>
<p>客户端证书可以是单个文件（包含密钥和证书）或一个包含两个文件路径的元组。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">response = requests.get(<span class="string">'https://www.12306.cn'</span>, cert=(<span class="string">'/path/server.crt'</span>, <span class="string">'/path/key'</span>))</span><br><span class="line">print(response.status_code)</span><br></pre></td></tr></table></figure>
<p>⚠️【注意】本地私有证书的 key 必须要是解密状态，加密状态的 key 是不支持的。</p>
<h4 id="代理设置"><a class="markdownIt-Anchor" href="#代理设置"></a> 代理设置</h4>
<p>找一个<a href="https://www.xicidaili.com/nn/" target="_blank" rel="noopener">免费的代理服务器</a>，然后用这个服务器来代理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0.3 Safari/605.1.15'</span>,</span><br><span class="line">        <span class="string">'Accept-Language'</span>: <span class="string">'zh-cn'</span>,</span><br><span class="line">        <span class="string">'Accept-Encoding'</span>: <span class="string">'br, gzip, deflate'</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">proxies = &#123;</span><br><span class="line">        <span class="string">'http'</span>: <span class="string">'http://110.52.235.57:9999'</span>,</span><br><span class="line">        <span class="string">'https'</span>: <span class="string">'https://110.52.235.57:9999'</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">'http://www.taobao.com'</span>, proxies=proxies, headers=headers)</span><br><span class="line"></span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>另外，若使用非免费的代理，可能需要使用 HTTP Basic Auth，可以使用类似 <a href="http://user:password@host" target="_blank" rel="noopener">http://user:password@host</a>:port 这样的语法来设置代理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">'https'</span>: <span class="string">'http://user:password@10.10.1.10:3128/'</span>,</span><br><span class="line">&#125;</span><br><span class="line">requests.get(<span class="string">'https://www.taobao.com'</span>, proxies=proxies)</span><br></pre></td></tr></table></figure>
<p>Requests 还支持 SOCKS 协议的代理:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip3 install <span class="string">"requests[socks]"</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">'http'</span>: <span class="string">'socks5://user:password@host:port'</span>,</span><br><span class="line">    <span class="string">'https'</span>: <span class="string">'socks5://user:password@host:port'</span></span><br><span class="line">&#125;</span><br><span class="line">requests.get(<span class="string">'https://www.taobao.com'</span>, proxies=proxies)</span><br></pre></td></tr></table></figure>
<h4 id="http-基本认证"><a class="markdownIt-Anchor" href="#http-基本认证"></a> HTTP 基本认证</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.auth <span class="keyword">import</span> HTTPBasicAuth</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">'http://pythonscraping.com/pages/auth/login.php'</span>, auth=HTTPBasicAuth(<span class="string">'username'</span>, <span class="string">'password'</span>))</span><br><span class="line">print(r.status_code)</span><br></pre></td></tr></table></figure>
<p>还可以更简单：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">'http://pythonscraping.com/pages/auth/login.php'</span>, auth=(<span class="string">'username'</span>, <span class="string">'password'</span>))</span><br><span class="line">print(r.status_code)</span><br></pre></td></tr></table></figure>
<p>Requests 还支持其他的认证，如 OAuth。关于这方面，可以查看 <a href="https://requests-oauthlib.readthedocs.io/en/latest/" target="_blank" rel="noopener">文档</a> 。</p>
<h4 id="prepared-request"><a class="markdownIt-Anchor" href="#prepared-request"></a> Prepared Request</h4>
<p>类似于 Urllib 中的 Request ，我们可以在 Requests 中使用 Prepared Request 来表示一个请求：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> requests <span class="keyword">import</span> Request, Session</span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://httpbin.org/post'</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'name'</span>: <span class="string">'germey'</span></span><br><span class="line">&#125;</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line">s = Session()</span><br><span class="line">req = Request(<span class="string">'POST'</span>, url, data=data, headers=headers)</span><br><span class="line">prepped = s.prepare_request(req)</span><br><span class="line">r = s.send(prepped)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure>
<p>这里我们引入了 Request，然后用 url、data、headers 参数构造了一个 Request 对象，这时我们需要再调用 Session 的 prepare_request() 方法将其转换为一个 Prepared Request 对象，然后调用 send() 方法发送即可</p>
<p>通过 Request 对象，我们就可以将一个个请求当做一个独立的对象来看待，这可以方便调度。</p>

  </div>
</article>
<!--Disqus-->


<!--Livere-->

    <div class="blog-post-comments">
        <div id="lv-container" data-id="city" data-uid="MTAyMC80NjEzMi8yMjY0Mw==">
            <noscript>加载评论需要在浏览器启用 JavaScript 脚本支持。</noscript>
        </div>
    </div>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/about/">关于</a></li>
         
          <li><a href="/archives/">归档</a></li>
         
          <li><a href="https://github.com/cdfmlr">项目</a></li>
         
          <li><a href="/search/">搜索</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#爬虫请求库的使用之requests"><span class="toc-number">1.</span> <span class="toc-text"> 爬虫请求库的使用之Requests</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#requests"><span class="toc-number">1.1.</span> <span class="toc-text"> requests</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#requestsget-get请求"><span class="toc-number">1.1.1.</span> <span class="toc-text"> requests.get() —— GET请求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#获取二进制数据"><span class="toc-number">1.1.2.</span> <span class="toc-text"> 获取二进制数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#抓取网页"><span class="toc-number">1.1.3.</span> <span class="toc-text"> 抓取网页</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#requestspost-post请求"><span class="toc-number">1.1.4.</span> <span class="toc-text"> requests.post() —— POST请求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#文件上传"><span class="toc-number">1.1.5.</span> <span class="toc-text"> 文件上传</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cookies"><span class="toc-number">1.1.6.</span> <span class="toc-text"> Cookies</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#获取cookies"><span class="toc-number">1.1.6.1.</span> <span class="toc-text"> 获取Cookies</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#调用cookies"><span class="toc-number">1.1.6.2.</span> <span class="toc-text"> 调用Cookies</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#会话维持"><span class="toc-number">1.1.6.3.</span> <span class="toc-text"> 会话维持</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#不使用会话维持"><span class="toc-number">1.1.6.3.0.1.</span> <span class="toc-text"> 不使用会话维持</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#使用会话维持"><span class="toc-number">1.1.6.3.0.2.</span> <span class="toc-text"> 使用会话维持</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ssl-证书验证"><span class="toc-number">1.1.6.4.</span> <span class="toc-text"> SSL 证书验证</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#代理设置"><span class="toc-number">1.1.6.5.</span> <span class="toc-text"> 代理设置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#http-基本认证"><span class="toc-number">1.1.6.6.</span> <span class="toc-text"> HTTP 基本认证</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#prepared-request"><span class="toc-number">1.1.6.7.</span> <span class="toc-text"> Prepared Request</span></a></li></ol></li></ol></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=https://clownote.github.io/2019/02/12/crawler-3-requests/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&text=python请求库requests"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&title=python请求库requests"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&is_video=false&description=python请求库requests"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=python请求库requests&body=Check out this article: https://clownote.github.io/2019/02/12/crawler-3-requests/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&title=python请求库requests"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&title=python请求库requests"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&title=python请求库requests"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&title=python请求库requests"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=https://clownote.github.io/2019/02/12/crawler-3-requests/&name=python请求库requests&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> 菜单</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> 目录</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> 分享</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> 返回顶部</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2019 CDFMLR
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/about/">关于</a></li>
         
          <li><a href="/archives/">归档</a></li>
         
          <li><a href="https://github.com/cdfmlr">项目</a></li>
         
          <li><a href="/search/">搜索</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css">

    <!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<!-- clipboard -->

  <script src="/lib/clipboard/clipboard.min.js"></script>
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"复制到粘贴板!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight .code pre").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      target: function(trigger) {
        return trigger.nextElementSibling;
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "复制成功!");
      e.clearSelection();
    })
  })
  </script>

<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-146911386-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Baidu Analytics -->

    <script type="text/javascript">
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?9a0d2e6fde93dad496ac79f04f3aba97";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

<!-- Disqus Comments -->


<!--Livere Comments-->

    <script type="text/javascript">
      (function (d, s) {
        var j, e = d.getElementsByTagName(s)[0];

        if (typeof LivereTower === 'function') { return; }

        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;

        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>

</body>
</html>
